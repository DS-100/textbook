{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Reference: https://jupyterbook.org/interactive/hiding.html\n",
    "# Use {hide, remove}-{input, output, cell} tags to hiding content\n",
    "\n",
    "import sys\n",
    "import os\n",
    "if not any(path.endswith('textbook') for path in sys.path):\n",
    "    sys.path.append(os.path.abspath('../../..'))\n",
    "from textbook_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex and Differentiable Loss Functions\n",
    "\n",
    "As its name suggests, the gradient descent algorithm requires the loss function to be differentiable. Choosing a differentiable loss function, $ \\nabla_\\theta L( \\boldsymbol{\\theta} ) $, is a crucial part of the  algorithm. The gradient allows us to make a linear approximation to the loss function in small neighborhoods of $ \\boldsymbol{\\theta} $. This approximation gives us the direction of the step and as long as we don't overshoot the minimum, $ \\boldsymbol{\\hat{\\theta}} $, we are bound to eventually reach it.  Well, as long as the loss function is also convex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GVy9_wsSeBqf"
   },
   "source": [
    "The step-by-step search for the minimum relies on the loss function being convex because then it can't have a local minimum. The function in the diagram on the left in {numref}`Figure %s <gd-convex>` has a local minimum, and depending on where the algorithm starts, it might converge to the local minimum and miss the real minimum entirely. The property of convexity avoids this problem, as shown in the diagram on the right in the figure. A *convex function* cannot have local minima. So, with an appropriate step size, gradient descent will find the globally optimal $ \\theta $ for any convex function. \n",
    "\n",
    "\n",
    "```{figure} figures/convex-diagram.png\n",
    "---\n",
    "name: gd-convex\n",
    "---\n",
    "\n",
    "With non-convex functions, such as the function on the left, gradient descent might locate a local minimum, rather than a global minimum. This is not possible with convex functions, such as the function on the right. \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0oF9T8G3_72R"
   },
   "source": [
    "Formally, a function $ f $ is convex if for any two input values, $ \\boldsymbol{\\theta}_a $ and $ \\boldsymbol{\\theta}_b $, and any $ q $ between 0 and 1: \n",
    "\n",
    "$$ qf(\\boldsymbol{\\theta}_a) + (1-q)f( \\boldsymbol{\\theta}_b) \\geq f(q \\boldsymbol{\\theta}_a + (1-q) \\boldsymbol{\\theta}_b)$$\n",
    "\n",
    "This inequality states that all lines connecting two points of the function must reside on or above the function itself.\n",
    "Heuristically, this means that whenever we take a small enough step to the right when the gradient is negative or to the left when the gradient is positive, we will head in the direction of the function's minimum. \n",
    "\n",
    "The formal definition of convexity gives us a precise way of determining whether a function is convex. \n",
    "And, we can use this definition to connect the convexity of the loss function $ \\cal{l}( \\boldsymbol{\\theta} ) $ to the convexity of the average loss $ L( \\boldsymbol{\\theta} ) $. We have been ignoring the fact that $ L( \\boldsymbol{\\theta} ) $ is also a function of the data, where $ \\cal{l}(\\boldsymbol{\\theta}, \\mathbf{x}_i, y_i) $ is the loss function and the average loss is $ L(\\boldsymbol{\\theta}) = 1/n \\sum \\cal{l}(\\boldsymbol{\\theta}, \\mathbf{x}_i, y_i) $.  If $ \\cal{l}(\\boldsymbol{\\theta}, \\mathbf{x}_i, y_i) $ is a convex function of $ \\boldsymbol{\\theta} $, then the average loss is also convex. We walk through a proof of this statement in the exercises. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of $ L(\\boldsymbol{\\theta}) $ can also be expressed in terms of the gradient of $ \\cal{l}(\\boldsymbol{\\theta}, \\mathbf{x}_i, y_i) $, \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\nabla_{\\theta} L(\\boldsymbol{\\theta}, \\textbf{X}, \\mathbf{y}) &= \\frac{1}{n} \\sum_{i=1}^{n} \\nabla_{\\theta} {\\cal l}(\\boldsymbol{\\theta}, \\mathbf{x}_i, y_i),\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $ \\textbf{X} $ is an $ n \\times p $ design matrix, and $ \\mathbf{x}_i $ is the $i$th row of the design matrix, which corresponds to the $ i $th observation in the data set. With a large amount of data, calculating $ \\theta^{(t)}$ can be computationally expensive since it involves the average of the gradient $ \\nabla_{\\theta} {\\cal l} $ over all the $ (\\textbf{x}_i, y_i) $. We consider alternatives to gradient descent that can be computationally faster because they don't average over all of the data. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "convexity.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
