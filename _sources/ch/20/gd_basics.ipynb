{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Reference: https://jupyterbook.org/interactive/hiding.html\n",
    "# Use {hide, remove}-{input, output, cell} tags to hiding content\n",
    "\n",
    "import sys\n",
    "import os\n",
    "if not any(path.endswith('textbook') for path in sys.path):\n",
    "    sys.path.append(os.path.abspath('../../..'))\n",
    "from textbook_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Basics\n",
    "\n",
    "Gradient descent is based on the notion that for many loss functions, the function is roughly linear in small neighborhoods of the parameter. {numref}`Figure %s <gd-diagram>` gives a diagram of the basic idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} figures/gd-diagram.png\n",
    "---\n",
    "name: gd-diagram\n",
    "---\n",
    "\n",
    "The technique of gradient descent moves in small increments towards the minimizing parameter value.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the diagram on the left in the figure, we have drawn the tangent line to the loss curve $ L $ at $ \\tilde{\\theta} $ to the left of the minimizing value, $ \\hat{\\theta} $. Notice that the slope of the tangent line is negative so, with a short step to  the right of $ \\tilde{\\theta} $, the point on the tangent line is close to the loss for that value and this loss is smaller than $ L(\\tilde{\\theta}) $. That is, since the slope, $ b $,  is negative, and the tangent line approximates the loss function in a neighborhood of $ \\tilde{\\theta} $, we have\n",
    "\n",
    "$$\n",
    "L(\\tilde{\\theta} + \\textrm{step}) \\approx  L(\\theta) + b\\times\\textrm{step} < L(\\theta)\n",
    "$$\n",
    "\n",
    "Taking a small step to the right of $ \\tilde{\\theta} $ decreases the loss. On the other hand, where the slope is positive, like in the diagram on the right in  {numref}`Figure %s <gd-diagram>`, then taking a small step to the left decreases the loss.\n",
    "\n",
    "When we take repeated small steps in the direction indicated by the slope of tangent line at each new step, this\n",
    "leads to smaller and smaller values of the average loss and eventually brings us to the minimizing value $ \\hat{\\theta} $ (or very close to it). This is the basic idea behind gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More formally, the gradient descent algorithm to minimize $ L (\\boldsymbol{\\theta}) $ for a general vector of parameters,  $ \\boldsymbol{\\theta} $, uses the gradient (first order derivative) to determine the small step to take. If we write the gradient, $ \\nabla_\\theta L(\\boldsymbol{\\theta})  $ as  simply $ g( \\boldsymbol{\\theta})$, then we take the step to be $ -\\alpha g( \\boldsymbol{\\theta}) $ for some small positive $ \\alpha $, and we have \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\theta + (-\\alpha g( \\boldsymbol{\\theta})) & \\approx L(\\theta) - \\alpha g( \\boldsymbol{\\theta})^T g( \\boldsymbol{\\theta} \\\\\n",
    " & < L(\\theta)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Note that $ g( \\boldsymbol{\\theta})$ is a $p \\times 1 $ vector, and $ g( \\boldsymbol{\\theta})^T g( \\boldsymbol{\\theta} $ is positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps in the algorithm go as follows:\n",
    "\n",
    "1. Choose a starting value, called $  \\boldsymbol{\\theta}^{(0)} $ (a common choice is $ \\boldsymbol{\\theta}^{(0)} = 0 $).\n",
    "2. Compute $  \\boldsymbol{\\theta}^{(t+1)} =  \\boldsymbol{\\theta}^{(t)} - \\alpha g( \\boldsymbol{\\theta}) $.\n",
    "3. Repeat step 2 until $ \\boldsymbol{\\theta}^{(t+1)} $ doesn't change (or changes little) between iterations. \n",
    "\n",
    "The quantity $ \\alpha $ is called the learning rate, and is important. It needs to be small enough to not overshoot the minimum but large enough to arrive at the minimum in reasonably few steps (see {numref}`Figure %s <gd-learning-rate>`). Sometimes it is useful to decrease $ \\alpha $ over time. When $ \\alpha $ changes between iterations, we use the notation $ \\alpha^{(t)} $ to indicate that the learning rate varies during the search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} figures/learning_rate.png\n",
    "---\n",
    "name: gd-learning-rate\n",
    "---\n",
    "\n",
    "A small learning rate requires many steps to converge (left), and a large learning rate can diverge (right). Choosing the learning rate well leads to fast convergence on the minimizing value (middle).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient descent algorithm is simple yet powerful since we can use it for many types of models and many types of loss functions. It is the computational tool of choice for fitting many models, including linear regression on large datasets and neural networks. We demonstrate the algorithm to fit a constant to the bus late times using Huber loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
