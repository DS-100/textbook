{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Reference: https://jupyterbook.org/interactive/hiding.html\n",
    "# Use {hide, remove}-{input, output, cell} tags to hiding content\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display\n",
    "import myst_nb\n",
    "\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option('display.max_rows', 7)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('precision', 2)\n",
    "# This option stops scientific notation for pandas\n",
    "# pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "def display_df(df, rows=pd.options.display.max_rows,\n",
    "               cols=pd.options.display.max_columns):\n",
    "    with pd.option_context('display.max_rows', rows,\n",
    "                           'display.max_columns', cols):\n",
    "        display(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# businesses\n",
    "bus = pd.read_csv('data/businesses.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# inspections\n",
    "insp = pd.read_csv(\"data/inspections.csv\")\n",
    "\n",
    "# violations\n",
    "viol = pd.read_csv(\"data/violations.csv\")\n",
    "\n",
    "# DAWN\n",
    "colspecs = [(0,6), (14,29), (33,35), (35, 37), (37, 39), (1213, 1214)]\n",
    "varNames = [\"id\", \"wt\", \"age\", \"sex\", \"race\",\"type\"]\n",
    "dawn = pd.read_fwf('data/DAWN-Data.txt', colspecs=colspecs, header=None, index_col=0,\n",
    "                   names = varNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ch:wrangling_checks)=\n",
    "# Quality Checks\n",
    "\n",
    "Once your data are in a table and you understand its scope and granularity, it's time to inspect their quality. You may have come across errors in the data as you examined it and wrangled it into a data frame. In this section, we continue the inspection and carry out a more comprehensive assessment of the quality of the features and their values.  We consider quality from four vantage points: \n",
    "\n",
    "+ Scope: Do the data match your understanding of the population? \n",
    "+ Measurements and Values: Are the values reasonable?\n",
    "+ Relationships: Are related features in agreement?\n",
    "+ Analysis: Which features can be used? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quality based on scope**. In the earlier {ref}`ch:data_scope` chapter, we addressed whether or not the data that have been collected can adequately address the problem at hand. In that chapter, we analyzed the data scope by\n",
    "looking at the data's target population,\n",
    "access frame, and sample.\n",
    "This framework helps us consider possible limitations\n",
    "in the way in which the data were collected that might impact the generalizability of our findings.\n",
    "\n",
    "While these broader data scope considerations are important\n",
    "as we deliberate our final conclusions, they are also useful for\n",
    "checking data quality.\n",
    "For example, with San Francisco restaurant inspections, all \n",
    "restaurant zip codes should start with 941.\n",
    "But, we can see that there are several zip codes that don't:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94080        1\n",
       "94621        1\n",
       "94544        1\n",
       "            ..\n",
       "64110        1\n",
       "94545        1\n",
       "941033148    1\n",
       "Name: postal_code, Length: 10, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus['postal_code'].value_counts().tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lets us spot problems in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another example, a bit of background reading on atmospheric CO2 revelas that typical measurements are about 400 ppm worldwide. So we can check whether the monthly averages of CO2 at Mauna Loa lie between 300 to 400 ppm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quality of measurements and recorded values**. We can use our knowledge of the scope of the data to check quality, as mentioned already, but we can also check the quality of measurements by considering what might be a reasonable value for a feature. For example, whats seems like a reasonable range for the number of violations in a restaurant inspection?  Possibly, 0 to 5? Other checks can be based on common knowledge of ranges: a restaurant inspection score must be between 0 and 100; months run between 1 and 12.  We can use documentation to tells us the expected values for a feature. For example, the type of emergency room visit in the DAWN has been coded as 1, 2, ..., 8 (see {numref}`Figure %s <DAWN_codebook>` below for a screenshot of the codebook explanation of the field) so we can confirm that all values for the type of visit are indeed integers between 1 and 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} figures/DAWN_codebook.png\n",
    "---\n",
    "name: DAWN_codebook\n",
    "---\n",
    "\n",
    "Screenshot of the description of the CASETYPE variable in the DAWN survey. Notice that there are eight possible values for this feature. And to help in figuring out if we have properly read the data, we can check the counts for these eight values. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More generic checks can confirm, say, that a proportion ranges between 0 and 1. We want to ensure that the data type matches our expectations. For example, we expect a price to be a number, whether or not it's stored as integer, floating point, or string.  Confirming that the units of measurement match what is expected can be another useful quality check to perform (for example weight recorded in pounds, not kilograms). We can devise checks for all of these situations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quality of relationships.**   In addition to checking individual values in a column, we also want to cross-check values between features. To do this cross-checking, we use builtin conditions on the relationship of values between two (or more) features.\n",
    "\n",
    "For example, according to the documentation for the DAWN study, alcohol consumption is only considered a type of visit for patients under 21 so we can check that all instances that record alcohol for the type of visit also have age recorded as under 21. Alcohol is coded as a 3, and ages under 21 are coded as 1, 2, 3, and 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>6231</td>\n",
       "      <td>313</td>\n",
       "      <td>4</td>\n",
       "      <td>2101</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1774</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>914</td>\n",
       "      <td>121</td>\n",
       "      <td>2433</td>\n",
       "      <td>2595</td>\n",
       "      <td>1183</td>\n",
       "      <td>48</td>\n",
       "      <td>76</td>\n",
       "      <td>4563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>817</td>\n",
       "      <td>796</td>\n",
       "      <td>4953</td>\n",
       "      <td>3111</td>\n",
       "      <td>1021</td>\n",
       "      <td>95</td>\n",
       "      <td>44</td>\n",
       "      <td>6188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>983</td>\n",
       "      <td>1650</td>\n",
       "      <td>0</td>\n",
       "      <td>4404</td>\n",
       "      <td>1399</td>\n",
       "      <td>170</td>\n",
       "      <td>48</td>\n",
       "      <td>9614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1068</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>5697</td>\n",
       "      <td>1697</td>\n",
       "      <td>140</td>\n",
       "      <td>62</td>\n",
       "      <td>11408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>957</td>\n",
       "      <td>1748</td>\n",
       "      <td>0</td>\n",
       "      <td>5262</td>\n",
       "      <td>1527</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>10296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1847</td>\n",
       "      <td>3411</td>\n",
       "      <td>0</td>\n",
       "      <td>10221</td>\n",
       "      <td>2845</td>\n",
       "      <td>113</td>\n",
       "      <td>115</td>\n",
       "      <td>18366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1616</td>\n",
       "      <td>3770</td>\n",
       "      <td>0</td>\n",
       "      <td>12404</td>\n",
       "      <td>3407</td>\n",
       "      <td>75</td>\n",
       "      <td>150</td>\n",
       "      <td>18381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>616</td>\n",
       "      <td>1207</td>\n",
       "      <td>0</td>\n",
       "      <td>12291</td>\n",
       "      <td>2412</td>\n",
       "      <td>31</td>\n",
       "      <td>169</td>\n",
       "      <td>7109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>205</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>24085</td>\n",
       "      <td>2218</td>\n",
       "      <td>12</td>\n",
       "      <td>308</td>\n",
       "      <td>1537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type     1     2     3      4     5    6     7      8\n",
       "age                                                  \n",
       "-8       2     2     0     21     5    1     1     36\n",
       " 1       0     6    20   6231   313    4  2101     69\n",
       " 2       8     2    15   1774   119    4   119     61\n",
       " 3     914   121  2433   2595  1183   48    76   4563\n",
       " 4     817   796  4953   3111  1021   95    44   6188\n",
       " 5     983  1650     0   4404  1399  170    48   9614\n",
       " 6    1068  1965     0   5697  1697  140    62  11408\n",
       " 7     957  1748     0   5262  1527  100    60  10296\n",
       " 8    1847  3411     0  10221  2845  113   115  18366\n",
       " 9    1616  3770     0  12404  3407   75   150  18381\n",
       " 10    616  1207     0  12291  2412   31   169   7109\n",
       " 11    205   163     0  24085  2218   12   308   1537"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_df(pd.crosstab(dawn['age'], dawn['type']), rows=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross tabulation shows that all of the alcohol cases are for patients under 21. The data values are as expected.       \n",
    "\n",
    "**Quality for analysis**. Even when data pass your quality checks, problems can arise with its usefulness. For example, if all but a handful of values for a feature are identical, then that feature adds little to the understanding of underlying patterns and relationships.  Or, if there are too many missing values, especially if there is a discernible pattern in the missing values, our findings may be limited. If a feature has many bad/corrupted values, then we might question the accuracy of even those values that fall in the appropriate range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see below that the type of restaurant inspection in San Francisco can be either routine or from a complaint. Since only one of the 14,000+ inspections was from a complaint, we lose little if we drop this feature, and we might also want to drop that single inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "routine      14221\n",
       "complaint        1\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(insp['type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two questions that might have come to your mind at this point are: 1) How do we look for garbled, anomalous, and inconsistently coded values? And, 2) once we find them, what do we do? We address these questions generally here, and show some of the practicalities in the example in {numref}`Section %s <ch:wrangling_restaurants>`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to find bad values and features?** \n",
    "\n",
    "- Check summary statistics, distributions, and value counts. {numref}`Chapter %s <ch:eda>` provides examples and guidance on how to go about checking the quality of your data using visualizations and summary statistics. We briefly mention a few approaches here. A table of counts of unique values in a feature can uncover unexpected encodings and lopsided distributions, where one option is a rare occurrence. Percentiles can be helpful in revealing the proportion of values with unusually high (or low) values.\n",
    "- Logical expressions can identify records with values out of range or relationships that are out of wack. Simply computing the number of records that do not pass the quality, check can quickly reveal the size of the problem.\n",
    "- Examine the whole record for those records with problematic values for a particular feature. At times, an entire record is garbled when, for example, a comma is misplaced in a CSV formatted file. Or, the record(s) might represent an unusual situation (such as ranches being included in data on house sales), and you will need to decide whether they should be included in your analysis or not.\n",
    "- Refer to an external source to figure out if there's a reason for the anomaly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What to do with your discoveries?** You have essentially four options: leave the data as is; modify values; remove features; or drop records.  Not every unusual aspect of the data needs to be fixed. You might have discovered a characteristic of your data that will inform you with your analysis, but otherwise does not need any correcting. Or, you might find that the problem is relatively minor and most likely will not impact your analysis so you can leave the data as is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, you might want to replace corrupted values with `NaN`. You might have figured out what went wrong and correct the value. Other possibilities for modifying records are covered in the examples of \n",
    "the {ref}`ch:eda` chapter.\n",
    "If you plan to change the values of a variable, then it's good practice to create a new feature with the modified value and preserve the original feature, or at a minimum, create a new feature that indicates which values in the original feature have been modified. These approaches give you some flexibility in checking the influence of the modified values on your analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you find yourself modifying many values for a feature then you might consider eliminating the feature from the dataset. Either way, you will want to study the possible impact of excluding the feature from your analysis.  In particular, you will want to determine whether the records with corrupted values are similar to each other, and different from the rest of the data. This would indicate that you may be unable to capture the impact of a potentially useful feature in your analysis. Rather than exclude the feature entirely, there may be a transformation that allows you to keep the feature while reducing the level of detail recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At times, you will want to eliminate the problematic records. In general, we do not want to drop a large number of observations from a dataset without good reason. We may want to scale back our investigation to a particular subgroup of the data, but that's a different situation than dropping records because of a corrupted value in a field (see Section xx).  When you discover that an unusual value is in fact correct,  you still might decide to exclude the record from your analysis because it's so different from the rest of your data and you do not want it to overly influence your analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "In this section, we introduced four types of quality checks: checks on scope,\n",
    "measurements, relationships, and analysis. These checks can reveal issues in\n",
    "the data that need to be addressed before proceeding with analysis. One\n",
    "particularly important type of check is to look for missing data. We suggested\n",
    "that there may be times when you want to replace corrupted data values with\n",
    "`NaN`, and hence treat them as missing. At other times, data might arrive\n",
    "missing. What to do with missing data is an important topic and there is a lot\n",
    "of research on this problem; we cover ways to address\n",
    "missing data in the next section."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
