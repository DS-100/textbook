{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "if not any(path.endswith('textbook') for path in sys.path):\n",
    "    sys.path.append(os.path.abspath('../../..'))\n",
    "from textbook_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "outlier_czs = [34105, 34113, 34112, 34106]\n",
    "df = (\n",
    "    pd.read_csv('data/mobility.csv')\n",
    "    # filter out rows with NaN AUM values\n",
    "    .query('not aum.isnull()', engine='python')\n",
    "    # take out outlier CZs\n",
    "    .query('cz not in @outlier_czs')\n",
    ")\n",
    "\n",
    "predictors = [\n",
    "    'frac_traveltime_lt15',\n",
    "    'gini',\n",
    "    'dropout_r',\n",
    "    'rel_tot',\n",
    "    'cs_fam_wkidsinglemom',\n",
    "    'taxrate',\n",
    "    'gradrate_r',\n",
    "    'frac_worked1416',\n",
    "    'cs_born_foreign',\n",
    "]\n",
    "\n",
    "X = (df[predictors]\n",
    "    # Some predictors are missing; we'll drop them for simplicity\n",
    "    .dropna()\n",
    "    .assign(intr=1)\n",
    "    # Move intercept column to appear first\n",
    "    [['intr', *predictors]]\n",
    ")\n",
    "y = df.loc[X.index, 'aum']\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sec:linear_multi_fit)=\n",
    "# Fitting the Multiple Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a $ n \\times (p + 1) $ design matrix $ X $, a $ n $-dimensional\n",
    "column vector of outcomes $ y $, and a $ (p + 1) $-dimensional column \n",
    "vector of model parameters $ \\theta $, we assume that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "y = X \\theta + \\epsilon\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, $ \\epsilon $ is a $ n $-dimensional column vector that represents the\n",
    "sampling error.\n",
    "We define the multiple linear model as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "f_{\\theta}(X) = X \\theta\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the simple linear model, we'll fit $ f_{\\theta}(X) $ using\n",
    "the squared loss function.\n",
    "We want to find the model parameters $ \\hat{\\theta} $ that minimize the\n",
    "mean squared loss:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\theta, X, y)\n",
    " &= \\frac{1}{n} \\left | y - f_{\\theta}(X) \\right|^2\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we're using the notation $ |v|^2 $ for a vector $ v $ as a\n",
    "shorthand for the sum of each vector element squared [^l2]:\n",
    "$ |v|^2 = \\sum_i v_i^2 $ .\n",
    "\n",
    "[^l2]: $ |v| $ is also called the $ \\ell_2 $ norm of a\n",
    "vector $ v $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll fit our model by figuring out what the\n",
    "minimizing $ \\hat{\\theta} $ is.\n",
    "One idea is to use calculus as we did for the simple linear model.\n",
    "However, this approach needs knowledge of vector calculus that we won't\n",
    "cover in this book.\n",
    "Instead, we'll use a geometric argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Geometric Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is the find the $ \\hat{\\theta} $ that minimizes our loss\n",
    "function---we want to make $ L(\\theta, X, y) $ as small as possible\n",
    "for a given $ X $ and $ y $.\n",
    "The key insight is that we can restate this goal in a geometric way.\n",
    "Remember: the model predictions $ f_{\\theta}(X) $ and the true outcomes\n",
    "$ y $ are both vectors.\n",
    "We can treat vectors as points---for example, we can plot\n",
    "the vector $ [ 2, 3 ] $ at $ x = 2, y = 3 $ in 2D space.\n",
    "Then, minimizing $ L(\\theta, X, y) $ is equivalent to finding\n",
    "$ \\hat{\\theta} $ that makes $ f_{\\theta}(X) $ as close as possible to\n",
    "$ y $ when we plot them as points.\n",
    "As depicted in {numref}`Figure %s <fig:geom-2d>`, different values of\n",
    "$ \\theta $ give different predictions $ f_{\\theta}(X) $ (hollow points).\n",
    "Then, $ \\hat{\\theta} $ is the vector of parameters that put\n",
    "$ f_{\\theta}(X) $ as close to $ y $ (filled point) as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} figures/geom-2d.svg\n",
    "---\n",
    "name: fig:geom-2d\n",
    "width: 250px\n",
    "---\n",
    "\n",
    "A plot showing different values of $ f_{\\theta}(X) $ (hollow points) and\n",
    "the outcome vector $ y $ (filled point).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll look at the possible values of $ f_{\\theta}(X) $.\n",
    "In {numref}`Figure %s <fig:geom-2d>`, we showed a few possible \n",
    "$ f_{\\theta}(X) $.\n",
    "Instead of just plotting a few possible points, we can\n",
    "plot *all* possible values of $ f_{\\theta}(X) $ by varying $ \\theta $.\n",
    "This results in a subspace of possible $ f_{\\theta}(X) $ values, as shown in\n",
    "{numref}`Figure %s <fig:geom-span>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} figures/geom-span.svg\n",
    "---\n",
    "name: fig:geom-span\n",
    "width: 250px\n",
    "---\n",
    "\n",
    "A plot showing all possible values of $ f_{\\theta}(X) $ as a line.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we notice that the vector $ f_{\\theta}(X) $ always lies in the\n",
    "span of the columns of $ X $ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key insight is that the model predictions\n",
    "$ f_{\\theta}(X) = X \\theta $ will always lie in the span of the \n",
    "columns of the design matrix $ X $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
