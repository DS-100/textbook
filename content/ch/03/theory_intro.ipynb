{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Reference: https://jupyterbook.org/interactive/hiding.html\n",
    "# Use {hide, remove}-{input, output, cell} tags to hiding content\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display\n",
    "\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option('display.max_rows', 7)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('precision', 2)\n",
    "# This option stops scientific notation for pandas\n",
    "# pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "def display_df(df, rows=pd.options.display.max_rows,\n",
    "               cols=pd.options.display.max_columns):\n",
    "    with pd.option_context('display.max_rows', rows,\n",
    "                           'display.max_columns', cols):\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ch:theory_datadesign)=\n",
    "# Theory for Data Design\n",
    "\n",
    "In this chapter, we develop the theory behind the chance processes introduced in the ref ch:data_scope chapter.  This theory makes the concepts of bias and variation more precise. We continue to motivate the accuracy of our data through the abstraction of an urn model that was first introduced in the ref sec:variationtypes section of numref Chapter ch:data_scope, and we use both basic probability and simulation studies to develop the theory.\n",
    "\n",
    "We use the urn model in two ways. First, we consider an artifical example with a small population. Since the population is so small, we can exactly calculate the chance of a particular sample being drawn from the population. Here, the urn model introduces the simple random sample and stratfied random sample, which are both core sampling techniques that form the basis of many complex surveys. (See Section sec:theory_samplingVariation).\n",
    "\n",
    "Next, we use the urn model as a technical framework to design and run simulation studies to understand larger and more complex situations. We return to some of the examples from numref Chapter ch:data_scope and, for example, dive deeper into understanding how the pollsters might have gotten the 2016 Presidential Election predictions wrong (Section sec:theory_electionpoll). We use the actual votes cast in Pennsylvania to simulate the sampling variation for a poll of 1,400 from six million voters. This simulation helps us uncover how response bias can skew polls, and convince us that collecting a lot more data would not have helped the situtation (another example of big data hubris). \n",
    "\n",
    "In a second simulation study (Section sec:theory_randomAssignment), we examine the efficacy of a COVID-19 vaccine. A designed experiment for the vaccine was carried out on over 50,000 volunteers. Abstracting the experiment to an urn model gives us a tool for studying assignment variation.  Through simulation, we find the expected outcome of the clinical trial. Our simulation, along with careful examination of the data scope, debunks claims of vaccine ineffectiveness. \n",
    "\n",
    "In addition, to sampling variation and assignment variation, we also address measurement error (Section sec:theory_measurementError). There, we use multiple measurements from diffeerent times of the day to estimate the accuracy of an air quality sensor. Later in Chapter ch:pa, we return to air quality for a more comprehensive treatment of measurement error and instrument calibration. \n",
    "\n",
    "Simulation studies enable us to approximate the typical variations in a chance process and in summary statistics. If you are looking for a more general approach, in Section sec:theory_probIntro, we use probability to work out formulas that formalize the theory of expected outcomes and variation. On the other hand, you may wish to skip this section until they find the need for this formal theory.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
