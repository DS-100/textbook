{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Reference: https://jupyterbook.org/interactive/hiding.html\n",
    "# Use {hide, remove}-{input, output, cell} tags to hiding content\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display\n",
    "import myst_nb\n",
    "\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option('display.max_rows', 7)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('precision', 2)\n",
    "# This option stops scientific notation for pandas\n",
    "# pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "def display_df(df, rows=pd.options.display.max_rows,\n",
    "               cols=pd.options.display.max_columns):\n",
    "    with pd.option_context('display.max_rows', rows,\n",
    "                           'display.max_columns', cols):\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ch:reading_format)=\n",
    "# File Formats\n",
    "\n",
    "The data from the DAWN survey and the San Francisco restaurant inspections are made available online as plain text files. In order to explore these data, we first need to get them into a `pandas` DataFrame. To do this, we need to know the source file's format and encoding.  For example, a comma-separated-value formatted (CSV) file contains plain text where data values are separated by commas, and records are delimited by newlines (`\"\\n\"` or `\"\\r\\n\"` characters).  CSV files are a natural format for storing data with a table structure: each line in the file corresponds to a row in the table, and the column/feature information in a line are separated by\n",
    "commas. Once we identify the file format, we know how to read it into a Python DataFrame. Other potentially important aspects of the file are its encoding and size. If we don't specify the encoding correctly, then the values in the data frame might contain gibberish, and if the file is huge, then we might not be able to load it into Python. We give an overview of file format and encoding in this section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A file format describes how data are stored on the computer. This is in contrast to the data's structure, which is a mental representation of our data.  The mental model for structure helps us  interact with and analyse the data. For example, a table representation corresponds to data values arranged in rows and columns, and when we work with these data we think about transforming columns, aggregating rows, and cleaning values. On the other hand, understanding how the raw data is stored on the computer (the source file) helps us figure out how to read the data into Python and work with it as a data frame. In this section, we introduce several popular formats used to store data tables as plain text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delimited format.** These formats use a specific character to separate data values. Typically, the separators are: a comma (Comma-Separated-Values or CSV for short), a tab (Tab-Separated Values or TSV), white-space, or colon. These formats are natural for storing data that have a table structure. In these files, each line represents a record, and within a line, the record's information is delimited by the comma character (\",\") for CSV or the tab character (\"\\t\") for TSV. The first line of these files often contains the names of the tableâ€™s columns/features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, the San Francisco restaurant scores are stored in CSV-formatted\n",
    "files. Here are the first few lines of the `inspections.csv` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\"business_id\",\"score\",\"date\",\"type\"\n",
    "19,\"94\",\"20160513\",\"routine\"\n",
    "19,\"94\",\"20171211\",\"routine\"\n",
    "24,\"98\",\"20171101\",\"routine\"\n",
    "24,\"98\",\"20161005\",\"routine\"\n",
    "24,\"96\",\"20160311\",\"routine\"\n",
    "31,\"98\",\"20151204\",\"routine\"\n",
    "45,\"78\",\"20160104\",\"routine\"\n",
    "45,\"88\",\"20170307\",\"routine\"\n",
    "45,\"85\",\"20170914\",\"routine\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the field names appear in the first line, comma-separated and in quotations. We see there are four fields, the business identifier, the restaurant's score, the date of the inspection, and the type of inspection. Each line in the file corresponds to one inspection, and the ID, score, date and type values are separated by commas. In addition to identifying the file\n",
    "format, we also want to identify the format of the features. We see two things of note: the scores and dates both appear as strings. We will want to convert the scores to numbers so we can calculate summary statistics and create a histogram of scores. And, we will convert the date into a date-time format so that we can make time-series plots. We show how to carry out these transformations in {numref}`Section %s <ch:wrangling_transformations>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fixed-width Format.** This format does not use delimiters to separate data values. Instead, the values for a specific field appear in the exact same position in each line. The DAWN data follow this format. Below are four partial lines from the DAWN survey data. Notice how the values appear to align from one row to the next. Notice also that they seem to be squished together with no separators. You need to know the exact position of each piece of information in a line in order to make sense of it. SAMHDA provides a 2,000-page codebook with all of the information needed to read the file. In the codebook we find that the age field appears in positions 34-35 and is coded in intervals from 1 to 11. The four records below have age categories of 4, 11, 11, and 2, and the codebook tells us that , 4, and 11 stand for the age brackets \"6 to 11\", \"18 to 20\", and \"65+\", respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "     1 2251082    .9426354082   3 4 1 2201141 2 865 105 1102005 1 2 1 2.00-7.00-7.0000-7.0000...\n",
    "     2 2291292   5.9920106887   911 1 3201134 12077  81  82 283-8 21767.0067.0167.0140-7.0000...\n",
    "     3 7 7 251   4.7231718669   611 2 2201143 12313   1  12  -7-8 21764.0064.99-7.0000-7.0000...\n",
    "     410 8 292   4.0801470012   6 2 1 3201122 1 234 358  99 215 2 21773.0073.0173.0106-7.0000...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "\n",
    "**Note**: A widely adopted convention is to use the filename extension, such as `.csv`, `.tsv`, and `.txt`, to indicate the format of the contents of the file. File names that end with `.csv` are expected to contain comma-separated values, `.tsv` tab-separated values, and `.txt` generally is plain text. However, these extension names are only suggestions. Even if a file has a `.csv` extension, the actual contents might not be formatted properly! It's good practice to inspect the contents of the file before loading it into a data frame. If the file is not too large, you can open and examine it with a plain text editor. Otherwise, you might use `readlines()` to view a couple of lines, or shell commands ({numref}`Section %s <ch:reading_command_line>`). \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other plain text formats that are popular include hierarchical formats and loosely structured formats (in contrast to formats that support table structures). These are covered in greater detail in other chapters, but for completeness we briefly describe them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hierarchical Format.** JavaScript Object Format (JSON) is a common format used for communication by web servers. JSON files have a hierarchical structure with keys and values similar to a Python dictionary. Each record in a JSON file can have different fields and records can contain tables, making for a potentially complicated structure. The eXtensible Markup Language (XML) and HyperText Markup Language (HTML) are common formats for storing documents on the Internet. Like JSON, these files also contain data in a hierarchical, key-value format. We cover both formats (JSON and XML) in more detail in {numref}`Chapter %s <ch:web>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loosely Structured Formats.** Web logs, instrument readings, and program logs typically provide data in plain text.  For example, below is one line of a Web log (we've split it across multiple lines for readability). It contains information such as the date and time and type of request made to the Web site.\n",
    "\n",
    "```\n",
    "169.237.46.168 - -\n",
    "[26/Jan/2004:10:47:58 -0800]\"GET /stat141/Winter04 HTTP/1.1\" 301 328\n",
    "\"http://anson.ucdavis.edu/courses\"\n",
    "\"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0; .NET CLR 1.1.4322)\"\n",
    "```\n",
    "\n",
    "There is structure present, but not in a simple delimited file format.  We see that the date and time appear between square brackets and the type of request (GET in this case) follows the date-time information and appears in quotes. Later in {numref}`Chapter %s <ch:text>`, we will use these observations about the log's structure and string manipulation tools to extract the values of interest into a data table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another example, below is a single recording of measurements taken with a wireless device. The device reports the timestamp, identifier, location of the device, and the signal strengths that it picks up from other devices. This information uses a combination of formats: key=value pairs, semicolon delimited, and comma delimited values. \n",
    "\n",
    "```\n",
    "t=1139644637174;id=00:02:2D:21:0F:33;pos=2.0,0.0,0.0;degree=45.5;\n",
    "00:14:bf:b1:97:8a=-33,2437000000,3;00:14:bf:b1:97:8a=-38,2437000000,3;\n",
    "```\n",
    "\n",
    "Like with the Web logs, we can use string manipulation and the patterns in the recordings to extract features into a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of this is to show: there are many types of file formats that store data!\n",
    "To keep the chapter manageable, we'll focus on data tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have mentioned already that our example source files are plain text.\n",
    "The most basic kind of plain text supports only standard ASCII characters, which includes the upper and lowercase English letters, numbers, punctuation symbols, and spaces. In short, ASCII is a particular character **encoding**. For example, in ASCII, the bits 100 001 stand for the letter A, 100 010 for B, etc. \n",
    "\n",
    "The ASCII encoding is not sufficient to represent a lot of special characters and characters from other languages. Other, more modern, character encodings have many more characters that can be represented. Common encodings for documents and Web pages are Latin-1 (ISO-8859-1) and UTF-8. \n",
    "UTF-8 has over one million characters, and is backwards compatible with ASCII, meaning that it uses the same representation for English letters, numbers and punctuation as ASCII."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `chardet` package can help use determine a file's encoding. No program can say with 100% certainty which encoding is used for a file because after all, it's just a sequence of bits and bytes. For this reason, `chardet.detect()` returns the most likely encoding for a file and a number between 0 and 1 that reflects the confidence in the classification of the encoding. We use `chardet.detect()` to detect the encodings of our example files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File                      Encoding   Confidence\n",
      "data/inspections.csv      ascii      1.0\n",
      "data/co2_mm_mlo.txt       ascii      1.0\n",
      "data/violations.csv       ascii      1.0\n",
      "data/DAWN-Data.txt        ascii      1.0\n",
      "data/legend.csv           ascii      1.0\n",
      "data/businesses.csv       ISO-8859-1 0.73\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "import glob\n",
    "\n",
    "# for each file, print its name, encoding & confidence in the encoding\n",
    "print(\"File\".ljust(25), \"Encoding\".ljust(10), \"Confidence\")\n",
    "for filename in glob.glob('data/*'):\n",
    "    with open(filename, 'rb') as rawdata:\n",
    "        result = chardet.detect(rawdata.read())\n",
    "        rawdata.close()\n",
    "    print(filename.ljust(25), result['encoding'].ljust(10), result['confidence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detection function is quite certain that all but one of the files are ASCII. The exception is  `businesses.csv`, which appears to have an ISO-8859-1 encoding. We run into trouble, if we ignore this encoding and try to read the business file into Pandas without specifying the special encoding. \n",
    "\n",
    "```\n",
    "pandas.read_csv('data/businesses.csv')\n",
    "```  \n",
    "\n",
    "The above call results in the following error.\n",
    "\n",
    "```\n",
    "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd1 in position 8: invalid continuation byte\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To successfully read the data, we must specify the ISO-8859-1 encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>phone_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>NRGIZE LIFESTYLE CAFE</td>\n",
       "      <td>1200 VAN NESS AVE, 3RD FLOOR</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>...</td>\n",
       "      <td>94109</td>\n",
       "      <td>37.79</td>\n",
       "      <td>-122.42</td>\n",
       "      <td>+14157763262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>OMNI S.F. HOTEL - 2ND FLOOR PANTRY</td>\n",
       "      <td>500 CALIFORNIA ST, 2ND  FLOOR</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>...</td>\n",
       "      <td>94104</td>\n",
       "      <td>37.79</td>\n",
       "      <td>-122.40</td>\n",
       "      <td>+14156779494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>NORMAN'S ICE CREAM AND FREEZES</td>\n",
       "      <td>2801 LEAVENWORTH ST</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>...</td>\n",
       "      <td>94133</td>\n",
       "      <td>37.81</td>\n",
       "      <td>-122.42</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6403</th>\n",
       "      <td>94571</td>\n",
       "      <td>THE PHOENIX PASTIFICIO</td>\n",
       "      <td>200 CLEMENT ST</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>...</td>\n",
       "      <td>94118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+14154726100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>94572</td>\n",
       "      <td>BROADWAY DIM SUM CAFE</td>\n",
       "      <td>684 BROADWAY ST</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>...</td>\n",
       "      <td>94133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6405</th>\n",
       "      <td>94574</td>\n",
       "      <td>BINKA BITES</td>\n",
       "      <td>2241 GEARY BLVD</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>...</td>\n",
       "      <td>94115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+14157712907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6406 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      business_id                                name  \\\n",
       "0              19               NRGIZE LIFESTYLE CAFE   \n",
       "1              24  OMNI S.F. HOTEL - 2ND FLOOR PANTRY   \n",
       "2              31      NORMAN'S ICE CREAM AND FREEZES   \n",
       "...           ...                                 ...   \n",
       "6403        94571              THE PHOENIX PASTIFICIO   \n",
       "6404        94572               BROADWAY DIM SUM CAFE   \n",
       "6405        94574                         BINKA BITES   \n",
       "\n",
       "                            address           city  ... postal_code latitude  \\\n",
       "0      1200 VAN NESS AVE, 3RD FLOOR  San Francisco  ...       94109    37.79   \n",
       "1     500 CALIFORNIA ST, 2ND  FLOOR  San Francisco  ...       94104    37.79   \n",
       "2              2801 LEAVENWORTH ST   San Francisco  ...       94133    37.81   \n",
       "...                             ...            ...  ...         ...      ...   \n",
       "6403                200 CLEMENT ST   San Francisco  ...       94118      NaN   \n",
       "6404               684 BROADWAY ST   San Francisco  ...       94133      NaN   \n",
       "6405               2241 GEARY BLVD   San Francisco  ...       94115      NaN   \n",
       "\n",
       "      longitude  phone_number  \n",
       "0       -122.42  +14157763262  \n",
       "1       -122.40  +14156779494  \n",
       "2       -122.42           NaN  \n",
       "...         ...           ...  \n",
       "6403        NaN  +14154726100  \n",
       "6404        NaN           NaN  \n",
       "6405        NaN  +14157712907  \n",
       "\n",
       "[6406 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus = pd.read_csv('data/businesses.csv', encoding='ISO-8859-1')\n",
    "bus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this section, we have introduced the tabular structure representation for data that we use throughout much of the rest of the book. We have introduced formats for plain text data that are widely used for storing and exchanging tables. The comma-separated-value format is the most common, but others, such as tab-separated and fixed-width, are also prevelant. \n",
    "\n",
    "In the next section, we address the issue of file size, and in {numref}`Section %s <ch:reading_command_line>`, we demonstrate how to use shell commands to find information about source files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
