{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Reference: https://jupyterbook.org/interactive/hiding.html\n",
    "# Use {hide, remove}-{input, output, cell} tags to hiding content\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display\n",
    "import myst_nb\n",
    "\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option('display.max_rows', 7)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('precision', 2)\n",
    "# This option stops scientific notation for pandas\n",
    "# pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "def display_df(df, rows=pd.options.display.max_rows,\n",
    "               cols=pd.options.display.max_columns):\n",
    "    with pd.option_context('display.max_rows', rows,\n",
    "                           'display.max_columns', cols):\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ch:wrangling_command_line)=\n",
    "# The Shell and Command Line Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly all computers provide access to a **shell interpreter**, such\n",
    "as `sh` or `bash`. Like the Python interpreter, shell interpreters allow users\n",
    "to run code and view its output. Shell interpreters typically perform\n",
    "operations on the files on a computer. Shell interpreters have their own\n",
    "language, syntax, and built-in commands.\n",
    "\n",
    "We use the term **command-line interface (CLI) tools** to refer to the commands\n",
    "available in the shell interpreter. Although we only cover a few useful CLI\n",
    "tools in this section, there are many useful CLI tools that enable all sorts of\n",
    "useful operations on the computer.\n",
    "For instance, running this command in `bash` produces a list of all the\n",
    "files in the `figures/` folder along with their file sizes:\n",
    "\n",
    "```bash\n",
    "ls -l -h figures/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic syntax for a shell command is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    " command -options arg1 arg2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLI tools often take one or more **arguments**, similar to how Python functions\n",
    "take in arguments, but we wrap arguments with spaces, not parentheses.\n",
    "The arguments appear at the end of the command line, and they are usually the name\n",
    "of a file or some text.\n",
    "In the `ls` example above, the argument to `ls` is `figures/`.\n",
    "Additionally, CLI tools support **flags** that provide\n",
    "additional options. These flags are specified immediately following the command\n",
    "name using a dash as a delimiter. \n",
    "In the `ls` example above, we provided the option flags `-l` (to provide\n",
    "extra information about each file) and `-h` (to format the filesizes).\n",
    "Many commands have default arguments and\n",
    "options, and the `man` command prints a list of acceptable options, examples,\n",
    "and defaults for a command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "\n",
    "All CLI tools we cover in this book are specific to the `sh` shell\n",
    "interpreter, the default interpreter for Jupyter installations on MacOS and\n",
    "Linux systems at the time of writing. Windows systems have a different\n",
    "interpreter and the commands shown in the book may not run on Windows, although\n",
    "Windows gives access to a `sh` interpreter through its Linux Subsystem.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly, we open a terminal program to start a shell interpreter. Jupyter\n",
    "notebooks, however, provide a convenience: if a line of code is prefixed with\n",
    "the `!` character, the line will go directly to the system’s shell interpreter.\n",
    "For example, the `!ls` command lists the files in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mdata\u001b[m\u001b[m                            wrangling_granularity.ipynb\n",
      "\u001b[34mfigures\u001b[m\u001b[m                         wrangling_intro.ipynb\n",
      "wrangling_checks.ipynb          wrangling_missing.ipynb\n",
      "wrangling_co2.ipynb             wrangling_restaurants.ipynb\n",
      "wrangling_command_line.ipynb    wrangling_structure.ipynb\n",
      "wrangling_datasets.ipynb        wrangling_summary.ipynb\n",
      "wrangling_formats.ipynb         wrangling_transformations.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the line above, Jupyter runs the `ls` command through the `sh` shell\n",
    "interpreter and displays the results of the command in the notebook.\n",
    "\n",
    "Calling `ls` with a folder name as an argument shows all the files in the\n",
    "folder. Let's examine the source files for the San Francisco restaurant scores\n",
    "with `ls`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 9496\n",
      "-rw-r--r--  1 sam  staff   645K Dec  6 15:05 businesses.csv\n",
      "-rw-r--r--  1 sam  staff   455K Dec  6 15:05 inspections.csv\n",
      "-rw-r--r--  1 sam  staff   120B Dec  6 15:05 legend.csv\n",
      "-rw-r--r--  1 sam  staff   3.6M Dec  6 15:05 violations.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -lLh data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scoring information is provided in three files. The businesses.csv file\n",
    "provides data on the restaurants, such as its name, address, and location;\n",
    "inspections.csv contains information about the inspection date and score; and\n",
    "violations.csv has more detailed information about the type of violations found\n",
    "during an inspection.  The legends.csv file provides the numeric score ranges\n",
    "for the inspection categories of poor, needs improvement, adequate, and good.\n",
    "To discover this information, however, we need to use other tools to look at\n",
    "the files' structure, size, and encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can display the first few\n",
    "lines of a file with the `head` command. This is very useful for peeking at a\n",
    "file's contents to determine whether it's formatted as a CSV, TSV, etc. Let's\n",
    "look at the inspections.csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"business_id\",\"score\",\"date\",\"type\"\n",
      "19,\"94\",\"20160513\",\"routine\"\n",
      "19,\"94\",\"20171211\",\"routine\"\n",
      "24,\"98\",\"20171101\",\"routine\"\n",
      "24,\"98\",\"20161005\",\"routine\"\n",
      "24,\"96\",\"20160311\",\"routine\"\n",
      "31,\"98\",\"20151204\",\"routine\"\n",
      "45,\"78\",\"20160104\",\"routine\"\n",
      "45,\"88\",\"20170307\",\"routine\"\n",
      "45,\"85\",\"20170914\",\"routine\"\n"
     ]
    }
   ],
   "source": [
    "!head data/inspections.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `head` displays the first 10 lines of a file. To display the last\n",
    "10 lines, we use the `tail`command. The final 10 lines in inspections.csv\n",
    "appear below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93959,\"100\",\"20171218\",\"routine\"\n",
      "93968,\"98\",\"20171120\",\"routine\"\n",
      "93969,\"98\",\"20171221\",\"routine\"\n",
      "93977,\"96\",\"20171219\",\"routine\"\n",
      "94012,\"100\",\"20171220\",\"routine\"\n",
      "94012,\"90\",\"20180112\",\"routine\"\n",
      "94133,\"100\",\"20171227\",\"routine\"\n",
      "94142,\"100\",\"20171220\",\"routine\"\n",
      "94189,\"96\",\"20171130\",\"routine\"\n",
      "94231,\"85\",\"20171214\",\"routine\"\n"
     ]
    }
   ],
   "source": [
    "!tail data/inspections.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the entire file’s contents using the `cat` command. However, you\n",
    "should take care when using this command, as printing a large file can cause\n",
    "the browser to crash. The legend.csv file is small, and we can use `cat` to\n",
    "concatenate and print its contents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Minimum_Score\",\"Maximum_Score\",\"Description\"\n",
      "0,70,\"Poor\"\n",
      "71,85,\"Needs Improvement\"\n",
      "86,90,\"Adequate\"\n",
      "91,100,\"Good\"\n"
     ]
    }
   ],
   "source": [
    "!cat data/legend.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases, using `head` and`tail` alone gives us a good enough sense of the\n",
    "file structure to proceed with loading it into a data frame. For example, we\n",
    "can see from the first 10 lines that the inspections.csv file uses the CSV\n",
    "format. Of course, we expect this format given file name extension is \".csv\",\n",
    "but as mentioned earlier, there is no guarantee that a file with this extension\n",
    "is indeed a CSV file. It's good practice to check the contents to confirm the\n",
    "extension matches the actual format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily read in CSV files using the pandas `pd.read_csv` command.\n",
    "But before we do that, let's look at the other two files restaurant inspection files:\n",
    "businesses.csv and violations.csv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"business_id\",\"date\",\"description\"\n",
      "19,\"20171211\",\"Inadequate food safety knowledge or lack of certified food safety manager\"\n",
      "19,\"20171211\",\"Unapproved or unmaintained equipment or utensils\"\n"
     ]
    }
   ],
   "source": [
    "# The -n 3 flag tells head to only display 3 lines\n",
    "!head -n 3 data/violations.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94571,\"THE PHOENIX PASTIFICIO\",\"200 CLEMENT ST \",\"San Francisco\",\"CA\",\"94118\",,,\"+14154726100\"\n",
      "94572,\"BROADWAY DIM SUM CAFE\",\"684 BROADWAY ST \",\"San Francisco\",\"CA\",\"94133\",,,\"\"\n",
      "94574,\"BINKA BITES\",\"2241 GEARY BLVD \",\"San Francisco\",\"CA\",\"94115\",,,\"+14157712907\"\n"
     ]
    }
   ],
   "source": [
    "!tail -n 3 data/businesses.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have confirmed all three files have CSV formats, we can \n",
    "read them into Pandas data frames with `pd.read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>score</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>94</td>\n",
       "      <td>20160513</td>\n",
       "      <td>routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>94</td>\n",
       "      <td>20171211</td>\n",
       "      <td>routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>98</td>\n",
       "      <td>20171101</td>\n",
       "      <td>routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14219</th>\n",
       "      <td>94142</td>\n",
       "      <td>100</td>\n",
       "      <td>20171220</td>\n",
       "      <td>routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14220</th>\n",
       "      <td>94189</td>\n",
       "      <td>96</td>\n",
       "      <td>20171130</td>\n",
       "      <td>routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14221</th>\n",
       "      <td>94231</td>\n",
       "      <td>85</td>\n",
       "      <td>20171214</td>\n",
       "      <td>routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14222 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       business_id  score      date     type\n",
       "0               19     94  20160513  routine\n",
       "1               19     94  20171211  routine\n",
       "2               24     98  20171101  routine\n",
       "...            ...    ...       ...      ...\n",
       "14219        94142    100  20171220  routine\n",
       "14220        94189     96  20171130  routine\n",
       "14221        94231     85  20171214  routine\n",
       "\n",
       "[14222 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insp = pd.read_csv(\"data/inspections.csv\")\n",
    "insp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>20171211</td>\n",
       "      <td>Inadequate food safety knowledge or lack of ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>20171211</td>\n",
       "      <td>Unapproved or unmaintained equipment or utensils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>20160513</td>\n",
       "      <td>Unapproved or unmaintained equipment or utensi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39039</th>\n",
       "      <td>94231</td>\n",
       "      <td>20171214</td>\n",
       "      <td>High risk vermin infestation  [ date violation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39040</th>\n",
       "      <td>94231</td>\n",
       "      <td>20171214</td>\n",
       "      <td>Moderate risk food holding temperature   [ dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39041</th>\n",
       "      <td>94231</td>\n",
       "      <td>20171214</td>\n",
       "      <td>Wiping cloths not clean or properly stored or ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39042 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       business_id      date  \\\n",
       "0               19  20171211   \n",
       "1               19  20171211   \n",
       "2               19  20160513   \n",
       "...            ...       ...   \n",
       "39039        94231  20171214   \n",
       "39040        94231  20171214   \n",
       "39041        94231  20171214   \n",
       "\n",
       "                                             description  \n",
       "0      Inadequate food safety knowledge or lack of ce...  \n",
       "1       Unapproved or unmaintained equipment or utensils  \n",
       "2      Unapproved or unmaintained equipment or utensi...  \n",
       "...                                                  ...  \n",
       "39039  High risk vermin infestation  [ date violation...  \n",
       "39040  Moderate risk food holding temperature   [ dat...  \n",
       "39041  Wiping cloths not clean or properly stored or ...  \n",
       "\n",
       "[39042 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viol = pd.read_csv(\"data/violations.csv\")\n",
    "viol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the businesses.csv file can't be immediately read into a \n",
    "dataframe. When we try to do so, we get this cryptic error:\n",
    "\n",
    "```\n",
    "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd1 in position 8: invalid continuation byte\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we'll need to learn more about this file's contents before we can successfully read\n",
    "it. We address this decoding problem later on in this section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's take another look at the shape of the inspections and violations \n",
    "dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14222, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39042, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viol.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `inspections` data frame has about 14,000 rows (and four\n",
    "columns), and `violations` has about 40,000 rows (and 3 columns). These files\n",
    "are large, but not so large that they cannot be easily read into Python. In the\n",
    "next section, we describe how to assess a file's size and what to do when it's\n",
    "too large to read into a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computers have finite limits on computing power. You have likely\n",
    "encountered these limits firsthand if your computer has slowed down from having\n",
    "too many applications opened at once. We often want to make sure that we do not\n",
    "exceed the computer's limits while working with data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many situations, we analyze datasets downloaded from the Internet. These\n",
    "files reside on the computer's **disk storage**. In order to use Python to\n",
    "explore and manipulate the data, we need to read the data into the computer's\n",
    "**memory**, also known as random access memory (RAM). All Python code requires\n",
    "the use of RAM, no matter how short the code is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A computer's RAM is typically much smaller than a computer's disk storage. For\n",
    "example, one computer model released in 2018 had 32 times more disk storage\n",
    "than RAM.  Unfortunately, this means that data files can often be much bigger\n",
    "than what is feasible to read into memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both disk storage and RAM capacity are measured in terms of **bytes**. Roughly\n",
    "speaking, each character in a text file adds one byte to the file's size. For\n",
    "example, the legends.csv file has 120 characters and takes up 120 bytes of\n",
    "disk space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, many of the datasets we work with today contain many characters. To\n",
    "succinctly describe the sizes of larger files, we use the prefixes as described\n",
    "in the following {numref}`byte-prefixes`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{table} Prefixes for common filesizes.\n",
    ":name: byte-prefixes\n",
    "\n",
    "| Multiple | Notation | Number of Bytes |\n",
    "| -------- | -------- | --------------- |\n",
    "| Kibibyte | KiB      | 1024    |\n",
    "| Mebibyte | MiB      | 1024²   |\n",
    "| Gibibyte | GiB      | 1024³   |\n",
    "| Tebibyte | TiB      | 1024⁴   |\n",
    "| Pebibyte | PiB      | 1024⁵   |\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, a file containing 52428800 characters takes up 52428800 bytes = 50\n",
    "mebibytes = 50 MiB on disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why use multiples of 1024 instead of simple multiples of 1000 for these\n",
    "prefixes?** This is a historical result of the fact that most computers\n",
    "use a binary number scheme where powers of 2 are simpler to represent. You will\n",
    "also see the typical SI prefixes used to describe size---kilobytes, megabytes,\n",
    "and gigabytes, for example. Unfortunately, these prefixes are used\n",
    "inconsistently. Sometimes a kilobyte refers to 1000 bytes; other times, a\n",
    "kilobyte refers to 1024 bytes. To avoid confusion, we will stick to kibi-,\n",
    "mebi-, and gibibytes which clearly represent multiples of 1024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When is it safe to read in a file?** Many computers have much more disk\n",
    "storage than available memory. It is not uncommon to have a data file happily\n",
    "stored on a computer that will overflow the computer's memory if we attempt to\n",
    "manipulate it with a program, including Python programs. We often begin our\n",
    "data work by making sure the files we are of manageable size. To accomplish\n",
    "this, we use the CLI tools `ls` and `wc` and `du`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that `ls` shows the files within a folder. If we add the `-l` flag, the\n",
    "output lists one file per line with additional metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "!ls -l data\n",
    "total 9496\n",
    "-rw-r--r--  1 sam  staff   645K Dec  6 15:05 businesses.csv\n",
    "-rw-r--r--  1 sam  staff   455K Dec  6 15:05 inspections.csv\n",
    "-rw-r--r--  1 sam  staff   120B Dec  6 15:05 legend.csv\n",
    "-rw-r--r--  1 sam  staff   3.6M Dec  6 15:05 violations.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, the fifth column of the listing shows the file size in bytes.\n",
    "For example, we can see that violations.csv takes up `3726206` bytes on disk.\n",
    "To make these file sizes more readable, we can use the `-h` flag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "!ls -lh data\n",
    "total 9496\n",
    "-rw-r--r--  1 sam  staff   645K Dec  6 15:05 businesses.csv\n",
    "-rw-r--r--  1 sam  staff   455K Dec  6 15:05 inspections.csv\n",
    "-rw-r--r--  1 sam  staff   120B Dec  6 15:05 legend.csv\n",
    "-rw-r--r--  1 sam  staff   3.6M Dec  6 15:05 violations.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that businesses.csv takes up 645 KiB on disk, making it well within the\n",
    "memory capacities of most systems. Although the violations.csv file takes up\n",
    "3.6 MiB of disk storage, most machines can easily read violations.csv into a\n",
    "Pandas dataframe too. A much larger file is DAWN-Data.txt, which stores the\n",
    "DAWN survey data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "!ls -lh DAWN-Data.txt\n",
    "rw-r--r--@ 1 sam staff 267M Dec 6 15:05 DAWN-Data.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file takes up 267 MiB of disk storage, and while some computers can work\n",
    "with it in memory, it might slow down most systems. The approach we have taken\n",
    "for working with these particular data is to reduce the number of features in\n",
    "the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command `wc` (short for wordcount), also provides helpful information about\n",
    "a file's size. This CLI tool returns the number of lines, words, and characters\n",
    "in the file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "!wc  DAWN-Data.txt\n",
    "229211 22695570 280095842 DAWN-Data.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Folder Sizes.** Sometimes we are interested in the total size of a folder\n",
    "instead of the size of individual files. For example, if we have one file of\n",
    "sensor recordings for each month in a year, we might like to see whether we can\n",
    "combine all the data into a single DataFrame. Note that `ls` does not calculate\n",
    "the cumulative size of the contents of a folder. To properly calculate the\n",
    "total size of a folder, including the files in the folder, we use the `du`\n",
    "(short for disk usage) CLI tool. By default, the `du` tool shows the sizes of\n",
    "folders in its own units called blocks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "!du data\n",
    "9496 data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show file sizes in bytes, we add the `-h` flag.\n",
    "\n",
    "```bash\n",
    "!du -h data\n",
    "4.6M\tdata\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We commonly also add the `-s` flag to `du` to show the file sizes for both\n",
    "files and folders. The asterisk in `data/*` below tells `du` to show the size\n",
    "of every item in the `data/*` folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "!du -sh data/*\n",
    "648K\tdata/businesses.csv\n",
    "456K\tdata/inspections.csv\n",
    "4.0K\tdata/legend.csv\n",
    "3.6M\tdata/violations.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Memory Overhead.** As a rule of thumb, reading in a file using `pandas`\n",
    "usually requires at least double the available memory as the file size. That\n",
    "is, reading in a 1 GiB file will typically require at least 2 GiB of available\n",
    "memory.\n",
    "\n",
    "Note that memory is shared by all programs running on a computer, including the\n",
    "operating system, web browsers, and yes, Jupyter notebook itself. A computer\n",
    "with 4 GiB total RAM might have only 1 GiB available RAM with many applications\n",
    "running. With 1 GiB available RAM, it is unlikely that `pandas` will be able to\n",
    "read in a 1 GiB file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the files that we have examined in this chapter are plain text files.\n",
    "Plain text, as you might guess, is simple and limited. It supports standard\n",
    "ASCII characters, which includes the upper and lowercase English letters,\n",
    "numbers, punctuation symbols, and spaces. In short, ASCII is a character\n",
    "**encoding**.\n",
    "\n",
    "However, the ASCII encoding is not sufficient to represent a lot\n",
    "of special characters and characters from other languages. Other, more modern,\n",
    "character encodings have many more characters that can be represented. Common\n",
    "encodings for documents and Web pages are Latin-1 (ISO-8859-1) and UTF-8. \n",
    "UTF-8 has over one million\n",
    "characters, and is backwards compatible with ASCII, meaning that it uses the\n",
    "same representation for English letters, numbers and punctuation as ASCII.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `file` CLI tool can help use determine a file's encoding. Earlier in\n",
    "this section, we had trouble reading the businesses.csv file, and were given an\n",
    "error message concerning decoding the information. The `file` tool uncovers the\n",
    "problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "!file -I data/*\n",
    "data/businesses.csv:  text/plain; charset=iso-8859-1\n",
    "data/inspections.csv: text/plain; charset=us-ascii\n",
    "data/legend.csv:      text/plain; charset=us-ascii\n",
    "data/violations.csv:  text/plain; charset=us-ascii\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the other three files are all ASCII, but businesses.csv has an\n",
    "ISO-8859-1 encoding. We can provide this information to `pandas.read_csv` to\n",
    "successfully read the business information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>phone_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>NRGIZE LIFESTYLE CAFE</td>\n",
       "      <td>1200 VAN NESS AVE, 3RD FLOOR</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>...</td>\n",
       "      <td>94109</td>\n",
       "      <td>37.79</td>\n",
       "      <td>-122.42</td>\n",
       "      <td>+14157763262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>OMNI S.F. HOTEL - 2ND FLOOR PANTRY</td>\n",
       "      <td>500 CALIFORNIA ST, 2ND  FLOOR</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>...</td>\n",
       "      <td>94104</td>\n",
       "      <td>37.79</td>\n",
       "      <td>-122.40</td>\n",
       "      <td>+14156779494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>NORMAN'S ICE CREAM AND FREEZES</td>\n",
       "      <td>2801 LEAVENWORTH ST</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>...</td>\n",
       "      <td>94133</td>\n",
       "      <td>37.81</td>\n",
       "      <td>-122.42</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6403</th>\n",
       "      <td>94571</td>\n",
       "      <td>THE PHOENIX PASTIFICIO</td>\n",
       "      <td>200 CLEMENT ST</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>...</td>\n",
       "      <td>94118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+14154726100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>94572</td>\n",
       "      <td>BROADWAY DIM SUM CAFE</td>\n",
       "      <td>684 BROADWAY ST</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>...</td>\n",
       "      <td>94133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6405</th>\n",
       "      <td>94574</td>\n",
       "      <td>BINKA BITES</td>\n",
       "      <td>2241 GEARY BLVD</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>...</td>\n",
       "      <td>94115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+14157712907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6406 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      business_id                                name  \\\n",
       "0              19               NRGIZE LIFESTYLE CAFE   \n",
       "1              24  OMNI S.F. HOTEL - 2ND FLOOR PANTRY   \n",
       "2              31      NORMAN'S ICE CREAM AND FREEZES   \n",
       "...           ...                                 ...   \n",
       "6403        94571              THE PHOENIX PASTIFICIO   \n",
       "6404        94572               BROADWAY DIM SUM CAFE   \n",
       "6405        94574                         BINKA BITES   \n",
       "\n",
       "                            address           city  ... postal_code latitude  \\\n",
       "0      1200 VAN NESS AVE, 3RD FLOOR  San Francisco  ...       94109    37.79   \n",
       "1     500 CALIFORNIA ST, 2ND  FLOOR  San Francisco  ...       94104    37.79   \n",
       "2              2801 LEAVENWORTH ST   San Francisco  ...       94133    37.81   \n",
       "...                             ...            ...  ...         ...      ...   \n",
       "6403                200 CLEMENT ST   San Francisco  ...       94118      NaN   \n",
       "6404               684 BROADWAY ST   San Francisco  ...       94133      NaN   \n",
       "6405               2241 GEARY BLVD   San Francisco  ...       94115      NaN   \n",
       "\n",
       "      longitude  phone_number  \n",
       "0       -122.42  +14157763262  \n",
       "1       -122.40  +14156779494  \n",
       "2       -122.42           NaN  \n",
       "...         ...           ...  \n",
       "6403        NaN  +14154726100  \n",
       "6404        NaN           NaN  \n",
       "6405        NaN  +14157712907  \n",
       "\n",
       "[6406 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus = pd.read_csv('data/businesses.csv', encoding='ISO-8859-1')\n",
    "bus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we have introduced the command-line tools `ls`, `du`, `wc`,\n",
    "`head`, `tail`, `cat`and `file`. These tools help us understand the format and\n",
    "structure of data files. We also use these tools to ensure that the data file\n",
    "is small enough to read into `pandas` and that the correct encoding is used so\n",
    "that values are not gibberish. Once a file is read into `pandas`, we have a\n",
    "dataframe and can proceed with analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shell commands give us a programmatic way to work with files, rather than a\n",
    "point-and-click \"manual\" approach. They are useful for:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Documentation: if you need to record what you did\n",
    "- Error reduction: if you want to reduce typographical errors and other simple\n",
    "  but potentially harmful mistakes\n",
    "- Reproducibility: if you need to repeat the same process in the future or you\n",
    "  plan to share your process with others you have a record of your actions\n",
    "- Volume: if you have many repetitive operations to perform, the size of the\n",
    "  file you are working with is large, or you need to perform things quickly,\n",
    "  CLI tools can help.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data are in a pandas data frame, our next task is to get a handle on\n",
    "the table's shape and granularity. We need to understand what a row represents\n",
    "and the expected kind of values in a field before we can begin to check the\n",
    "quality of the data. This is the topic of the next section.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
