
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>15.4. Least Squares — A Geometric Perspective &#8212; Principles and Techniques of Data Science</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/custom.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="16. Probability and Generalization" href="../16/prob_and_gen.html" />
    <link rel="prev" title="15.3. [In progress] Inference for Linear Regression" href="linear_inference.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-113006011-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Principles and Techniques of Data Science</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Frontmatter
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../preface.html">
   To the Reader
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prereqs.html">
   Prerequisites
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../notation.html">
   Notation
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  The Data Science Lifecycle
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01/lifecycle_intro.html">
   1. The Data Science Lifecycle
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_students_1.html">
     1.1. The Students of Data 100
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_students_2.html">
     1.2. Exploratory Data Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_students_3.html">
     1.3. What’s in a Name?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02/data_scope_intro.html">
   2. Data Scope
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_big_data_hubris.html">
     2.1. Big Data and New Opportunities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_construct.html">
     2.2. Target Population, Access Frame, Sample
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_protocols.html">
     2.3. Instruments and Protocols
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_natural.html">
     2.4. Measuring Natural Phenomenon
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_accuracy.html">
     2.5. Accuracy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_summary.html">
     2.6. Summary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_exercises.html">
     2.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03/theory_intro.html">
   3. Simulation and Data Design
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/theory_urn.html">
     3.1. The Urn Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/theory_election.html">
     3.2. Simulating Election Polls: Bias, Variance, and Big Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/theory_vaccine_efficacy.html">
     3.3. Simulating a Randomized Trial: Vaccine Efficacy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/theory_measurement_error.html">
     3.4. Measurement Error: Air Quality Variation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/theory_summary.html">
     3.5. Summary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/theory_exercises.html">
     3.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04/modeling_intro.html">
   4. Modeling and Estimation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/modeling_simple.html">
     4.1. Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/modeling_loss_functions.html">
     4.2. Loss Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/modeling_abs_huber.html">
     4.3. Absolute and Huber Loss
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../05/cycle_case_study_intro.html">
   5. [In progress] Case Study
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Rectangular Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../06/pandas_intro.html">
   6. Working With Dataframes Using pandas
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_subsetting.html">
     6.1. Subsetting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_aggregating.html">
     6.2. Aggregating
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_joining.html">
     6.3. Joining
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_transforming.html">
     6.4. Transforming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_other_reps.html">
     6.5. How are Dataframes Different from Other Data Representations?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_conclusion.html">
     6.6. Conclusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_exercises.html">
     6.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../07/sql_intro.html">
   7. Working With Relations Using SQL
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_subsetting.html">
     7.1. Subsetting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_aggregating.html">
     7.2. Aggregating
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_joining.html">
     7.3. Joining
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_transforming.html">
     7.4. Transforming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_other_reps.html">
     7.5. How are Relations Different from Other Data Representations?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_conclusion.html">
     7.6. Conclusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_exercises.html">
     7.7. Exercises
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Understanding The Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08/files_intro.html">
   8. Wrangling Files
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_datasets.html">
     8.1. Data Source Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_formats.html">
     8.2. File Formats
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_size.html">
     8.3. File Size
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_command_line.html">
     8.4. The Shell and Command Line Tools
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_granularity.html">
     8.5. Table Shape and Granularity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_summary.html">
     8.6. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../09/wrangling_intro.html">
   9. Wrangling Dataframes
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_co2.html">
     9.1. Example: Wrangling CO2 Measurements from Mauna Loa Observatory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_checks.html">
     9.2. Quality Checks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_missing.html">
     9.3. Missing Values and Records
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_transformations.html">
     9.4. Transformations and Timestamps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_structure.html">
     9.5. Modifying Structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_restaurants.html">
     9.6. Example: Wrangling Restaurant Safety Violations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_summary.html">
     9.7. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../10/eda_intro.html">
   10. Exploratory Data Analysis
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_feature_types.html">
     10.1. Feature Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_distributions.html">
     10.2. What to Look For in a Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_relationships.html">
     10.3. What to Look For in a Relationship?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_guidelines.html">
     10.4. Guidelines for Exploration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_example.html">
     10.5. Example: Sale Prices for Houses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_summary.html">
     10.6. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../11/viz_intro.html">
   11. Data Visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_scale.html">
     11.1. Choosing Scale to Reveal Structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_smoothing.html">
     11.2. Smoothing and Aggregating Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_comparisons.html">
     11.3. Facilitating Meaningful Comparisons
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_data_design.html">
     11.4. Incorporating the Data Design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_context.html">
     11.5. Adding Context
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_plotly.html">
     11.6. Creating Plots Using
     <code class="docutils literal notranslate">
      <span class="pre">
       plotly
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_other_tools.html">
     11.7. Other Tools for Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_summary.html">
     11.8. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../12/pa_intro.html">
   12. Case Study: Data Science for Accurate and Timely Air Quality Measurements
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_collocated.html">
     12.1. Finding Collocated Sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_cleaning_aqs.html">
     12.2. Exploring and Cleaning AQS Sensor Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_cleaning_purpleair.html">
     12.3. Exploring and Cleaning PurpleAir Sensor Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_modeling.html">
     12.4. Creating a Model to Correct PurpleAir Measurements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_conclusion.html">
     12.5. In Conclusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_exercises.html">
     12.6. Exercises
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Other Data Sources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../13/text_intro.html">
   13. Working with Text
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/text_strings.html">
     13.1. Python String Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/text_regex.html">
     13.2. Regular Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/text_re.html">
     13.3. Regex and Python
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../14/web_intro.html">
   14. Web Technologies
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/web_http.html">
     14.1. HTTP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/web_rest.html">
     14.2. [In Progress] REST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/web_html.html">
     14.3. [In Progress] XPath and HTML
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Linear Modeling
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="linear_models.html">
   15. Linear Models
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="linear_tips.html">
     15.1. Predicting Tip Amounts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="linear_fitting.html">
     15.2. [In progress] Fitting a linear model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="linear_inference.html">
     15.3. [In progress] Inference for Linear Regression
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     15.4. Least Squares — A Geometric Perspective
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../16/prob_and_gen.html">
   16. Probability and Generalization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/prob_random_vars.html">
     16.1. Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/prob_exp_var.html">
     16.2. Expectation and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/prob_risk.html">
     16.3. Risk
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../17/gradient_descent.html">
   17. Gradient Descent and Numerical Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/gradient_basics.html">
     17.1. Loss Minimization Using a Program
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/gradient_descent_define.html">
     17.2. Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/gradient_convexity.html">
     17.3. Convexity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/gradient_stochastic.html">
     17.4. Stochastic Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/gradient_lin_reg.html">
     17.5. Fitting a Linear Model Using Gradient Descent
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../18/donkey_intro.html">
   18. [In progress] Case Study: Donkey Dimensions
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../18/donkey_analysis.html">
     18.1. Linear Regression Case Study
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Multiple Linear Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../19/mult_intro.html">
   19. [In progress] Multiple Linear Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/mult_model.html">
     19.1. Multiple Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/mult_inference.html">
     19.2. Inference for Multiple Linear Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../20/feature_engineering.html">
   20. Feature Engineering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/feature_one_hot.html">
     20.1. The Walmart dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/feature_polynomial.html">
     20.2. Predicting Ice Cream Ratings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../21/bias_intro.html">
   21. The Bias-Variance Tradeoff
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../21/bias_risk.html">
     21.1. Risk and Loss Minimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../21/bias_modeling.html">
     21.2. Model Bias and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../21/bias_cv.html">
     21.3. Cross-Validation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../22/reg_intro.html">
   22. Regularization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
  <label for="toctree-checkbox-21">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../22/reg_intuition.html">
     22.1. Regularization Intuition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../22/reg_ridge.html">
     22.2. L2 Regularization: Ridge Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../22/reg_lasso.html">
     22.3. L1 Regularization: Lasso Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../23/mult_case_intro.html">
   23. [In progress] Case Study: Multiple Linear Models
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Classification
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../24/classification_intro.html">
   24. Classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/classification_prob.html">
     24.1. Regression on Probabilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/classification_log_model.html">
     24.2. The Logistic Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/classification_cost.html">
     24.3. A Loss Function for the Logistic Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/classification_log_reg.html">
     24.4. Using Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/classification_cost_justification.html">
     24.5. Approximating the Empirical Probability Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/classification_sgd.html">
     24.6. Fitting a Logistic Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/classification_sensitivity_specificity.html">
     24.7. Evaluating Logistic Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/classification_multiclass.html">
     24.8. Multiclass Classification
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Replicability
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../25/repl_intro.html">
   25. [In progress] Replicable Research
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../25/repl_phacking.html">
     25.1. P-hacking
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Extra Topics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../26/pca_intro.html">
   26. Dimensionality Reduction and PCA
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
  <label for="toctree-checkbox-24">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../26/pca_dims.html">
     26.1. Dimensions of a Data Table
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../26/pca_svd.html">
     26.2. PCA using the Singular Value Decomposition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../26/pca_in_practice.html">
     26.3. PCA in Practice
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../27/dtrees_intro.html">
   27. [In progress] Decision Trees and Random Forests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../28/clustering_intro.html">
   28. [In progress] Clustering
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Appendices
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../a01/prob_review.html">
   Probability Review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../a02/vector_space_review.html">
   Vector Space Review
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../a03/hyp_intro.html">
   Statistical Inference Review
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
  <label for="toctree-checkbox-25">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../a03/hyp_introduction.html">
     Hypothesis Testing and Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a03/hyp_introduction_part2.html">
     Permutation Test
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../a04/ref_intro.html">
   Reference Tables
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
  <label for="toctree-checkbox-26">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_pandas.html">
     pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_seaborn.html">
     Seaborn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_matplotlib.html">
     matplotlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_sklearn.html">
     scikit-learn
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../a05/contributors.html">
   Contributors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../references.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/ch/15/linear_projection.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        <a class="jupyterhub-button" href="https://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/ds-100/textbook&urlpath=tree/textbook/content/ch/15/linear_projection.ipynb&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#least-squares-constant-model">
   15.4.1. Least Squares: Constant Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#least-squares-simple-linear-model">
   15.4.2. Least Squares: Simple Linear Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#geometric-intuition">
   15.4.3. Geometric Intuition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-algebra">
   15.4.4. Linear Algebra
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#finishing-up-the-case-study">
   15.4.5. Finishing up the Case Study
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#when-variables-are-linearly-dependent">
   15.4.6. When Variables are Linearly Dependent
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#two-schools-of-thought">
   15.4.7. Two Schools of Thought
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Least Squares — A Geometric Perspective</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#least-squares-constant-model">
   15.4.1. Least Squares: Constant Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#least-squares-simple-linear-model">
   15.4.2. Least Squares: Simple Linear Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#geometric-intuition">
   15.4.3. Geometric Intuition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-algebra">
   15.4.4. Linear Algebra
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#finishing-up-the-case-study">
   15.4.5. Finishing up the Case Study
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#when-variables-are-linearly-dependent">
   15.4.6. When Variables are Linearly Dependent
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#two-schools-of-thought">
   15.4.7. Two Schools of Thought
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="c1"># Ignore numpy dtype warnings. These warnings are caused by an interaction</span>
<span class="c1"># between numpy and Cython and can be safely ignored.</span>
<span class="c1"># Reference: https://stackoverflow.com/a/40846742</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;numpy.dtype size changed&quot;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;numpy.ufunc size changed&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">interact_manual</span>
<span class="kn">import</span> <span class="nn">nbinteract</span> <span class="k">as</span> <span class="nn">nbi</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s1">&#39;talk&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_columns</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="c1"># This option stops scientific notation for pandas</span>
<span class="c1"># pd.set_option(&#39;display.float_format&#39;, &#39;{:.2f}&#39;.format)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="least-squares-a-geometric-perspective">
<h1><span class="section-number">15.4. </span>Least Squares — A Geometric Perspective<a class="headerlink" href="#least-squares-a-geometric-perspective" title="Permalink to this headline">¶</a></h1>
<p>Recall that we found the optimal coefficients for linear models by optimizing their loss functions with gradient descent. We also mentioned that least squares linear regression can be solved analytically. While gradient descent is practical, this geometric perspective will provide a deeper understanding of linear regression.</p>
<p>A Vector Space Review is included in the Appendix. We will assume familiarity with vector arithmetic, the 1-vector, span of a collection of vectors, and projections.</p>
<p>Suppose we seek a linear model for this data:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>x</p></th>
<th class="head"><p>y</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>3</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd"><td><p>0</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p>-1</p></td>
<td><p>-2</p></td>
</tr>
</tbody>
</table>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
    <span class="p">],</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">ci</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fit_reg</span><span class="o">=</span><span class="kc">False</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/linear_projection_5_0.png" src="../../_images/linear_projection_5_0.png" />
</div>
</div>
<p>Assume that the best model is one with the least error, and that the least squares error is an acceptable measure.</p>
<div class="section" id="least-squares-constant-model">
<h2><span class="section-number">15.4.1. </span>Least Squares: Constant Model<a class="headerlink" href="#least-squares-constant-model" title="Permalink to this headline">¶</a></h2>
<p>Like we did with the tips dataset, let’s start with the constant model: the model that only ever predicts a single number.</p>
<div class="math notranslate nohighlight">
\[ \theta = C\]</div>
<p>Thus, we are working with just the <span class="math notranslate nohighlight">\(y\)</span>-values.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>y</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>2</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
</tr>
<tr class="row-even"><td><p>-2</p></td>
</tr>
</tbody>
</table>
<p>Our goal is to find the <span class="math notranslate nohighlight">\( \theta \)</span> that results in the line that minimizes the squared loss:</p>
<div class="math notranslate nohighlight">
\[\begin{split} L(\theta, \textbf{y}) = \sum_{i = 1}^{n}(y_i - \theta)^2\\ \end{split}\]</div>
<p>Recall that for the constant model, the minimizing <span class="math notranslate nohighlight">\(\theta\)</span> for MSE is <span class="math notranslate nohighlight">\(\bar{\textbf{y}}\)</span>, the average of the <span class="math notranslate nohighlight">\(\textbf{y}\)</span> values. The calculus derivation can be found in the Loss Functions lesson in the Modeling and Estimations chapter. For the linear algebra derivation, please refer to the Vector Space Review in the Appendix.</p>
<p>Notice that our loss function is a sum of squares. The <em>L2</em>-norm for a vector is also a sum of squares, but with a square root:</p>
<div class="math notranslate nohighlight">
\[\Vert \textbf{v} \Vert = \sqrt{v_1^2 + v_2^2 + \dots + v_n^2}\]</div>
<p>If we let <span class="math notranslate nohighlight">\(y_i - \theta = v_i\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
L(\theta, \textbf{y}) 
&amp;= v_1^2 + v_2^2 + \dots + v_n^2 \\
&amp;= \Vert \textbf{v} \Vert^2
\end{aligned}
\end{split}\]</div>
<p>This means our loss can be expressed as the <em>L2</em>-norm of some vector <span class="math notranslate nohighlight">\(\textbf{v}\)</span>, squared. We can express <span class="math notranslate nohighlight">\(v_i\)</span> as <span class="math notranslate nohighlight">\(y_i - \theta \quad \forall i \in [1,n]\)</span> so that in Cartesian notation,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\textbf{v} \quad &amp;= \quad \begin{bmatrix} y_1 - \theta \\ y_2 - \theta \\ \vdots \\ y_n - \theta \end{bmatrix} \\
&amp;= \quad \begin{bmatrix} y_1 \\ y_2 \\ \vdots \\ y_n  \end{bmatrix} \quad - \quad 
\begin{bmatrix} \theta \\ \theta \\ \vdots \\ \theta \end{bmatrix} \\
&amp;= \quad \begin{bmatrix} y_1 \\ y_2 \\ \vdots \\ y_n  \end{bmatrix} \quad - \quad 
\theta \begin{bmatrix} 1 \\ 1 \\ \vdots \\ 1 \end{bmatrix}
\end{aligned}
\end{split}\]</div>
<p>So our loss function can be written as:</p>
<div class="math notranslate nohighlight">
\[\begin{split} 
\begin{aligned}
L(\theta, \textbf{y})
\quad &amp;= \quad \left \Vert  \qquad   
\begin{bmatrix} y_1 \\ y_2 \\ \vdots \\ y_n  \end{bmatrix} \quad - \quad 
\theta \begin{bmatrix} 1 \\ 1 \\ \vdots \\ 1 \end{bmatrix}
\qquad \right \Vert ^2 \\
\quad &amp;= \quad \left \Vert  \qquad  
\textbf{y} 
\quad - \quad 
\hat{\textbf{y}}
\qquad \right \Vert ^2 \\
\end{aligned}
\end{split}\]</div>
<p>The expression <span class="math notranslate nohighlight">\(\theta \begin{bmatrix} 1 \\ 1 \\ \vdots \\ 1 \end{bmatrix}\)</span>  is a scalar multiple of the columns of the <span class="math notranslate nohighlight">\(\textbf{1}\)</span> vector, and is the result of our predictions, denoted <span class="math notranslate nohighlight">\(\hat{\textbf{y}}\)</span>.</p>
<p>This gives us a new perspective on what it means to minimize the least squares error.</p>
<p><span class="math notranslate nohighlight">\(\textbf{y}\)</span> and <span class="math notranslate nohighlight">\(\textbf{1}\)</span> are fixed, but <span class="math notranslate nohighlight">\(\theta\)</span> can take on any value, so <span class="math notranslate nohighlight">\(\hat{\textbf{y}}\)</span> can be any scalar multiple of <span class="math notranslate nohighlight">\(\textbf{1}\)</span>. We want to find <span class="math notranslate nohighlight">\(\theta\)</span> so that <span class="math notranslate nohighlight">\( \theta \textbf{1} \)</span> is as close to <span class="math notranslate nohighlight">\(\textbf{y}\)</span> as possible. We use <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> to denote this best-fit <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<a class="reference internal image-reference" href="../../_images/1dprojection.png"><img alt="1dprojection.png" class="align-center" src="../../_images/1dprojection.png" style="width: 300px;" /></a>
<p>The projection of <span class="math notranslate nohighlight">\(\textbf{y}\)</span> onto <span class="math notranslate nohighlight">\(\textbf{1}\)</span> is guaranteed to be the closest vector (see “Vector Space Review” in the Appendix).</p>
</div>
<div class="section" id="least-squares-simple-linear-model">
<h2><span class="section-number">15.4.2. </span>Least Squares: Simple Linear Model<a class="headerlink" href="#least-squares-simple-linear-model" title="Permalink to this headline">¶</a></h2>
<p>Now, let’s look at the simple linear regression model. This is strongly parallel to the constant model derivation, but be mindful of the differences and think about how you might generalize to multiple linear regression.</p>
<p>The simple linear model is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_\boldsymbol\theta (x_i) 
&amp;= \theta_0 + \theta_1 x_i \\
\end{aligned}
\end{split}\]</div>
<p>Our goal is to find the <span class="math notranslate nohighlight">\(\boldsymbol\theta\)</span> that results in the line with the least squared error:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
L(\boldsymbol\theta, \textbf{x}, \textbf{y})
&amp;= \sum_{i = 1}^{n}(y_i - f_\boldsymbol\theta (x_i))^2\\
&amp;= \sum_{i = 1}^{n}(y_i - \theta_0 - \theta_1 x_i)^2\\
&amp;= \sum_{i = 1}^{n}(y_i - \begin{bmatrix} 1 &amp; x_i \end{bmatrix}
\begin{bmatrix} 
     \theta_0 \\
     \theta_1
\end{bmatrix} ) ^2
\end{aligned}
\end{split}\]</div>
<p>To help us visualize the translation of our loss summation into matrix form, let’s expand out the loss with <span class="math notranslate nohighlight">\(n = 3\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
L(\boldsymbol{\theta}, \textbf{x}, \textbf{y})
&amp;=
(y_1 - \begin{bmatrix} 1 &amp; x_1 \end{bmatrix}
\begin{bmatrix} 
     \theta_0 \\
     \theta_1
\end{bmatrix})^2  \\
&amp;+
(y_2 - \begin{bmatrix} 1 &amp; x_2 \end{bmatrix}
\begin{bmatrix} 
     \theta_0 \\
     \theta_1
\end{bmatrix})^2 \\
&amp;+
(y_3 - \begin{bmatrix} 1 &amp; x_3 \end{bmatrix}
\begin{bmatrix} 
     \theta_0 \\
     \theta_1
\end{bmatrix})^2 \\
\end{aligned}
\end{split}\]</div>
<p>Again, our loss function is a sum of squares and the <em>L2</em>-norm for a vector is the square root of a sum of squares:</p>
<div class="math notranslate nohighlight">
\[\Vert \textbf{v} \Vert = \sqrt{v_1^2 + v_2^2 + \dots + v_n^2}\]</div>
<p>If we let $y_i - \begin{bmatrix} 1 &amp; x_i \end{bmatrix}</p>
<div class="amsmath math notranslate nohighlight" id="equation-b3685877-591f-4e3b-b9aa-54b53db5b3f7">
<span class="eqno">(15.1)<a class="headerlink" href="#equation-b3685877-591f-4e3b-b9aa-54b53db5b3f7" title="Permalink to this equation">¶</a></span>\[\begin{bmatrix} 
     \theta_0 \\
     \theta_1
\end{bmatrix}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
L(\boldsymbol{\theta}, \textbf{x}, \textbf{y}) 
&amp;= v_1^2 + v_2^2 + \dots + v_n^2 \\
&amp;= \Vert \textbf{v} \Vert^2
\end{aligned}
\end{split}\]</div>
<p>As before, our loss can be expressed as the <em>L2</em>-norm of some vector <span class="math notranslate nohighlight">\(\textbf{v}\)</span>, squared. With each component $v_i = y_i - \begin{bmatrix} 1 &amp; x_i \end{bmatrix}</p>
<div class="amsmath math notranslate nohighlight" id="equation-2ebb981e-e9f7-40c3-b8f2-5f2bd83a8f08">
<span class="eqno">(15.2)<a class="headerlink" href="#equation-2ebb981e-e9f7-40c3-b8f2-5f2bd83a8f08" title="Permalink to this equation">¶</a></span>\[\begin{bmatrix} 
     \theta_0 \\
     \theta_1
\end{bmatrix}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split} 
\begin{aligned}
L(\boldsymbol{\theta}, \textbf{x}, \textbf{y})
&amp;= \left \Vert  \qquad   
\begin{bmatrix} y_1 \\ y_2 \\ y_3  \end{bmatrix} \quad - \quad 
\begin{bmatrix} 1 &amp; x_1 \\ 1 &amp; x_2 \\ 1 &amp; x_3 \end{bmatrix}
\begin{bmatrix} 
     \theta_0 \\
     \theta_1
\end{bmatrix}
\qquad \right \Vert ^2 \\
&amp;= \left \Vert  \qquad  
\textbf{y} 
\quad - \quad 
\textbf{X}
\begin{bmatrix} 
     \theta_0 \\
     \theta_1
\end{bmatrix}
\qquad \right \Vert ^2 \\
&amp;= \left \Vert  \qquad  
\textbf{y} 
\quad - \quad 
f_\boldsymbol\theta(\textbf{x})
\qquad \right \Vert ^2 \\
&amp;= \left \Vert  \qquad  
\textbf{y} 
\quad - \quad 
\hat{\textbf{y}}
\qquad \right \Vert ^2 \\
\end{aligned}
\end{split}\]</div>
<p>The matrix multiplication $\begin{bmatrix} 1 &amp; x_1 \ 1 &amp; x_2 \ 1 &amp; x_3 \end{bmatrix}</p>
<div class="amsmath math notranslate nohighlight" id="equation-7c0c8b2d-c140-42e5-92c3-05baa750c52a">
<span class="eqno">(15.3)<a class="headerlink" href="#equation-7c0c8b2d-c140-42e5-92c3-05baa750c52a" title="Permalink to this equation">¶</a></span>\[\begin{bmatrix} 
     \theta_0 \\
     \theta_1
\end{bmatrix}\]</div>
<p><span class="math notranslate nohighlight">\(\textbf{X}\)</span> and <span class="math notranslate nohighlight">\(\textbf{y}\)</span> are fixed, but <span class="math notranslate nohighlight">\(\theta_0\)</span> and <span class="math notranslate nohighlight">\(\theta_1\)</span> can take on any value, so <span class="math notranslate nohighlight">\(\hat{\textbf{y}}\)</span> can take on any of the infinite linear combinations of the columns of <span class="math notranslate nohighlight">\(\textbf{X}\)</span>. To have the smallest loss, we want to choose <span class="math notranslate nohighlight">\(\boldsymbol\theta\)</span> such that <span class="math notranslate nohighlight">\(\hat{\textbf{y}}\)</span> is as close to <span class="math notranslate nohighlight">\(\textbf{y}\)</span> as possibled, denoted as <span class="math notranslate nohighlight">\(\hat{\boldsymbol\theta}\)</span>.</p>
</div>
<div class="section" id="geometric-intuition">
<h2><span class="section-number">15.4.3. </span>Geometric Intuition<a class="headerlink" href="#geometric-intuition" title="Permalink to this headline">¶</a></h2>
<p>Now, let’s develop an intuition for why it matters that <span class="math notranslate nohighlight">\(\hat{\textbf{y}}\)</span> is restricted to the linear combinations of the columns of <span class="math notranslate nohighlight">\(\textbf{X}\)</span>. Although the span of any set of vectors includes an infinite number of linear combinations, infinite does not mean any—the linear combinations are restricted by the basis vectors.</p>
<p>As a reminder, here is our loss function and scatter plot:</p>
<div class="math notranslate nohighlight">
\[L(\boldsymbol{\theta}, \textbf{x}, \textbf{y}) \quad = \quad \left \Vert  \quad  
\textbf{y} 
\quad - \quad 
\textbf{X} \boldsymbol\theta
\quad \right \Vert ^2\]</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">ci</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fit_reg</span><span class="o">=</span><span class="kc">False</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/linear_projection_19_0.png" src="../../_images/linear_projection_19_0.png" />
</div>
</div>
<p>By inspecting our scatter plot, we see that no line can perfectly fit our points, so we cannot achieve 0 loss. Thus, we know that <span class="math notranslate nohighlight">\(\textbf{y}\)</span> is not in the plane spanned by <span class="math notranslate nohighlight">\(\textbf{x}\)</span> and <span class="math notranslate nohighlight">\(\textbf{1}\)</span>, represented as a parallelogram below.</p>
<a class="reference internal image-reference" href="../../_images/proj1.png"><img alt="proj1.png" class="align-center" src="../../_images/proj1.png" style="width: 500px;" /></a>
<p>Since our loss is distance-based, we can see that to minimize <span class="math notranslate nohighlight">\( L(\boldsymbol\theta, \textbf{x}, \textbf{y}) = \left \Vert  \textbf{y} - \textbf{X} \boldsymbol\theta \right \Vert ^2\)</span>, we want <span class="math notranslate nohighlight">\(\textbf{X} \boldsymbol\theta\)</span> to be as close to <span class="math notranslate nohighlight">\(\textbf{y}\)</span> as possible.</p>
<p>Mathematically, we are looking for the projection of <span class="math notranslate nohighlight">\(\textbf{y}\)</span> onto the vector space spanned by the columns of <span class="math notranslate nohighlight">\(\textbf{X}\)</span>, as the projection of any vector is the closest point in <span class="math notranslate nohighlight">\(Span(\textbf{X})\)</span> to that vector. Thus, choosing <span class="math notranslate nohighlight">\(\boldsymbol\theta\)</span> such that <span class="math notranslate nohighlight">\(\hat{\textbf{y}} = \textbf{X} \boldsymbol\theta= \)</span> proj<span class="math notranslate nohighlight">\(_{Span(\textbf{X})} \)</span> <span class="math notranslate nohighlight">\(\textbf{y}\)</span> is the best solution.</p>
<a class="reference internal image-reference" href="../../_images/proj2.png"><img alt="proj2.png" class="align-center" src="../../_images/proj2.png" style="width: 500px;" /></a>
<p>To see why, consider other points on the vector space, in purple.</p>
<a class="reference internal image-reference" href="../../_images/proj3.png"><img alt="proj3.png" class="align-center" src="../../_images/proj3.png" style="width: 500px;" /></a>
<p>By the Pythagorean Theorem, any other point on the plane is farther from <span class="math notranslate nohighlight">\(\textbf{y}\)</span> than <span class="math notranslate nohighlight">\(\hat{\textbf{y}}\)</span> is. The length of the perpendicular corresponding to <span class="math notranslate nohighlight">\(\hat{\textbf{y}}\)</span> represents the least squared error.</p>
</div>
<div class="section" id="linear-algebra">
<h2><span class="section-number">15.4.4. </span>Linear Algebra<a class="headerlink" href="#linear-algebra" title="Permalink to this headline">¶</a></h2>
<p>Since we’ve snuck in a lot of linear algebra concepts already, all that’s left is solving for the <span class="math notranslate nohighlight">\(\hat{\boldsymbol\theta}\)</span> that yields our desired <span class="math notranslate nohighlight">\(\hat{\textbf{y}}\)</span>.</p>
<p>A couple things to note:</p>
<a class="reference internal image-reference" href="../../_images/proj4.png"><img alt="proj4.png" class="align-center" src="../../_images/proj4.png" style="width: 500px;" /></a>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{\textbf{y}} + \textbf{e} = \textbf{y}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\textbf{e}\)</span> is perpendicular to <span class="math notranslate nohighlight">\(\textbf{x}\)</span> and <span class="math notranslate nohighlight">\(\textbf{1}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{\textbf{y}} = \textbf{X} \hat{\boldsymbol\theta}\)</span> is the vector closest to <span class="math notranslate nohighlight">\(\textbf{y}\)</span> in the vector space spanned by <span class="math notranslate nohighlight">\(\textbf{x}\)</span> and <span class="math notranslate nohighlight">\(\textbf{1}\)</span></p></li>
</ul>
<p>Thus, we arrive at the equation:</p>
<div class="math notranslate nohighlight">
\[\textbf{X}  \hat{\boldsymbol\theta} + \textbf{e} = \textbf{y}\]</div>
<p>Left-multiplying both sides by <span class="math notranslate nohighlight">\(\textbf{X}^T\)</span>:</p>
<div class="math notranslate nohighlight">
\[\textbf{X}^T \textbf{X}  \hat{\boldsymbol\theta} + \textbf{X}^T \textbf{e} = \textbf{X}^T \textbf{y}\]</div>
<p>Since <span class="math notranslate nohighlight">\(\textbf{e}\)</span> is perpendicular to the columns of <span class="math notranslate nohighlight">\(\textbf{X}\)</span>, <span class="math notranslate nohighlight">\(\textbf{X}^T \textbf{e}\)</span> is a column vector of <span class="math notranslate nohighlight">\(0\)</span>’s. Thus, we arrive at the Normal Equation:</p>
<div class="math notranslate nohighlight">
\[\textbf{X}^T \textbf{X}  \hat{\boldsymbol\theta} = \textbf{X}^T \textbf{y}\]</div>
<p>From here, we can easily solve for <span class="math notranslate nohighlight">\(\hat{\boldsymbol\theta}\)</span> by left-multiplying both sides by <span class="math notranslate nohighlight">\((\textbf{X}^T \textbf{X})^{-1}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\hat{\boldsymbol\theta} = (\textbf{X}^T \textbf{X})^{-1} \textbf{X}^T \textbf{y}\]</div>
<p>Note: we can get this same solution by minimizing with vector calculus, but in the case of least squares loss, vector calculus isn’t necessary. For other loss functions, we will need to use vector calculus to get the analytic solution.</p>
</div>
<div class="section" id="finishing-up-the-case-study">
<h2><span class="section-number">15.4.5. </span>Finishing up the Case Study<a class="headerlink" href="#finishing-up-the-case-study" title="Permalink to this headline">¶</a></h2>
<p>Let’s return to our case study, apply what we’ve learned, and explain why our solution is sound.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\textbf{y} = \begin{bmatrix} 2 \\ 1 \\ -2  \end{bmatrix} \qquad \textbf{X} = \begin{bmatrix} 1 &amp; 3 \\ 1 &amp; 0 \\ 1 &amp; -1 \end{bmatrix}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\hat{\boldsymbol\theta} 
&amp;= 
\left(
\begin{bmatrix} 1 &amp; 1 &amp; 1 \\ 3 &amp; 0 &amp; -1 \end{bmatrix}
\begin{bmatrix} 1 &amp; 3 \\ 1 &amp; 0 \\ 1 &amp; -1 \end{bmatrix}
\right)^{-1}
\begin{bmatrix} 1 &amp; 1 &amp; 1 \\ 3 &amp; 0 &amp; -1 \end{bmatrix}
\begin{bmatrix} 2 \\ 1 \\ -2  \end{bmatrix} \\
&amp;= 
\left(
\begin{bmatrix} 3 &amp; 2\\ 2 &amp; 10 \end{bmatrix}
\right)^{-1}
\begin{bmatrix} 1 \\ 8 \end{bmatrix} \\
&amp;=
\frac{1}{30-4}
\begin{bmatrix} 10 &amp; -2\\ -2 &amp; 3 \end{bmatrix}
\begin{bmatrix} 1 \\ 8 \end{bmatrix} \\
&amp;=
\frac{1}{26}
\begin{bmatrix} -6 \\ 22 \end{bmatrix}\\
&amp;=
\begin{bmatrix} - \frac{3}{13} \\ \frac{11}{13} \end{bmatrix}
\end{align}
\end{split}\]</div>
<p>We have analytically found that best model for least squares regression is <span class="math notranslate nohighlight">\(f_\boldsymbol{\boldsymbol\theta}(x_i) = - \frac{3}{13} + \frac{11}{13} x_i\)</span>. We know that our choice of <span class="math notranslate nohighlight">\(\boldsymbol\theta\)</span> is sound by the mathematical property that the projection of <span class="math notranslate nohighlight">\(\textbf{y}\)</span> onto the span of the columns of <span class="math notranslate nohighlight">\(\textbf{X}\)</span> yields the closest point in the vector space to <span class="math notranslate nohighlight">\(\textbf{y}\)</span>. Under linear constraints using the least squares loss, solving for <span class="math notranslate nohighlight">\(\hat{\boldsymbol\theta}\)</span> by taking the projection guarantees us the optimal solution.</p>
</div>
<div class="section" id="when-variables-are-linearly-dependent">
<h2><span class="section-number">15.4.6. </span>When Variables are Linearly Dependent<a class="headerlink" href="#when-variables-are-linearly-dependent" title="Permalink to this headline">¶</a></h2>
<p>For every additional variable, we add one column to <span class="math notranslate nohighlight">\(\textbf{X}\)</span>. The span of the columns of <span class="math notranslate nohighlight">\(\textbf{X}\)</span> is the linear combinations of the column vectors, so adding columns only changes the span if it is linearly independent from all existing columns.</p>
<p>When the added column is linearly dependent, it can be expressed as a linear combination of some other columns, and thus will not introduce new any vectors to the subspace.</p>
<p>Recall that the span of <span class="math notranslate nohighlight">\(\textbf{X}\)</span> is important because it is the subspace we want to project <span class="math notranslate nohighlight">\(\textbf{y}\)</span> onto. If the subspace does not change, then the projection will not change.</p>
<p>For example, when we introduced <span class="math notranslate nohighlight">\(\textbf{x}\)</span> to the constant model to get the simple linear model, we introduced a independent variable. <span class="math notranslate nohighlight">\(\textbf{x} = \begin{bmatrix} 3 \\ 0 \\ -1 \end{bmatrix}\)</span> cannot be expressed as a scalar of <span class="math notranslate nohighlight">\(\begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix}\)</span>. Thus, we moved from finding the projection of <span class="math notranslate nohighlight">\(\textbf{y}\)</span> onto a line:</p>
<a class="reference internal image-reference" href="../../_images/1dprojection.png"><img alt="1dprojection.png" class="align-center" src="../../_images/1dprojection.png" style="width: 250px;" /></a>
<p>to finding the projection of <span class="math notranslate nohighlight">\(\textbf{y}\)</span> onto a plane:</p>
<a class="reference internal image-reference" href="../../_images/proj1.png"><img alt="proj1.png" class="align-center" src="../../_images/proj1.png" style="width: 400px;" /></a>
<p>Now, lets introduce another variable, <span class="math notranslate nohighlight">\(\textbf{z}\)</span>, and explicitly write out the bias column:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>z</strong></p></th>
<th class="head"><p><strong>1</strong></p></th>
<th class="head"><p><strong>x</strong></p></th>
<th class="head"><p><strong>y</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>4</p></td>
<td><p>1</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p>0</p></td>
<td><p>1</p></td>
<td><p>-1</p></td>
<td><p>-2</p></td>
</tr>
</tbody>
</table>
<p>Notice that <span class="math notranslate nohighlight">\(\textbf{z} = \textbf{1} + \textbf{x}\)</span>. Since <span class="math notranslate nohighlight">\(\textbf{z}\)</span> is a linear combination of <span class="math notranslate nohighlight">\(\textbf{1}\)</span> and <span class="math notranslate nohighlight">\(\textbf{x}\)</span>, it lies in the original <span class="math notranslate nohighlight">\(Span(\textbf{X})\)</span>. Formally, <span class="math notranslate nohighlight">\(\textbf{z}\)</span> is linearly dependent to <span class="math notranslate nohighlight">\(\{\textbf{1}\)</span>, <span class="math notranslate nohighlight">\(\textbf{x}\}\)</span> and does not change <span class="math notranslate nohighlight">\(Span(\textbf{X})\)</span>. Thus, the projection of <span class="math notranslate nohighlight">\(\textbf{y}\)</span> onto the subspace spanned by <span class="math notranslate nohighlight">\(\textbf{1}\)</span>, <span class="math notranslate nohighlight">\(\textbf{x}\)</span>, and <span class="math notranslate nohighlight">\(\textbf{z}\)</span> would be the same as the projection of <span class="math notranslate nohighlight">\(\textbf{y}\)</span> onto the subspace spanned by <span class="math notranslate nohighlight">\(\textbf{1}\)</span> and <span class="math notranslate nohighlight">\(\textbf{x}\)</span>.</p>
<a class="reference internal image-reference" href="../../_images/dependent_variablesz.png"><img alt="dependent_variablesz.png" class="align-center" src="../../_images/dependent_variablesz.png" style="width: 500px;" /></a>
<p>We can also observe this from minimizing the loss function:</p>
<div class="math notranslate nohighlight">
\[\begin{split} 
\begin{aligned}
L(\boldsymbol\theta, \textbf{d}, \textbf{y})
&amp;= \left \Vert  \qquad   
\begin{bmatrix} y_1 \\ y_2 \\ y_3  \end{bmatrix} \quad - \quad 
\begin{bmatrix} 1 &amp; x_1 &amp; z_1 \\ 1 &amp; x_2 &amp; z_2\\ 1 &amp; x_3 &amp; z_3\end{bmatrix}
\begin{bmatrix} 
     \theta_0 \\
     \theta_1 \\
     \theta_2
\end{bmatrix}
\qquad \right \Vert ^2
\end{aligned}
\end{split}\]</div>
<p>Our possible solutions follow the form <span class="math notranslate nohighlight">\(\theta_0 \textbf{1} + \theta_1 \textbf{x} + \theta_2 \textbf{z}\)</span>.</p>
<p>Since <span class="math notranslate nohighlight">\(\textbf{z} = \textbf{1} + \textbf{x}\)</span>, regardless of <span class="math notranslate nohighlight">\(\theta_0\)</span>, <span class="math notranslate nohighlight">\(\theta_1\)</span>, and <span class="math notranslate nohighlight">\(\theta_2\)</span>, the possible values can be rewritten as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\theta_0 \textbf{1} + \theta_1 \textbf{x} + \theta_2 (\textbf{1} + \textbf{x})
&amp;= 
(\theta_0 + \theta_2) \textbf{1} + (\theta_1 + \theta_2) \textbf{x} \\
\end{aligned}
\end{split}\]</div>
<p>So adding <span class="math notranslate nohighlight">\(\textbf{z}\)</span> does not change the problem at all. The only difference is, we can express this projection in multiple ways. Recall that we found the projection of <span class="math notranslate nohighlight">\(\textbf{y}\)</span> onto the plane spanned by <span class="math notranslate nohighlight">\(\textbf{1}\)</span> and <span class="math notranslate nohighlight">\(\textbf{x}\)</span> to be:</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{bmatrix} \textbf{1} &amp; \textbf{x} \end{bmatrix}  \begin{bmatrix} - \frac{3}{13} \\ \frac{11}{13} \end{bmatrix} = - \frac{3}{13} \textbf{1} + \frac{11}{13} \textbf{x}\end{split}\]</div>
<p>However, with the introduction of <span class="math notranslate nohighlight">\(\textbf{z}\)</span>, we have more ways to express this same projection vector.</p>
<p>Since <span class="math notranslate nohighlight">\(\textbf{1} = \textbf{z} - \textbf{x}\)</span>, <span class="math notranslate nohighlight">\(\hat{\textbf{y}}\)</span> can also be expressed as:</p>
<div class="math notranslate nohighlight">
\[ - \frac{3}{13} (\textbf{z} - \textbf{x}) + \frac{11}{13} \textbf{x} = - \frac{3}{13} \textbf{z} + \frac{14}{13} \textbf{x} \]</div>
<p>Since <span class="math notranslate nohighlight">\(\textbf{x} = \textbf{z} + \textbf{1}\)</span>, <span class="math notranslate nohighlight">\(\hat{\textbf{y}}\)</span> can also be expressed as:</p>
<div class="math notranslate nohighlight">
\[ - \frac{3}{13} \textbf{1} + \frac{11}{13} (\textbf{z} + \textbf{1}) = \frac{8}{13} \textbf{1} + \frac{11}{13} \textbf{z} \]</div>
<p>But all three expressions represent the same projection.</p>
<p>In conclusion, adding a linearly dependent column to <span class="math notranslate nohighlight">\(\textbf{X}\)</span> does not change <span class="math notranslate nohighlight">\(Span(\textbf{X})\)</span>, and thus will not change the projection and solution to the least squares problem.</p>
</div>
<div class="section" id="two-schools-of-thought">
<h2><span class="section-number">15.4.7. </span>Two Schools of Thought<a class="headerlink" href="#two-schools-of-thought" title="Permalink to this headline">¶</a></h2>
<p>We included the scatter plots twice in this lesson. The first reminded us that like before, we are finding the best-fit line for the data. The second showed that there was no line that could fit all points. Apart from these two occurences, we tried not to disrupt our vector space drawings with scatter plots. This is because scatter plots correspond with the row-space perspective of the least squares problem: looking at each data point and trying to minimize the distance between our predictions and each datum. In this lesson, we looked at the column-space perspective: each feature was a vector, constructing a space of possible solutions (projections).</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch/15"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="linear_inference.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">15.3. </span>[In progress] Inference for Linear Regression</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../16/prob_and_gen.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">16. </span>Probability and Generalization</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Sam Lau, Joey Gonzalez, and Deb Nolan<br/>
    
        &copy; Copyright 2022.<br/>
      <div class="extra_footer">
        <p>
License: CC BY-NC-ND 4.0
</p>

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>