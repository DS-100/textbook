
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>21.2. L2 Regularization: Ridge Regression &#8212; Principles and Techniques of Data Science</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.5f77b4aec8189eecf79907ce328c390d.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="21.3. L1 Regularization: Lasso Regression" href="reg_lasso.html" />
    <link rel="prev" title="21.1. Regularization Intuition" href="reg_intuition.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      <h1 class="site-logo" id="site-title">Principles and Techniques of Data Science</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Frontmatter
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../preface.html">
   To the Reader
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prereqs.html">
   Prerequisites
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../notation.html">
   Notation
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  The Data Science Lifecycle
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01/lifecycle_intro.html">
   1. The Data Science Lifecycle
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_students_1.html">
     1.1. The Students of Data 100
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_students_2.html">
     1.2. Exploratory Data Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_students_3.html">
     1.3. What’s in a Name?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02/design_intro.html">
   2. Generalizing from Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/design_dewey_truman.html">
     2.1. Dewey Defeats Truman
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/design_data.html">
     2.2. Data Sampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/design_sampling.html">
     2.3. Probability Sampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/design_srs_vs_big_data.html">
     2.4. SRS vs. “Big Data”
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03/modeling_intro.html">
   3. Modeling and Estimation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/modeling_simple.html">
     3.1. Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/modeling_loss_functions.html">
     3.2. Loss Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/modeling_abs_huber.html">
     3.3. Absolute and Huber Loss
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04/cycle_case_study_intro.html">
   4. [In progress] Case Study
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Rectangular Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../05/sql_intro.html">
   5. Relational Databases and SQL
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/sql_rdbms.html">
     5.1. The Relational Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/sql_basics.html">
     5.2. SQL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/sql_joins.html">
     5.3. SQL Joins
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../06/pandas_intro.html">
   6. Working with Dataframes using pandas
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_indexes.html">
     6.1. DataFrames, Slicing, Filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_grouping_pivoting.html">
     6.2. Grouping and Pivoting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_apply_strings_plotting.html">
     6.3. Apply, Strings, and Plotting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_joins.html">
     6.4. [In progress] Joins
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Understanding The Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../07/repr_intro.html">
   7. Data Representation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/repr_structure.html">
     7.1. Structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/repr_data_types.html">
     7.2. Data Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/repr_granularity.html">
     7.3. Granularity
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../08/quality_intro.html">
   8. [In Progress] Data Quality
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09/eda_intro.html">
   9. [In Progress] Exploratory Data Analysis
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../10/viz_intro.html">
   10. Data Visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/viz_quantitative.html">
     10.1. Visualizing Quantitative Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/viz_qualitative.html">
     10.2. Visualizing Qualitative Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/viz_matplotlib.html">
     10.3. Customizing Plots using
     <code class="docutils literal notranslate">
      <span class="pre">
       matplotlib
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/viz_principles.html">
     10.4. Visualization Principles
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/viz_principles_2.html">
     10.5. Visualization Principles Continued
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/viz_philosophy.html">
     10.6. Philosophy for Data Visualization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../11/police_intro.html">
   11. [In progress] Case Study: Berkeley Policing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/police_calls.html">
     11.1. Cleaning the Calls Dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/police_stops.html">
     11.2. Cleaning The Stops Dataset
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Other Data Sources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../12/text_intro.html">
   12. Working with Text
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/text_strings.html">
     12.1. Python String Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/text_regex.html">
     12.2. Regular Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/text_re.html">
     12.3. Regex and Python
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../13/web_intro.html">
   13. Web Technologies
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/web_http.html">
     13.1. HTTP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/web_rest.html">
     13.2. [In Progress] REST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/web_html.html">
     13.3. [In Progress] XPath and HTML
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Linear Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../14/linear_models.html">
   14. Linear Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/linear_tips.html">
     14.1. Predicting Tip Amounts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/linear_fitting.html">
     14.2. [In progress] Fitting a linear model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/linear_inference.html">
     14.3. [In progress] Inference for Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/linear_projection.html">
     14.4. Least Squares — A Geometric Perspective
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../15/prob_and_gen.html">
   15. Probability and Generalization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/prob_random_vars.html">
     15.1. Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/prob_exp_var.html">
     15.2. Expectation and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/prob_risk.html">
     15.3. Risk
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../16/gradient_descent.html">
   16. Gradient Descent and Numerical Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/gradient_basics.html">
     16.1. Loss Minimization Using a Program
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/gradient_descent_define.html">
     16.2. Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/gradient_convexity.html">
     16.3. Convexity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/gradient_stochastic.html">
     16.4. Stochastic Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/gradient_lin_reg.html">
     16.5. Fitting a Linear Model Using Gradient Descent
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../17/donkey_intro.html">
   17. [In progress] Case Study: Donkey Dimensions
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/donkey_analysis.html">
     17.1. Linear Regression Case Study
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Multiple Linear Modeling
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../18/mult_intro.html">
   18. [In progress] Multiple Linear Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../18/mult_model.html">
     18.1. Multiple Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18/mult_inference.html">
     18.2. Inference for Multiple Linear Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../19/feature_engineering.html">
   19. Feature Engineering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/feature_one_hot.html">
     19.1. The Walmart dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/feature_polynomial.html">
     19.2. Predicting Ice Cream Ratings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../20/bias_intro.html">
   20. The Bias-Variance Tradeoff
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/bias_risk.html">
     20.1. Risk and Loss Minimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/bias_modeling.html">
     20.2. Model Bias and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/bias_cv.html">
     20.3. Cross-Validation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="reg_intro.html">
   21. Regularization
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="reg_intuition.html">
     21.1. Regularization Intuition
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     21.2. L2 Regularization: Ridge Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="reg_lasso.html">
     21.3. L1 Regularization: Lasso Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../22/mult_case_intro.html">
   22. [In progress] Case Study: Multiple Linear Models
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Classification
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../23/classification_intro.html">
   23. Classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../23/classification_prob.html">
     23.1. Regression on Probabilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23/classification_log_model.html">
     23.2. The Logistic Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23/classification_cost.html">
     23.3. A Loss Function for the Logistic Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23/classification_log_reg.html">
     23.4. Using Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23/classification_cost_justification.html">
     23.5. Approximating the Empirical Probability Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23/classification_sgd.html">
     23.6. Fitting a Logistic Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23/classification_sensitivity_specificity.html">
     23.7. Evaluating Logistic Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23/classification_multiclass.html">
     23.8. Multiclass Classification
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Replicability
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../24/repl_intro.html">
   24. [In progress] Replicable Research
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/repl_phacking.html">
     24.1. P-hacking
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Extra Topics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../25/pca_intro.html">
   25. Dimensionality Reduction and PCA
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
  <label for="toctree-checkbox-21">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../25/pca_dims.html">
     25.1. Dimensions of a Data Table
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25/pca_svd.html">
     25.2. PCA using the Singular Value Decomposition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25/pca_in_practice.html">
     25.3. PCA in Practice
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../26/dtrees_intro.html">
   26. [In progress] Decision Trees and Random Forests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../27/clustering_intro.html">
   27. [In progress] Clustering
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Appendices
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../a01/prob_review.html">
   Probability Review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../a02/vector_space_review.html">
   Vector Space Review
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../a03/hyp_intro.html">
   Statistical Inference Review
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../a03/hyp_introduction.html">
     Hypothesis Testing and Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a03/hyp_introduction_part2.html">
     Permutation Test
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../a04/ref_intro.html">
   Reference Tables
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_pandas.html">
     pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_seaborn.html">
     Seaborn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_matplotlib.html">
     matplotlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_sklearn.html">
     scikit-learn
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../a05/contributors.html">
   Contributors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../references.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/ch/21/reg_ridge.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#l2-regularization-definition">
   21.2.1. L2 Regularization Definition
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-regularization-parameter">
     21.2.1.1. The Regularization Parameter
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bias-term-exclusion">
     21.2.1.2. Bias Term Exclusion
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-normalization">
     21.2.1.3. Data Normalization
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-ridge-regression">
   21.2.2. Using Ridge Regression
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   21.2.3. Summary
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="c1"># Ignore numpy dtype warnings. These warnings are caused by an interaction</span>
<span class="c1"># between numpy and Cython and can be safely ignored.</span>
<span class="c1"># Reference: https://stackoverflow.com/a/40846742</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;numpy.dtype size changed&quot;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;numpy.ufunc size changed&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">interact_manual</span>
<span class="kn">import</span> <span class="nn">nbinteract</span> <span class="k">as</span> <span class="nn">nbi</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s1">&#39;talk&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_columns</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="c1"># This option stops scientific notation for pandas</span>
<span class="c1"># pd.set_option(&#39;display.float_format&#39;, &#39;{:.2f}&#39;.format)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">df_interact</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">7</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Outputs sliders that show rows and columns of df</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="nf">peek</span><span class="p">(</span><span class="n">row</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">row</span><span class="p">:</span><span class="n">row</span> <span class="o">+</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">col</span><span class="p">:</span><span class="n">col</span> <span class="o">+</span> <span class="n">ncols</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">ncols</span><span class="p">:</span>
        <span class="n">interact</span><span class="p">(</span><span class="n">peek</span><span class="p">,</span> <span class="n">row</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">-</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">nrows</span><span class="p">),</span> <span class="n">col</span><span class="o">=</span><span class="n">fixed</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">interact</span><span class="p">(</span><span class="n">peek</span><span class="p">,</span>
                 <span class="n">row</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">-</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">nrows</span><span class="p">),</span>
                 <span class="n">col</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="o">-</span> <span class="n">ncols</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;(</span><span class="si">{}</span><span class="s1"> rows, </span><span class="si">{}</span><span class="s1"> columns) total&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;water_large.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="n">Curve</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Curve&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;xs&#39;</span><span class="p">,</span> <span class="s1">&#39;ys&#39;</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">flatten</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span> <span class="k">return</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">subseq</span> <span class="ow">in</span> <span class="n">seq</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">subseq</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">make_curve</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">x_start</span><span class="o">=-</span><span class="mi">50</span><span class="p">,</span> <span class="n">x_end</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_start</span><span class="p">,</span> <span class="n">x_end</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">Curve</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_data</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_curve</span><span class="p">(</span><span class="n">curve</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">curve</span><span class="o">.</span><span class="n">xs</span><span class="p">,</span> <span class="n">curve</span><span class="o">.</span><span class="n">ys</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">plot_curves</span><span class="p">(</span><span class="n">curves</span><span class="p">,</span> <span class="n">cols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;Deg </span><span class="si">{</span><span class="n">deg</span><span class="si">}</span><span class="s1"> poly&#39;</span> <span class="k">for</span> <span class="n">deg</span> <span class="ow">in</span> <span class="n">degrees</span><span class="p">]</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">curves</span><span class="p">)</span> <span class="o">/</span> <span class="n">cols</span><span class="p">))</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
                             <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">curve</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">flatten</span><span class="p">(</span><span class="n">axes</span><span class="p">),</span> <span class="n">curves</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">plot_data</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training data&#39;</span><span class="p">)</span>
        <span class="n">plot_curve</span><span class="p">(</span><span class="n">curve</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">5e10</span><span class="p">,</span> <span class="mf">170e10</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        
    <span class="c1"># add a big axes, hide frame</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># hide tick and tick label of the big axes</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">labelcolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="s1">&#39;off&#39;</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="s1">&#39;off&#39;</span><span class="p">,</span>
                    <span class="n">left</span><span class="o">=</span><span class="s1">&#39;off&#39;</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Polynomial Regression&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Water Level Change (m)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Water Flow (Liters)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">coefs</span><span class="p">(</span><span class="n">clf</span><span class="p">):</span>
    <span class="n">reg</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;reg&#39;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reg</span><span class="o">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="n">reg</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">coef_table</span><span class="p">(</span><span class="n">clf</span><span class="p">):</span>
    <span class="n">vals</span> <span class="o">=</span> <span class="n">coefs</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Coefficient Value&#39;</span><span class="p">:</span> <span class="n">vals</span><span class="p">})</span>
            <span class="o">.</span><span class="n">rename_axis</span><span class="p">(</span><span class="s1">&#39;degree&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span>

<span class="n">degrees</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">]</span>
<span class="n">clfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="n">deg</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>
                  <span class="p">(</span><span class="s1">&#39;reg&#39;</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">())])</span>
        <span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">deg</span> <span class="ow">in</span> <span class="n">degrees</span><span class="p">]</span>

<span class="n">curves</span> <span class="o">=</span> <span class="p">[</span><span class="n">make_curve</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span> <span class="k">for</span> <span class="n">clf</span> <span class="ow">in</span> <span class="n">clfs</span><span class="p">]</span>

<span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">]</span>

<span class="n">ridge_clfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="n">deg</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>
                        <span class="p">(</span><span class="s1">&#39;reg&#39;</span><span class="p">,</span> <span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">))])</span>
        <span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">deg</span> <span class="ow">in</span> <span class="n">degrees</span><span class="p">]</span>

<span class="n">ridge_curves</span> <span class="o">=</span> <span class="p">[</span><span class="n">make_curve</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span> <span class="k">for</span> <span class="n">clf</span> <span class="ow">in</span> <span class="n">ridge_clfs</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="l2-regularization-ridge-regression">
<h1><span class="section-number">21.2. </span>L2 Regularization: Ridge Regression<a class="headerlink" href="#l2-regularization-ridge-regression" title="Permalink to this headline">¶</a></h1>
<p>In this section we introduce <span class="math notranslate nohighlight">\( L_2 \)</span> regularization, a method of penalizing large weights in our cost function to lower model variance. We briefly review linear regression, then introduce regularization as a modification to the cost function.</p>
<p>To perform least squares linear regression, we use the model:</p>
<div class="math notranslate nohighlight">
\[
f_\hat{\theta}(x) = \hat{\theta} \cdot x
\]</div>
<p>We fit the model by minimizing the mean squared error cost function:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
L(\hat{\theta}, X, y)
&amp;= \frac{1}{n} \sum_{i}^n(y_i - f_\hat{\theta} (X_i))^2\\
\end{aligned}
\end{split}\]</div>
<p>In the above definitions, <span class="math notranslate nohighlight">\( X \)</span> represents the <span class="math notranslate nohighlight">\( n \times p \)</span> data matrix, <span class="math notranslate nohighlight">\( x \)</span> represents a row of <span class="math notranslate nohighlight">\( X \)</span>, <span class="math notranslate nohighlight">\( y \)</span> represents the observed outcomes, and <span class="math notranslate nohighlight">\( \hat{\theta} \)</span> represents the model weights.</p>
<div class="section" id="l2-regularization-definition">
<h2><span class="section-number">21.2.1. </span>L2 Regularization Definition<a class="headerlink" href="#l2-regularization-definition" title="Permalink to this headline">¶</a></h2>
<p>To add <span class="math notranslate nohighlight">\( L_2 \)</span> regularization to the model, we modify the cost function above:</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
L(\hat{\theta}, X, y)
&amp;= \frac{1}{n} \sum_{i}(y_i - f_\hat{\theta} (X_i))^2
    + \lambda \sum_{j = 1}^{p} \hat{\theta_j}^2
\end{aligned}
\]</div>
<p>Notice that the cost function above is the same as before with the addition of the <span class="math notranslate nohighlight">\( L_2 \)</span> regularization <span class="math notranslate nohighlight">\( \lambda \sum_{j = 1}^{p} \hat{\theta_j}^2 \)</span> term. The summation in this term sums the square of each model weight <span class="math notranslate nohighlight">\( \hat{\theta_1}, \hat{\theta_2}, \ldots, \hat{\theta_p} \)</span>. The term also introduces a new scalar model parameter <span class="math notranslate nohighlight">\( \lambda \)</span> that adjusts the regularization penalty.</p>
<p>The regularization term causes the cost to increase if the values in <span class="math notranslate nohighlight">\( \hat{\theta} \)</span> are further away from 0. With the addition of regularization, the optimal model weights minimize the combination of loss and regularization penalty rather than the loss alone. Since the resulting model weights tend to be smaller in absolute value, the model has lower variance and higher bias.</p>
<p>Using <span class="math notranslate nohighlight">\( L_2 \)</span> regularization with a linear model and the mean squared error cost function is also known more commonly as <strong>ridge regression</strong>.</p>
<div class="section" id="the-regularization-parameter">
<h3><span class="section-number">21.2.1.1. </span>The Regularization Parameter<a class="headerlink" href="#the-regularization-parameter" title="Permalink to this headline">¶</a></h3>
<p>The regularization parameter <span class="math notranslate nohighlight">\( \lambda \)</span> controls the regularization penalty. A small <span class="math notranslate nohighlight">\( \lambda \)</span> results in a small penalty—if <span class="math notranslate nohighlight">\( \lambda = 0 \)</span> the regularization term is also <span class="math notranslate nohighlight">\( 0 \)</span> and the cost is not regularized at all.</p>
<p>A large <span class="math notranslate nohighlight">\( \lambda \)</span> terms results in a large penalty and therefore a simpler model. Increasing <span class="math notranslate nohighlight">\( \lambda \)</span> decreases the variance and increases the bias of the model. We use cross-validation to select the value of <span class="math notranslate nohighlight">\( \lambda \)</span> that minimizes the validation error.</p>
<p><strong>Note about regularization in <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>:</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> provides regression models that have regularization built-in. For example, to conduct ridge regression you may use the <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"><code class="docutils literal notranslate"><span class="pre">sklearn.linear_model.Ridge</span></code></a> regression model. Note that <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> models call the regularization parameter <code class="docutils literal notranslate"><span class="pre">alpha</span></code> instead of <span class="math notranslate nohighlight">\( \lambda \)</span>.</p>
<p><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> conveniently provides regularized models that perform cross-validation to select a good value of <span class="math notranslate nohighlight">\( \lambda \)</span>. For example, the <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV"><code class="docutils literal notranslate"><span class="pre">sklearn.linear_model.RidgeCV</span></code></a> allows users to input regularization parameter values and will automatically use cross-validation to select the parameter value with the least validation error.</p>
</div>
<div class="section" id="bias-term-exclusion">
<h3><span class="section-number">21.2.1.2. </span>Bias Term Exclusion<a class="headerlink" href="#bias-term-exclusion" title="Permalink to this headline">¶</a></h3>
<p>Note that the bias term <span class="math notranslate nohighlight">\( \theta_0 \)</span> is not included in the summation of the regularization term. We do not penalize the bias term because increasing the bias term does not increase the variance of our model—the bias term simply shifts all predictions by a constant value.</p>
</div>
<div class="section" id="data-normalization">
<h3><span class="section-number">21.2.1.3. </span>Data Normalization<a class="headerlink" href="#data-normalization" title="Permalink to this headline">¶</a></h3>
<p>Notice that the regularization term <span class="math notranslate nohighlight">\( \lambda \sum_{j = 1}^{p} \hat{\theta_j}^2 \)</span> penalizes each <span class="math notranslate nohighlight">\( \hat{\theta_j} \)</span> equally. However, the effect of each <span class="math notranslate nohighlight">\( \hat{\theta_j} \)</span> differs depending on the data itself. Consider this section of the water flow dataset after adding degree 8 polynomial features:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">clfs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;poly&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">]),</span>
             <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;deg_</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">_feat&#39;</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>deg_0_feat</th>
      <th>deg_1_feat</th>
      <th>...</th>
      <th>deg_6_feat</th>
      <th>deg_7_feat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-15.94</td>
      <td>253.98</td>
      <td>...</td>
      <td>-261095791.08</td>
      <td>4161020472.12</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-29.15</td>
      <td>849.90</td>
      <td>...</td>
      <td>-17897014961.65</td>
      <td>521751305227.70</td>
    </tr>
    <tr>
      <th>2</th>
      <td>36.19</td>
      <td>1309.68</td>
      <td>...</td>
      <td>81298431147.09</td>
      <td>2942153527269.12</td>
    </tr>
    <tr>
      <th>3</th>
      <td>37.49</td>
      <td>1405.66</td>
      <td>...</td>
      <td>104132296999.30</td>
      <td>3904147586408.71</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-48.06</td>
      <td>2309.65</td>
      <td>...</td>
      <td>-592123531634.12</td>
      <td>28456763821657.78</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 8 columns</p>
</div></div></div>
</div>
<p>We can see that the degree 7 polynomial features have much larger values than the degree 1 features. This means that a large model weight for the degree 7 features affects the predictions much more than a large model weight for the degree 1 features. If we apply regularization to this data directly, the regularization penalty will disproportionately lower the model weight for the lower degree features. In practice, this often results in high model variance even after applying regularization since the features with large effect on prediction will not be affected.</p>
<p>To combat this, we <em>normalize</em> each data column by subtracting the mean and scaling the values in each column to be between -1 and 1. In <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>, most regression models allow initializing with <code class="docutils literal notranslate"><span class="pre">normalize=True</span></code> to normalize the data before fitting.</p>
<p>Another analogous technique is <em>standardizing</em> the data columns by subtracting the mean and dividing by the standard deviation for each data column.</p>
</div>
</div>
<div class="section" id="using-ridge-regression">
<h2><span class="section-number">21.2.2. </span>Using Ridge Regression<a class="headerlink" href="#using-ridge-regression" title="Permalink to this headline">¶</a></h2>
<p>We have previously used polynomial features to fit polynomials of degree 2, 8, and 12 to water flow data. The original data and resulting model predictions are repeated below.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>water_level_change</th>
      <th>water_flow</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-15.94</td>
      <td>60422330445.52</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-29.15</td>
      <td>33214896575.60</td>
    </tr>
    <tr>
      <th>2</th>
      <td>36.19</td>
      <td>972706380901.06</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>20</th>
      <td>7.09</td>
      <td>236352046523.78</td>
    </tr>
    <tr>
      <th>21</th>
      <td>46.28</td>
      <td>1494256381086.73</td>
    </tr>
    <tr>
      <th>22</th>
      <td>14.61</td>
      <td>378146284247.97</td>
    </tr>
  </tbody>
</table>
<p>23 rows × 2 columns</p>
</div></div></div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_curves</span><span class="p">(</span><span class="n">curves</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/reg_ridge_15_0.png" src="../../_images/reg_ridge_15_0.png" />
</div>
</div>
<p>To conduct ridge regression, we first extract the data matrix and the vector of outcomes from the data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;X: &#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;y: &#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>X: 
[[-15.94]
 [-29.15]
 [ 36.19]
 ...
 [  7.09]
 [ 46.28]
 [ 14.61]]

y: 
[6.04e+10 3.32e+10 9.73e+11 ... 2.36e+11 1.49e+12 3.78e+11]
</pre></div>
</div>
</div>
</div>
<p>Then, we apply a degree 12 polynomial transform to <code class="docutils literal notranslate"><span class="pre">X</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>

<span class="c1"># We need to specify include_bias=False since sklearn&#39;s classifiers</span>
<span class="c1"># automatically add the intercept term.</span>
<span class="n">X_poly_8</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;First two rows of transformed X:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_poly_8</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>First two rows of transformed X:
[[-1.59e+01  2.54e+02 -4.05e+03  6.45e+04 -1.03e+06  1.64e+07 -2.61e+08
   4.16e+09]
 [-2.92e+01  8.50e+02 -2.48e+04  7.22e+05 -2.11e+07  6.14e+08 -1.79e+10
   5.22e+11]]
</pre></div>
</div>
</div>
</div>
<p>We specify <code class="docutils literal notranslate"><span class="pre">alpha</span></code> values that <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> will select from using cross-validation, then use the <code class="docutils literal notranslate"><span class="pre">RidgeCV</span></code> classifier to fit the transformed data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeCV</span>

<span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">]</span>

<span class="c1"># Remember to set normalize=True to normalize data</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_poly_8</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Display the chosen alpha value:</span>
<span class="n">clf</span><span class="o">.</span><span class="n">alpha_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.1
</pre></div>
</div>
</div>
</div>
<p>Finally, we plot the model predictions for the base degree 8 polynomial classifier next to the regularized degree 8 classifier:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plot_data</span><span class="p">()</span>
<span class="n">plot_curve</span><span class="p">(</span><span class="n">curves</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Base degree 8 polynomial&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plot_data</span><span class="p">()</span>
<span class="n">plot_curve</span><span class="p">(</span><span class="n">ridge_curves</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Regularized degree 8 polynomial&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/reg_ridge_23_0.png" src="../../_images/reg_ridge_23_0.png" />
</div>
</div>
<p>We can see that the regularized polynomial is smoother than the base degree 8 polynomial and still captures the major trend in the data.</p>
<p>Comparing the coefficients of the non-regularized and regularized models shows that ridge regression favors placing model weights on the lower degree polynomial terms:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">base</span> <span class="o">=</span> <span class="n">coef_table</span><span class="p">(</span><span class="n">clfs</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Coefficient Value&#39;</span><span class="p">:</span> <span class="s1">&#39;Base&#39;</span><span class="p">})</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">coef_table</span><span class="p">(</span><span class="n">ridge_clfs</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Coefficient Value&#39;</span><span class="p">:</span> <span class="s1">&#39;Regularized&#39;</span><span class="p">})</span>

<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">display</span><span class="p">(</span><span class="n">base</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ridge</span><span class="p">))</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">7</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Base</th>
      <th>Regularized</th>
    </tr>
    <tr>
      <th>degree</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>225782472111.94</td>
      <td>221063525725.23</td>
    </tr>
    <tr>
      <th>1</th>
      <td>13115217770.78</td>
      <td>6846139065.96</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-144725749.98</td>
      <td>146158037.96</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-10355082.91</td>
      <td>1930090.04</td>
    </tr>
    <tr>
      <th>4</th>
      <td>567935.23</td>
      <td>38240.62</td>
    </tr>
    <tr>
      <th>5</th>
      <td>9805.14</td>
      <td>564.21</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-249.64</td>
      <td>7.25</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-2.09</td>
      <td>0.18</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.03</td>
      <td>0.00</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Repeating the process for degree 12 polynomial features results in a similar result:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plot_data</span><span class="p">()</span>
<span class="n">plot_curve</span><span class="p">(</span><span class="n">curves</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Base degree 12 polynomial&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">5e10</span><span class="p">,</span> <span class="mf">170e10</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plot_data</span><span class="p">()</span>
<span class="n">plot_curve</span><span class="p">(</span><span class="n">ridge_curves</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Regularized degree 12 polynomial&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">5e10</span><span class="p">,</span> <span class="mf">170e10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/reg_ridge_27_0.png" src="../../_images/reg_ridge_27_0.png" />
</div>
</div>
<p>Increasing the regularization parameter results in progressively simpler models. The plot below demonstrates the effects of increasing the regularization amount from 0.001 to 100.0.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]</span>

<span class="n">alpha_clfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;reg&#39;</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">))]</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">]</span>

<span class="n">alpha_curves</span> <span class="o">=</span> <span class="p">[</span><span class="n">make_curve</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span> <span class="k">for</span> <span class="n">clf</span> <span class="ow">in</span> <span class="n">alpha_clfs</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">lambda = </span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s1">$&#39;</span> <span class="k">for</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">]</span>

<span class="n">plot_curves</span><span class="p">(</span><span class="n">alpha_curves</span><span class="p">,</span> <span class="n">cols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/reg_ridge_29_0.png" src="../../_images/reg_ridge_29_0.png" />
</div>
</div>
<p>As we can see, increasing the regularization parameter increases the bias of our model. If our parameter is too large, the model becomes a constant model because any non-zero model weight is heavily penalized.</p>
</div>
<div class="section" id="summary">
<h2><span class="section-number">21.2.3. </span>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>Using <span class="math notranslate nohighlight">\( L_2 \)</span> regularization allows us to tune model bias and variance by penalizing large model weights. <span class="math notranslate nohighlight">\( L_2 \)</span> regularization for least squares linear regression is also known by the more common name ridge regression. Using regularization adds an additional model parameter <span class="math notranslate nohighlight">\( \lambda \)</span> that we adjust using cross-validation.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch/21"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="reg_intuition.html" title="previous page"><span class="section-number">21.1. </span>Regularization Intuition</a>
    <a class='right-next' id="next-link" href="reg_lasso.html" title="next page"><span class="section-number">21.3. </span>L1 Regularization: Lasso Regression</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Sam Lau, Joey Gonzalez, and Deb Nolan<br/>
        
            &copy; Copyright 2021.<br/>
          <div class="extra_footer">
            <p>
License: CC BY-NC-ND 4.0
</p>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-113006011-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </body>
</html>