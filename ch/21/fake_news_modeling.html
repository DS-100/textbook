
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>21.4. Modeling &#8212; Learning Data Science</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/custom.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="21.5. Summary" href="fake_news_summary.html" />
    <link rel="prev" title="21.3. Exploring the Data" href="fake_news_exploring.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-113006011-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Learning Data Science</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Frontmatter
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../preface.html">
   Preface
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  The Data Science Lifecycle
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01/lifecycle_intro.html">
   1. The Data Science Lifecycle
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_cycle.html">
     1.1. The Stages of the Lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_map.html">
     1.2. Examples of the Lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_summary.html">
     1.3. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02/data_scope_intro.html">
   2. Questions and Data Scope
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_big_data_hubris.html">
     2.1. Big Data and New Opportunities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_construct.html">
     2.2. Target Population, Access Frame, and Sample
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_protocols.html">
     2.3. Instruments and Protocols
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_natural.html">
     2.4. Measuring Natural Phenomena
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_accuracy.html">
     2.5. Accuracy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_summary.html">
     2.6. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03/theory_intro.html">
   3. Simulation and Data Design
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/theory_urn.html">
     3.1. The Urn Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/theory_election.html">
     3.2. Example: Simulating Election Poll Bias and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/theory_vaccine_efficacy.html">
     3.3. Example: Simulating a Randomized Trial for a Vaccine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/theory_measurement_error.html">
     3.4. Example: Measuring Air Quality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/theory_summary.html">
     3.5. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04/modeling_intro.html">
   4. Modeling with Summary Statistics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/modeling_simple.html">
     4.1. The Constant Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/modeling_loss_functions.html">
     4.2. Minimizing Loss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/modeling_summary.html">
     4.3. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../05/bus_intro.html">
   5. Case Study: Why Is My Bus Always Late?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/bus_scope.html">
     5.1. Question and Scope
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/bus_clean.html">
     5.2. Data Wrangling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/bus_eda.html">
     5.3. Exploring Bus Times
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/bus_modeling.html">
     5.4. Modeling Wait Times
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/bus_summary.html">
     5.5. Summary
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Rectangular Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../06/pandas_intro.html">
   6. Working with Dataframes Using pandas
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_subsetting.html">
     6.1. Subsetting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_aggregating.html">
     6.2. Aggregating
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_joining.html">
     6.3. Joining
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_transforming.html">
     6.4. Transforming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_other_reps.html">
     6.5. How Are Dataframes Different from Other Data Representations?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_summary.html">
     6.6. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../07/sql_intro.html">
   7. Working with Relations Using SQL
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_subsetting.html">
     7.1. Subsetting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_aggregating.html">
     7.2. Aggregating
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_joining.html">
     7.3. Joining
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_transforming.html">
     7.4. Transforming and Common Table Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_summary.html">
     7.5. Summary
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Understanding The Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08/files_intro.html">
   8. Wrangling Files
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_datasets.html">
     8.1. Data Source Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_formats.html">
     8.2. File Formats
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_encoding.html">
     8.3. File Encoding
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_size.html">
     8.4. File Size
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_command_line.html">
     8.5. The Shell and Command-Line Tools
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_granularity.html">
     8.6. Table Shape and Granularity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_summary.html">
     8.7. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../09/wrangling_intro.html">
   9. Wrangling Dataframes
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_co2.html">
     9.1. Example: Wrangling CO
     <sub>
      2
     </sub>
     Measurements from the Mauna Loa Observatory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_checks.html">
     9.2. Quality Checks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_missing.html">
     9.3. Missing Values and Records
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_transformations.html">
     9.4. Transformations and Timestamps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_structure.html">
     9.5. Modifying Structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_restaurants.html">
     9.6. Example: Wrangling Restaurant Safety Violations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_summary.html">
     9.7. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../10/eda_intro.html">
   10. Exploratory Data Analysis
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_feature_types.html">
     10.1. Feature Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_distributions.html">
     10.2. What to Look For in a Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_relationships.html">
     10.3. What to Look For in a Relationship
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_multi.html">
     10.4. Comparisons in Multivariate Settings
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_guidelines.html">
     10.5. Guidelines for Exploration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_example.html">
     10.6. Example: Sale Prices for Houses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_summary.html">
     10.7. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../11/viz_intro.html">
   11. Data Visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_scale.html">
     11.1. Choosing Scale to Reveal Structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_smoothing.html">
     11.2. Smoothing and Aggregating Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_comparisons.html">
     11.3. Facilitating Meaningful Comparisons
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_data_design.html">
     11.4. Incorporating the Data Design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_context.html">
     11.5. Adding Context
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_plotly.html">
     11.6. Creating Plots Using plotly
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_other_tools.html">
     11.7. Other Tools for Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_summary.html">
     11.8. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../12/pa_intro.html">
   12. Case Study: How Accurate Are Air Quality Measurements?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_scope.html">
     12.1. Question, Design, and Scope
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_collocated.html">
     12.2. Finding Collocated Sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_cleaning_aqs.html">
     12.3. Wrangling and Cleaning AQS Sensor Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_cleaning_purpleair.html">
     12.4. Wrangling PurpleAir Sensor Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_eda.html">
     12.5. Exploring PurpleAir and AQS Measurements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_modeling.html">
     12.6. Creating a Model to Correct PurpleAir Measurements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_conclusion.html">
     12.7. Summary
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Other Data Sources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../13/text_intro.html">
   13. Working with Text
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/text_examples.html">
     13.1. Examples of Text and Tasks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/text_strings.html">
     13.2. String Manipulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/text_regex.html">
     13.3. Regular Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/text_sotu.html">
     13.4. Text Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/text_summary.html">
     13.5. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../14/web_intro.html">
   14. Data Exchange
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/web_netCDF.html">
     14.1. NetCDF Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/web_json.html">
     14.2. JSON Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/web_http.html">
     14.3. HTTP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/web_rest.html">
     14.4. REST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/web_html.html">
     14.5. XML, HTML, and XPath
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/web_summary.html">
     14.6. Summary
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Linear Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../15/linear_intro.html">
   15. Linear Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_simple.html">
     15.1. Simple Linear Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_pa.html">
     15.2. Example: A Simple Linear Model for Air Quality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_simple_fit.html">
     15.3. Fitting the Simple Linear Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_multi.html">
     15.4. Multiple Linear Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_multi_fit.html">
     15.5. Fitting the Multiple Linear Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_case.html">
     15.6. Example: Where Is the Land of Opportunity?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_feature_eng.html">
     15.7. Feature Engineering for Numeric Measurements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_categorical.html">
     15.8. Feature Engineering for Categorical Measurements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_summary.html">
     15.9. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../16/ms_intro.html">
   16. Model Selection
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/ms_overfitting.html">
     16.1. Overfitting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/ms_train_test.html">
     16.2. Train-Test Split
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/ms_cv.html">
     16.3. Cross-Validation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/ms_regularization.html">
     16.4. Regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/ms_risk.html">
     16.6. Model Bias and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/ms_summary.html">
     16.7. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../17/inf_pred_gen_intro.html">
   17. Theory for Inference and Prediction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/inf_pred_gen_dist.html">
     17.1. Distributions: Population, Empirical, Sampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/inf_pred_gen_HT.html">
     17.2. Basics of Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/inf_pred_gen_boot.html">
     17.3. Bootstrapping for Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/inf_pred_gen_CI.html">
     17.4. Basics of Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/inf_pred_gen_PI.html">
     17.5. Basics of Prediction Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/inf_pred_gen_prob.html">
     17.6. Probability for Inference and Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/inf_pred_gen_summary.html">
     17.7. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../18/donkey_intro.html">
   18. Case Study: How to Weigh a Donkey
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../18/donkey_scope.html">
     18.1. Donkey Study Question and Scope
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18/donkey_clean.html">
     18.2. Wrangling and Transforming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18/donkey_eda.html">
     18.3. Exploring
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18/donkey_model.html">
     18.4. Modeling a Donkey’s Weight
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18/donkey_summary.html">
     18.5. Summary
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Classification
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../19/class_intro.html">
   19. Classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/class_example.html">
     19.1. Example: Wind-Damaged Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/class_pred.html">
     19.2. Modeling and Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/class_log_model.html">
     19.3. Modeling Proportions (and Probabilities)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/class_loss.html">
     19.4. A Loss Function for the Logistic Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/class_dr.html">
     19.5. From Probabilities to Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/class_summary.html">
     19.6. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../20/gd_intro.html">
   20. Numerical Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/gd_basics.html">
     20.1. Gradient Descent Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/gd_example.html">
     20.2. Minimizing Huber Loss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/gd_convex.html">
     20.3. Convex and Differentiable Loss Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/gd_alternative.html">
     20.4. Variants of Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/gd_summary.html">
     20.5. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="fake_news_intro.html">
   21. Case Study: Detecting Fake News
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
  <label for="toctree-checkbox-21">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="fake_news_question.html">
     21.1. Question and Scope
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fake_news_data.html">
     21.2. Obtaining and Wrangling the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fake_news_exploring.html">
     21.3. Exploring the Data
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     21.4. Modeling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fake_news_summary.html">
     21.5. Summary
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../additional_resources.html">
   Additional Material
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_sources.html">
   Data Sources
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Appendices
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../a01/prob_review.html">
   Probability Review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../a02/vector_space_review.html">
   Vector Space Review
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https%3A//github.com/ds-100/textbook&urlpath=tree/textbook/content/ch/21/fake_news_modeling.ipynb&branch=master"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on JupyterHub"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_jupyterhub.svg">
  </span>
<span class="headerbtn__text-container">JupyterHub</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/ch/21/fake_news_modeling.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-single-word-model">
   21.4.1. A Single-Word Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multiple-word-model">
   21.4.2. Multiple-Word Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#predicting-with-the-tf-idf-transform">
   21.4.3. Predicting with the tf-idf Transform
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Modeling</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-single-word-model">
   21.4.1. A Single-Word Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multiple-word-model">
   21.4.2. Multiple-Word Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#predicting-with-the-tf-idf-transform">
   21.4.3. Predicting with the tf-idf Transform
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="modeling">
<span id="sec-fake-news-modeling"></span><h1><span class="section-number">21.4. </span>Modeling<a class="headerlink" href="#modeling" title="Permalink to this headline">#</a></h1>
<p>Now that we’ve obtained, cleaned, and explored our data, let’s fit models to predict whether articles are real or fake. In this section, we use logistic regression because we have a binary classification problem. We fit three different models that increase in complexity. First, we fit a model that just uses the presence of a single handpicked word in the document as an explanatory feature. Then we fit a model that uses multiple handpicked words. Finally, we fit a model that uses all the words in the train set, vectorized using the tf-idf transform (introduced in <a class="reference internal" href="../13/text_intro.html#ch-text"><span class="std std-numref">Chapter 13</span></a>). Let’s start with the simple single-word model.</p>
<section id="a-single-word-model">
<h2><span class="section-number">21.4.1. </span>A Single-Word Model<a class="headerlink" href="#a-single-word-model" title="Permalink to this headline">#</a></h2>
<p>Our EDA showed that the word <em>vote</em> is related to whether an article is labeled <code class="docutils literal notranslate"><span class="pre">real</span></code> or <code class="docutils literal notranslate"><span class="pre">fake</span></code>. To test this, we fit a logistic regression model using a single binary feature: <code class="docutils literal notranslate"><span class="pre">1</span></code> if the word <em>vote</em> appears in the article and <code class="docutils literal notranslate"><span class="pre">0</span></code> if not. We start by defining a function to lowercase the article content:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">lowercase</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>For our first classifier, we only use the word <em>vote</em>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">one_word</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;vote&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>We can chain the <code class="docutils literal notranslate"><span class="pre">lowercase</span></code> function and the function <code class="docutils literal notranslate"><span class="pre">make_word_features</span></code> from our EDA into a <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> pipeline. This provides a convenient way to transform and fit data all at once:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegressionCV</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">FunctionTransformer</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model1</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">lowercase</span><span class="p">),</span>
    <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">make_word_features</span><span class="p">,</span> <span class="n">kw_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;words&#39;</span><span class="p">:</span> <span class="n">one_word</span><span class="p">}),</span>
    <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">Cs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;saga&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>When used, the preceding pipeline converts the characters in the article content to lowercase, creates a dataframe with a binary feature for each word of interest, and fits a logistic regression model on the data using <span class="math notranslate nohighlight">\( L_2 \)</span> regularization. Additionally, the <code class="docutils literal notranslate"><span class="pre">LogisticRegressionCV</span></code> function uses cross-validation (5-fold by default) to select the best regularization parameter. (See <a class="reference internal" href="../16/ms_intro.html#ch-risk"><span class="std std-numref">Chapter 16</span></a> for more on regularization and cross-validation.)</p>
<p>Let’s use the pipeline to fit the training data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="n">model1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">model1</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">)</span><span class="si">:</span><span class="s1">.1%</span><span class="si">}</span><span class="s1"> accuracy on training set.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>64.9% accuracy on training set.
CPU times: user 110 ms, sys: 42.7 ms, total: 152 ms
Wall time: 144 ms
</pre></div>
</div>
</div>
</div>
<p>Overall, the single-word classifier only classifies 65% of articles correctly. We plot the confusion matrix of the classifier on the train set to see what kinds of mistakes it makes:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">ConfusionMatrixDisplay</span>

<span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
    <span class="n">model1</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">,</span> <span class="n">colorbar</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/fake_news_modeling_18_0.svg" src="../../_images/fake_news_modeling_18_0.svg" /></div>
</div>
<p>Our model often misclassifies real articles (0) as fake (1). Since this model is simple, we can take a look at the probabilities for the two cases: the word <em>vote</em> is in the article or is not:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vote_present</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;vote&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]})</span>
<span class="n">vote_absent</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;vote&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">]})</span>

<span class="n">log_reg</span> <span class="o">=</span> <span class="n">model1</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;logisticregressioncv&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;&quot;vote&quot; present: </span><span class="si">{</span><span class="n">log_reg</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">vote_present</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;&quot;vote&quot; absent: </span><span class="si">{</span><span class="n">log_reg</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">vote_absent</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&quot;vote&quot; present: [[0.72 0.28]]
&quot;vote&quot; absent: [[0.48 0.52]]
</pre></div>
</div>
</div>
</div>
<p>When an article contains the word <em>vote</em>, the model gives a high probability to the article being real, and when <em>vote</em> is absent, the probability leans slightly toward the article being fake. We encourage readers to verify this for themselves using the definition of the logistic regression model and the fitted coefficients:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Intercept: </span><span class="si">{</span><span class="n">log_reg</span><span class="o">.</span><span class="n">intercept_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="p">[[</span><span class="n">coef</span><span class="p">]]</span> <span class="o">=</span> <span class="n">log_reg</span><span class="o">.</span><span class="n">coef_</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;&quot;vote&quot; Coefficient: </span><span class="si">{</span><span class="n">coef</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept: 0.08
&quot;vote&quot; Coefficient: -1.00
</pre></div>
</div>
</div>
</div>
<p>As we saw in <a class="reference internal" href="../19/class_intro.html#ch-logistic"><span class="std std-numref">Chapter 19</span></a>, the coefficient indicates the size of the change in the odds with a change in the explanatory variable. With a 0-1 variable like the presence or absence of a word in an article, this has a particularly intuitive meaning. For an article with <em>vote</em> in it, the odds of being fake decrease by a factor of <span class="math notranslate nohighlight">\(\exp(\theta_{vote})\)</span>, which is:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">coef</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.36836305405149367
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Remember that in this modeling scenario, a label of <code class="docutils literal notranslate"><span class="pre">0</span></code>  corresponds to a
real article and a label of <code class="docutils literal notranslate"><span class="pre">1</span></code> corresponds to a fake article. This might
seem a bit counterintuitive—we’re saying that a “true positive” is when
a model correctly predicts a fake article as fake. In binary classification, we
typically say a “positive” result is the one with the presence of something
unusual. For example, a person who tests positive for an illness would expect
to have the illness.</p>
</div>
<p>Let’s make our model a bit more sophisticated by introducing additional word features.</p>
</section>
<section id="multiple-word-model">
<h2><span class="section-number">21.4.2. </span>Multiple-Word Model<a class="headerlink" href="#multiple-word-model" title="Permalink to this headline">#</a></h2>
<p>We create a model that uses all of the words we examined in our EDA of the train set, except for <em>the</em>. Let’s fit a model using these 15 features:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model2</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">lowercase</span><span class="p">),</span>
    <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">make_word_features</span><span class="p">,</span> <span class="n">kw_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;words&#39;</span><span class="p">:</span> <span class="n">word_features</span><span class="p">}),</span>
    <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">Cs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;saga&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="n">model2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">model2</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">)</span><span class="si">:</span><span class="s1">.1%</span><span class="si">}</span><span class="s1"> accuracy on training set.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>74.8% accuracy on training set.
CPU times: user 1.54 s, sys: 59.1 ms, total: 1.6 s
Wall time: 637 ms
</pre></div>
</div>
</div>
</div>
<p>This model is about 10 percentage points more accurate than the one-word model. It may seem a bit surprising that going from a one-word model to a 15-word model only gains 10 percentage points. The confusion matrix is helpful in teasing out the kinds of errors made:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
    <span class="n">model2</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">,</span> <span class="n">colorbar</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/fake_news_modeling_32_0.svg" src="../../_images/fake_news_modeling_32_0.svg" /></div>
</div>
<p>We can see that this classifier does a better job classifying real articles accurately. However, it makes more mistakes than the simple one-word model when classifying fake article—59 of the fake articles were classified as real. In this scenario, we might be more concerned about misclassifying an article as fake when it is real. So we wish to have a high precision—the ratio of fake articles correctly predicted as fake to articles predicted as fake:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model1_precision</span> <span class="o">=</span> <span class="mi">238</span> <span class="o">/</span> <span class="p">(</span><span class="mi">238</span> <span class="o">+</span> <span class="mi">179</span><span class="p">)</span>
<span class="n">model2_precision</span> <span class="o">=</span> <span class="mi">205</span> <span class="o">/</span> <span class="p">(</span><span class="mi">205</span> <span class="o">+</span> <span class="mi">88</span><span class="p">)</span>

<span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="p">[</span><span class="n">model1_precision</span><span class="p">,</span> <span class="n">model2_precision</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.57, 0.7]
</pre></div>
</div>
</div>
</div>
<p>The precision in our larger model is improved, but about 30% of the articles labeled as fake are actually real. Let’s take a look at the model’s coefficients:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">log_reg2</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;logisticregressioncv&#39;</span><span class="p">]</span>
<span class="n">coefs</span> <span class="o">=</span> <span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="n">word_features</span><span class="p">,</span> <span class="s1">&#39;coef&#39;</span><span class="p">:</span> <span class="n">log_reg2</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]})</span>
         <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;coef&#39;</span><span class="p">)</span>
        <span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">coefs</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;coef&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;word&#39;</span><span class="p">,</span>
                 <span class="n">labels</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;coef&#39;</span><span class="p">:</span> <span class="s1">&#39;Model coefficient&#39;</span><span class="p">,</span><span class="s1">&#39;word&#39;</span><span class="p">:</span><span class="s1">&#39;Word&#39;</span><span class="p">},</span>
                 <span class="n">width</span><span class="o">=</span><span class="mi">350</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">add_vline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">line_width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">line_dash</span><span class="o">=</span><span class="s2">&quot;dash&quot;</span><span class="p">,</span> <span class="n">opacity</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">fig</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/fake_news_modeling_36_0.svg" src="../../_images/fake_news_modeling_36_0.svg" /></div>
</div>
<p>We can make a quick interpretation of the coefficients by looking at their signs. The large positive values on <em>trump</em> and <em>investig</em> indicate that the model predicts that new articles containing these words have a higher probability of being fake. The reverse is true for words like <em>congress</em> and <em>vote</em>, which have negative weights. We can use these coefficients to compare the log odds when an article does or does not contain a particular word.</p>
<p>Although this larger model performs better than the simple one-word model, we had to handpick the word features using our knowledge of the news. What if we missed the words that are highly predictive? To address this, we can incorporate all the words in the articles using the tf-idf transform.</p>
</section>
<section id="predicting-with-the-tf-idf-transform">
<h2><span class="section-number">21.4.3. </span>Predicting with the tf-idf Transform<a class="headerlink" href="#predicting-with-the-tf-idf-transform" title="Permalink to this headline">#</a></h2>
<p>For the third and final model, we use the term frequency-inverse document frequency (tf-idf) transform from <a class="reference internal" href="../13/text_intro.html#ch-text"><span class="std std-numref">Chapter 13</span></a> to vectorize the entire text of all articles in the train set. Recall that with this transform, an article is converted into a vector with one element for each word that appears in any of the 564 articles. The vector consists of normalized counts of the number of times the word appears in the article normalized by the rareness of the word. The tf-idf puts more weight on words that only appear in a few documents. This means that our classifier uses all the words in the train set’s news articles for prediction. As we’ve done when we introduced tf-idf, first we remove stopwords, then we tokenize the words, and then we use the <code class="docutils literal notranslate"><span class="pre">TfidfVectorizer</span></code> from <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.stem.porter</span> <span class="kn">import</span> <span class="n">PorterStemmer</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="n">stop_words</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">))</span>
<span class="n">porter_stemmer</span> <span class="o">=</span> <span class="n">PorterStemmer</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">stemming_tokenizer</span><span class="p">(</span><span class="n">document</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">porter_stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">words</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tfidf</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">stemming_tokenizer</span><span class="p">,</span> <span class="n">token_pattern</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">make_column_transformer</span>

<span class="n">model3</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">lowercase</span><span class="p">),</span>
    <span class="n">make_column_transformer</span><span class="p">((</span><span class="n">tfidf</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">)),</span>
    <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">Cs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                         <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;saga&#39;</span><span class="p">,</span>
                         <span class="n">n_jobs</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                         <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="n">model3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">model3</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">)</span><span class="si">:</span><span class="s1">.1%</span><span class="si">}</span><span class="s1"> accuracy on training set.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Pipeline]  (step 1 of 3) Processing functiontransformer, total=   0.0s
[Pipeline] . (step 2 of 3) Processing columntransformer, total=  14.5s
[Pipeline]  (step 3 of 3) Processing logisticregressioncv, total=   6.3s
100.0% accuracy on training set.
CPU times: user 50.2 s, sys: 508 ms, total: 50.7 s
Wall time: 34.2 s
</pre></div>
</div>
</div>
</div>
<p>We find that this model achieves 100% accuracy on the train set. We can take a look at the tf-idf transformer to better understand the model. Let’s start by finding out how many unique tokens the classifier uses:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tfidf</span> <span class="o">=</span> <span class="n">model3</span><span class="o">.</span><span class="n">named_steps</span><span class="o">.</span><span class="n">columntransformer</span><span class="o">.</span><span class="n">named_transformers_</span><span class="o">.</span><span class="n">tfidfvectorizer</span>
<span class="n">n_unique_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tfidf</span><span class="o">.</span><span class="n">vocabulary_</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">n_unique_tokens</span><span class="si">}</span><span class="s1"> tokens appeared across </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="si">}</span><span class="s1"> examples.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>23800 tokens appeared across 584 examples.
</pre></div>
</div>
</div>
</div>
<p>This means that our classifier has 23,812 features, a large increase from our previous model, which only had 15. Since we can’t display that many model weights, we display the 10 most negative and 10 most positive weights:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">log_reg</span> <span class="o">=</span> <span class="n">model3</span><span class="o">.</span><span class="n">named_steps</span><span class="o">.</span><span class="n">logisticregressioncv</span>
<span class="n">coefs</span> <span class="o">=</span> <span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">tfidf</span><span class="o">.</span><span class="n">vocabulary_</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span>
                      <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;word&#39;</span><span class="p">],</span>
                      <span class="n">index</span><span class="o">=</span><span class="n">tfidf</span><span class="o">.</span><span class="n">vocabulary_</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
         <span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>
         <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">coef</span><span class="o">=</span><span class="n">log_reg</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
         <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;coef&#39;</span><span class="p">)</span>
        <span class="p">)</span>
<span class="n">fig1</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">coefs</span><span class="p">[:</span><span class="mi">10</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;coef&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;word&#39;</span><span class="p">)</span>
<span class="n">fig2</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">coefs</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:],</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;coef&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;word&#39;</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">left_right</span><span class="p">(</span><span class="n">fig1</span><span class="p">,</span> <span class="n">fig2</span><span class="p">,</span> <span class="n">horizontal_spacing</span><span class="o">=</span><span class="mf">0.15</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">update_xaxes</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Model coefficient&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">update_yaxes</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Word&#39;</span><span class="p">,</span> <span class="n">row</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/fake_news_modeling_48_0.svg" src="../../_images/fake_news_modeling_48_0.svg" /></div>
</div>
<p>These coefficients show a few quirks about this model. We see that several influential features correspond to punctuation in the original text. It’s unclear whether we should clean out the punctuation in the model. On the one hand, punctuation doesn’t seem to convey as much meaning as words do. On the other, it seems plausible that, for example, lots of explanation points in an article could help a model decide whether the article is real or fake. In this case, we’ve decided to keep punctuation, but curious readers can repeat this analysis after stripping the punctuation out to see how the resulting model is affected.</p>
<p>We conclude by displaying the test set error for all three models:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;test set error&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">model1</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
                       <span class="n">model2</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
                       <span class="n">model3</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)]</span>
<span class="p">},</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;model1&#39;</span><span class="p">,</span> <span class="s1">&#39;model2&#39;</span><span class="p">,</span> <span class="s1">&#39;model3&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>test set error</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>model1</th>
      <td>0.61</td>
    </tr>
    <tr>
      <th>model2</th>
      <td>0.70</td>
    </tr>
    <tr>
      <th>model3</th>
      <td>0.88</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>As we might expect, the models became more accurate as we introduced more features. The model that used tf-idf performed much better than the models with binary handpicked word features, but it did not meet the 100% accuracy obtained on the train set. This illustrates a common trade-off in modeling: given enough data, more complex models can often outperform simpler ones, especially in situations like this case study where simpler models have too much model bias to perform well. However, complex models can be more difficult to interpret. For example, our tf-idf model had over 20,000 features, which makes it basically impossible to explain how our model makes its decisions. In addition, the tf-idf model takes much longer to make predictions—it’s over 100 times slower compared to model 2. All of these factors need to be considered when deciding which model to use in practice.</p>
<p>In addition, we need to be careful about what our models are useful for. In this case, our models use the content of the news articles for prediction, making them highly dependent on the words that appear in the train set. However, our models will likely not perform as well on future news articles that use words that didn’t appear in the train set. For example, our models use the US election candidates’ names in 2016 for prediction, but they won’t know to incorporate the names of the candidates in 2020 or 2024. To use our models in the longer term, we would need to address this issue of <em>drift</em>.</p>
<p>That said, it’s surprising that a logistic regression model can perform well with a relatively small amount of feature engineering (tf-idf). We’ve addressed our original research question: our tf-idf model appears effective for detecting fake news in our dataset, and it could plausibly generalize to other news published in the same time period covered in the training data.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch/21"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="fake_news_exploring.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">21.3. </span>Exploring the Data</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="fake_news_summary.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">21.5. </span>Summary</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Sam Lau, Joey Gonzalez, and Deb Nolan<br/>
  
      &copy; Copyright 2023.<br/>
    <div class="extra_footer">
      <p>
License: CC BY-NC-ND 4.0
</p>

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>