
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>16.6. Probability for Inference and Prediction &#8212; Learning Data Science</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/custom.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="16.7. Summary" href="inf_pred_gen_summary.html" />
    <link rel="prev" title="16.5. Basics of Prediction Intervals" href="inf_pred_gen_PI.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-113006011-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Learning Data Science</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Frontmatter
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../preface.html">
   To the Data 100 Student
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prereqs.html">
   Prerequisites
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../notation.html">
   Notation
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  The Data Science Lifecycle
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01/lifecycle_intro.html">
   1. The Data Science Lifecycle
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_cycle.html">
     1.1. The Stages of the Lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_map.html">
     1.2. Examples of the Lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_summary.html">
     1.3. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02/data_scope_intro.html">
   2. Questions and Data Scope
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_big_data_hubris.html">
     2.1. Big Data and New Opportunities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_construct.html">
     2.2. Target Population, Access Frame, Sample
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_protocols.html">
     2.3. Instruments and Protocols
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_natural.html">
     2.4. Measuring Natural Phenomenon
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_accuracy.html">
     2.5. Accuracy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_summary.html">
     2.6. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03/theory_intro.html">
   3. Simulation and Data Design
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/theory_urn.html">
     3.1. The Urn Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/theory_election.html">
     3.2. Example: Simulating Election Poll Bias and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/theory_vaccine_efficacy.html">
     3.3. Example: Simulating a Randomized Trial for a Vaccine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/theory_measurement_error.html">
     3.4. Example: Measurement Error in Air Quality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/theory_summary.html">
     3.5. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04/modeling_intro.html">
   4. Modeling with Summary Statistics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/modeling_simple.html">
     4.1. The Constant Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/modeling_loss_functions.html">
     4.2. Loss Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/modeling_summary.html">
     4.3. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../05/bus_intro.html">
   5. Case Study: Why is my Bus Always Late?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/bus_scope.html">
     5.1. Question and Scope
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/bus_clean.html">
     5.2. Data Wrangling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/bus_eda.html">
     5.3. Exploring Bus Times
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/bus_modeling.html">
     5.4. Modeling Wait Times
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/bus_summary.html">
     5.5. Summary
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Rectangular Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../06/pandas_intro.html">
   6. Working With Dataframes Using pandas
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_subsetting.html">
     6.1. Subsetting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_aggregating.html">
     6.2. Aggregating
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_joining.html">
     6.3. Joining
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_transforming.html">
     6.4. Transforming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_other_reps.html">
     6.5. How are Dataframes Different from Other Data Representations?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_summary.html">
     6.6. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../07/sql_intro.html">
   7. Working With Relations Using SQL
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_subsetting.html">
     7.1. Subsetting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_aggregating.html">
     7.2. Aggregating
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_joining.html">
     7.3. Joining
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_transforming.html">
     7.4. Transforming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_other_reps.html">
     7.5. How are Relations Different from Other Data Representations?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_summary.html">
     7.6. Conclusion
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Understanding The Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08/files_intro.html">
   8. Wrangling Files
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_datasets.html">
     8.1. Data Source Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_formats.html">
     8.2. File Formats
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_size.html">
     8.3. File Size
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_command_line.html">
     8.4. The Shell and Command Line Tools
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_granularity.html">
     8.5. Table Shape and Granularity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/files_summary.html">
     8.6. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../09/wrangling_intro.html">
   9. Wrangling Dataframes
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_co2.html">
     9.1. Example: Wrangling CO2 Measurements from Mauna Loa Observatory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_checks.html">
     9.2. Quality Checks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_missing.html">
     9.3. Missing Values and Records
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_transformations.html">
     9.4. Transformations and Timestamps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_structure.html">
     9.5. Modifying Structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_restaurants.html">
     9.6. Example: Wrangling Restaurant Safety Violations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/wrangling_summary.html">
     9.7. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../10/eda_intro.html">
   10. Exploratory Data Analysis
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_feature_types.html">
     10.1. Feature Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_distributions.html">
     10.2. What to Look For in a Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_relationships.html">
     10.3. What to Look For in a Relationship?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_guidelines.html">
     10.4. Guidelines for Exploration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_example.html">
     10.5. Example: Sale Prices for Houses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_summary.html">
     10.6. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../11/viz_intro.html">
   11. Data Visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_scale.html">
     11.1. Choosing Scale to Reveal Structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_smoothing.html">
     11.2. Smoothing and Aggregating Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_comparisons.html">
     11.3. Facilitating Meaningful Comparisons
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_data_design.html">
     11.4. Incorporating the Data Design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_context.html">
     11.5. Adding Context
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_plotly.html">
     11.6. Creating Plots Using
     <code class="docutils literal notranslate">
      <span class="pre">
       plotly
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_other_tools.html">
     11.7. Other Tools for Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_summary.html">
     11.8. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../12/pa_intro.html">
   12. Case Study: Data Science for Accurate and Timely Air Quality Measurements
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_collocated.html">
     12.1. Finding Collocated Sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_cleaning_aqs.html">
     12.2. Exploring and Cleaning AQS Sensor Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_cleaning_purpleair.html">
     12.3. Exploring and Cleaning PurpleAir Sensor Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_modeling.html">
     12.4. Creating a Model to Correct PurpleAir Measurements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_conclusion.html">
     12.5. In Conclusion
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Other Data Sources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../13/text_intro.html">
   13. Working with Text
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/text_examples.html">
     13.1. Examples of Text and Tasks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/text_strings.html">
     13.2. String Manipulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/text_regex.html">
     13.3. Regular Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/text_sotu.html">
     13.4. Text Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/text_summary.html">
     13.5. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../14/web_intro.html">
   14. Web Technologies
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/web_http.html">
     14.1. HTTP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/web_rest.html">
     14.2. [In Progress] REST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/web_html.html">
     14.3. [In Progress] XPath and HTML
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Linear Modeling
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../15/linear_intro.html">
   15. Linear Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_simple.html">
     15.1. Simple Linear Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_simple_fit.html">
     15.2. Fitting the Simple Linear Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_multi.html">
     15.3. Multiple Linear Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_multi_fit.html">
     15.4. Fitting the Multiple Linear Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_case.html">
     15.5. Example: Where is the Land of Opportunity?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_feature_eng.html">
     15.6. Feature Engineering for Numeric Measurements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_categorical.html">
     15.7. Feature Engineering for Categorical Measurements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_summary.html">
     15.8. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="inf_pred_gen_intro.html">
   16. Theory for Inference and Prediction
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="inf_pred_gen_dist.html">
     16.1. Distributions: Population, Empirical, Sampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="inf_pred_gen_HT.html">
     16.2. Basics of Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="inf_pred_gen_boot.html">
     16.3. Bootstrapping for Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="inf_pred_gen_CI.html">
     16.4. Basics of Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="inf_pred_gen_PI.html">
     16.5. Basics of Prediction Intervals
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     16.6. Probability for Inference and Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="inf_pred_gen_summary.html">
     16.7. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../17/ms_intro.html">
   17. Model Selection
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/ms_overfitting.html">
     17.1. Overfitting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/ms_train_test.html">
     17.2. Train-Test Split
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/ms_cv.html">
     17.3. Cross-Validation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/ms_regularization.html">
     17.4. Regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/ms_risk.html">
     17.5. Risk and Loss Minimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/ms_summary.html">
     17.6. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../18/donkey_intro.html">
   18. Case Study: How to Weigh a Donkey
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../18/donkey_scope.html">
     18.1. Donkey Study Question and Scope
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18/donkey_clean.html">
     18.2. Wrangling and Transforming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18/donkey_eda.html">
     18.4. Exploring
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18/donkey_model.html">
     18.5. Modeling a Donkey’s Weight
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18/donkey_summary.html">
     18.6. Summary
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Classification
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../19/classification_intro.html">
   19. Classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/classification_prob.html">
     19.1. Regression on Probabilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/classification_log_model.html">
     19.2. The Logistic Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/classification_cost.html">
     19.3. A Loss Function for the Logistic Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/classification_log_reg.html">
     19.4. Using Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/classification_cost_justification.html">
     19.5. Approximating the Empirical Probability Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/classification_sgd.html">
     19.6. Fitting a Logistic Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/classification_sensitivity_specificity.html">
     19.7. Evaluating Logistic Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/classification_multiclass.html">
     19.8. Multiclass Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../20/gd_intro.html">
   20. Numerical Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/gd_basics.html">
     20.1. Gradient Descent Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/gd_example.html">
     20.2. Minimizing Huber Loss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/gd_convex.html">
     20.3. Convex and Differentiable Loss Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/gd_alternative.html">
     20.4. Variants of Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/gd_summary.html">
     20.5. Summary
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Extra Topics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../21/repl_intro.html">
   21. Replicable Research
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
  <label for="toctree-checkbox-21">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../21/repl_phacking.html">
     21.1. P-hacking
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../22/pca_intro.html">
   22. Dimensionality Reduction and PCA
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../22/pca_dims.html">
     22.1. Dimensions of a Data Table
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../22/pca_svd.html">
     22.2. PCA using the Singular Value Decomposition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../22/pca_in_practice.html">
     22.3. PCA in Practice
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../23/dtrees_intro.html">
   23. Decision Trees and Random Forests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../24/clustering_intro.html">
   24. Clustering
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Appendices
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../a01/prob_review.html">
   Probability Review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../a02/vector_space_review.html">
   Vector Space Review
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../a03/hyp_intro.html">
   Statistical Inference Review
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../a03/hyp_introduction.html">
     Hypothesis Testing and Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a03/hyp_introduction_part2.html">
     Permutation Test
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../a04/ref_intro.html">
   Reference Tables
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
  <label for="toctree-checkbox-24">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_pandas.html">
     pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_seaborn.html">
     Seaborn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_matplotlib.html">
     matplotlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_sklearn.html">
     scikit-learn
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../a05/bias_intro.html">
   The Bias-Variance Tradeoff
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
  <label for="toctree-checkbox-25">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../a05/bias_risk.html">
     Risk and Loss Minimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a05/bias_modeling.html">
     Model Bias and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a05/bias_cv.html">
     Cross-Validation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../a06/reg_intro.html">
   Regularization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
  <label for="toctree-checkbox-26">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../a06/reg_intuition.html">
     Regularization Intuition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a06/reg_ridge.html">
     L2 Regularization: Ridge Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a06/reg_lasso.html">
     L1 Regularization: Lasso Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../a07/contributors.html">
   Contributors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../references.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/ch/16/inf_pred_gen_prob.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        <a class="jupyterhub-button" href="https://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/ds-100/textbook&urlpath=tree/textbook/content/ch/16/inf_pred_gen_prob.ipynb&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#formalizing-the-theory-for-average-rank-statistics">
   16.6.1. Formalizing the theory for average rank statistics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#general-properties-of-random-variables">
   16.6.2. General properties of random variables
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probability-behind-testing-and-intervals">
   16.6.3. Probability behind testing and intervals
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Probability for Inference and Prediction</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#formalizing-the-theory-for-average-rank-statistics">
   16.6.1. Formalizing the theory for average rank statistics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#general-properties-of-random-variables">
   16.6.2. General properties of random variables
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probability-behind-testing-and-intervals">
   16.6.3. Probability behind testing and intervals
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="section" id="probability-for-inference-and-prediction">
<span id="sec-theory-probintro"></span><h1><span class="section-number">16.6. </span>Probability for Inference and Prediction<a class="headerlink" href="#probability-for-inference-and-prediction" title="Permalink to this headline">¶</a></h1>
<p>Hypothesis testing, confidence intervals, and prediction intervals rely on probability calculations computed from the sampling distribution and the data generation process. These probability frameworks also enable us to run simulation and bootstrap studies for a hypothetical survey, an experiment, or some other chance process in order to study its random behavior. For example, we found the sampling distribution for an average of ranks under the assumption that the treatment in a Wikipedia experiment was not effective. Using simulation, we quantified the typical deviations from the expected outcome and the distribution of the possible values for the summary statistic. The triptych in <a class="reference internal" href="inf_pred_gen_dist.html#triptych"><span class="std std-numref">Figure 1 16.1</span></a> provided a diagram to guide us in the process; it helped keep straight the differences between the population, probability, and sample and also showed their connections. In this section, we bring more mathematical rigor to these concepts.</p>
<p>We formally introduce the notions of expected value, standard deviation, and random variable, and we connect them to the concepts we have been using in this chapter for testing hypotheses and making confidence and prediction intervals. We begin with the specific example from the Wikipedia experiment, before we generalize them. Along the way, we connect this formalism to the triptych that we have used as our guide throughout the chapter.</p>
<div class="figure align-default" id="triptychrank">
<img alt="../../_images/TriptychRank.png" src="../../_images/TriptychRank.png" />
<p class="caption"><span class="caption-number">Fig. 16.3 </span><span class="caption-text">This diagram shows the population, sampling, and sample distributions and their summaries from the Wikipedia example. In this example, the population is known to consist of the integers from 1 to 200, and the sample are the ranks of the observed post-productivity measurements for the treatment group. In the middle, the sampling distribution of the average rank is created from a simulation study. Notice it is normal in shape with a center that matches the population average.</span><a class="headerlink" href="#triptychrank" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="formalizing-the-theory-for-average-rank-statistics">
<h2><span class="section-number">16.6.1. </span>Formalizing the theory for average rank statistics<a class="headerlink" href="#formalizing-the-theory-for-average-rank-statistics" title="Permalink to this headline">¶</a></h2>
<p>Recall in the Wikipedia experiment, we pooled the post-award productivity values from the treatment and control groups and converted them into ranks, <span class="math notranslate nohighlight">\(1, 2, 3, \ldots, 200\)</span> so the population is simply made up of the integers from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(200\)</span>. <a class="reference internal" href="#triptychrank"><span class="std std-numref">Figure 16.3</span></a> is a diagram that represents this specific situation. Notice that the population distribution is flat and ranges from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(200\)</span> (see leftside of <a class="reference internal" href="#triptychrank"><span class="std std-numref">Figure 16.3</span></a>). Also, the population summary (called <em>population parameter</em>) we have used is the average rank:</p>
<div class="math notranslate nohighlight">
\[\theta^* ~=~ Avg(pop) ~=~  \frac{1}{200} \Sigma_{k=1}^{200} k ~=~ 100.5. \]</div>
<p>Another relevant summary is the spread about <span class="math notranslate nohighlight">\(\theta^*\)</span>, defined as the population standard deviation:</p>
<div class="math notranslate nohighlight">
\[ SD(pop) ~=~ \sqrt{\frac {1}{200} \Sigma_{k=1}^{200} (k - \theta^*)^2} ~=~  
\sqrt{\frac {1}{200} \Sigma_{k=1}^{200} (k - 100.5)^2}
~\approx~ 57.7 \]</div>
<p>The SD(pop) represents the typical deviation of a rank from the population average.   To calculate SD(pop) for this example takes some mathematical handiwork. If you want to learn more see Pitman.</p>
<p>The observed sample consists of the integer ranks of the treatment group; we refer to these values as <span class="math notranslate nohighlight">\(k_1, k_2, \ldots, k_{100}.\)</span> The sample distribution appears on the right in <a class="reference internal" href="#triptychrank"><span class="std std-numref">Figure 16.3</span></a> (each of the 100 integers appears once).</p>
<p>A parallel to the population average is the sample average, which is our statistic of interest:</p>
<div class="math notranslate nohighlight">
\[ Avg(sample) ~=~  \frac{1}{100} \Sigma_{i=1}^{100} k_i ~=~ \bar{k} ~=~113.7. \]</div>
<p>The <span class="math notranslate nohighlight">\(Avg(sample)\)</span> is the observed value for <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>. Similarly, the spread about <span class="math notranslate nohighlight">\(Avg(sample)\)</span>, called the standard deviation of the sample, represents the typical deviation of a rank in the sample from the sample average:</p>
<div class="math notranslate nohighlight">
\[ SD(sample) ~=~ \sqrt{\frac {1}{100} \Sigma_{i=1}^{100} (k_i - \bar{k})^2} ~=~ 55.3.\]</div>
<p>Notice the parallel between the definitions of the sample statistic and the population parameter, in the case where they are averages. The parallel between the two SDs is also note worthy.</p>
<p>Next we turn to the data generation process: draw 100 marbles from the urn (with values <span class="math notranslate nohighlight">\(1, 2,\ldots,200\)</span>), without replacement, to create the treatment ranks.  We represent the action of drawing the first marble from the urn and the integer that we get, by the capital letter <span class="math notranslate nohighlight">\(Z_1\)</span>. This <span class="math notranslate nohighlight">\(Z_1\)</span> is called a <em>random variable</em>. It has a probability distribution determined by the urn model. That is, we can list all of the values that <span class="math notranslate nohighlight">\(Z_1\)</span> might take and the probability associated with each:</p>
<div class="math notranslate nohighlight">
\[{\mathbb{P}}(Z_1 = k) ~=~ \frac{1}{200} ~~~~\textrm{ for } k=1, \ldots, 200.\]</div>
<p>In this example, the probability distribution of <span class="math notranslate nohighlight">\(Z_1\)</span> is determined by a simple formula because all of the integers are equally likely to be drawn from the urn. (<a class="reference internal" href="../03/theory_intro.html#ch-theory-datadesign"><span class="std std-numref">Chapter 3</span></a> first introduces the notion of a probability distribution).</p>
<p>We often summarize the distribution of a random variable by its <em>expected value</em> and <em>standard deviation</em>. Like with the population and sample, these two quantities give us a sense of what to expect as an outcome and how far the actual value might be from what is expected.</p>
<p>For our example, the expected value of <span class="math notranslate nohighlight">\(Z_1\)</span> is simply,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{E}[Z_1]
&amp;= 1 \mathbb{P}(Z_1 = 1) + 2 \mathbb{P}(Z_1 = 2) +  \cdots + 200 \mathbb{P}(Z_1 = 200) \\
&amp;= 1 \times \frac{1}{200} + 2 \times \frac{1}{200} + \cdots + 200 \times \frac{1}{200} \\
&amp;= 100.5
\end{aligned}
\end{split}\]</div>
<p>Notice that <span class="math notranslate nohighlight">\(\mathbb{E}[Z_1] = \theta^*\)</span>, the population average from the urn. The average value in a population and the expected value of a random variable that represents one draw at random  from an urn that contains the population are always the same. This is more easily seen by expressing the population average as a weighted average of the unique values in the population weighted by the fraction of units that have that value. The expected value of a random variable of a draw at random from the population urn uses the exact same weights because they match the chance of selecting the particular value.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The term <em>expected value</em> can be a bit confusing because it need not be a possible value of the random variable. For example, <span class="math notranslate nohighlight">\(\mathbb{E}[Z_1] = 100.5\)</span>, but only integers are possible values for <span class="math notranslate nohighlight">\(Z_1\)</span>.</p>
</div>
<p>Next, the variance of <span class="math notranslate nohighlight">\(Z_1\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{V}(Z_1)
&amp;= (1 - \mathbb{E}[Z_1)]^2 \mathbb{P}(Z_1 = 1) + \cdots + [200 - \mathbb{E}(Z_1)]^2  \mathbb{P}(Z_1 = 200) \\
&amp;= (1 - 100.5)^2 \times \frac{1}{200} + \cdots + (200 - 100.5)^2  \times \frac{1}{200} \\
&amp;= 3333.25
\end{aligned}
\end{split}\]</div>
<p>Additionally,</p>
<div class="math notranslate nohighlight">
\[
SD(Z_1) = \sqrt{\mathbb{V}(Z_1)} = 57.7
\]</div>
<p>We again point out that the standard deviation of <span class="math notranslate nohighlight">\(Z_1 \)</span> matches the <span class="math notranslate nohighlight">\(SD(pop)\)</span>.</p>
<p>To describe the entire data generation process in <a class="reference internal" href="#triptychrank"><span class="std std-numref">Figure 16.3</span></a>, we also define, <span class="math notranslate nohighlight">\(Z_2 , Z_3, \ldots, Z_{100}\)</span> as the result of the remaining 99 draws from the urn. By symmetry these random variables should all have the same probability distribution. That is, for any <span class="math notranslate nohighlight">\(k = 1, \ldots, 200\)</span>,</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}(Z_1 = k) ~=~ \mathbb{P}(Z_2 = k) ~=~ \cdots ~=~ \mathbb{P}(Z_{100} = k) ~=~ \frac{1}{200}.\]</div>
<p>This implies that each <span class="math notranslate nohighlight">\(Z_i\)</span> has the same expected value, 100.5, and standard deviation, 57.7.  However, these random variables are not independent. For example, if you know that <span class="math notranslate nohighlight">\(Z_1 = 17\)</span>, then it is not possible for <span class="math notranslate nohighlight">\(Z_2 = 17\)</span>.</p>
<p>To complete the middle portion of <a class="reference internal" href="#triptychrank"><span class="std std-numref">Figure 16.3</span></a>, which involves the sampling distribution of <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>, we express the average rank statistic as follows:</p>
<div class="math notranslate nohighlight">
\[\hat{\theta} = \frac{1}{100} \Sigma_{i=1}^{100} Z_i\]</div>
<p>We can use the expected value and SD of <span class="math notranslate nohighlight">\(Z_1\)</span> and our knowledge of the data generation process to find the expected value and SD of <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>. However, we need some more information about how combinations of random variables behave so we first present the results and then circle back to explain why. We first find the expected value of <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbb{E}(\hat{\theta}) ~&amp;=~ \mathbb{E}[\frac{1}{100} \Sigma_{i=1}^{100} Z_i]\\
~&amp;=~ \frac{1}{100} \Sigma_{i=1}^{100} \mathbb{E}[Z_i] \\
~&amp;=~  100.5 \\
~&amp;=~ \theta^*
\end{align}
\end{split}\]</div>
<p>In other words, the expected value of the average of random draws from the population equals the population average. Below we provide formulas for the variance of the average in terms of the population variance, as well as the SD.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbb{V}(\hat{\theta}) ~&amp;=~ \mathbb{V}[\frac{1}{100} \Sigma_{i=1}^{100} Z_i]\\
 ~&amp;=~ \frac{200-100}{100-1} \times \frac{\mathbb{V}(Z_i)}{100} \\
 ~&amp;=~ 16.75 \\
 ~&amp;~\\
 SD(\hat{\theta}) ~&amp;=~ \sqrt{\frac{100}{199}} \frac{SD(Z_1)}{10} \\
 ~&amp;=~ 4.1 
\end{align}
\end{split}\]</div>
<p>These computations relied on several properties of expected value and variance of a random variable and sums of random variables. Next we describe several useful properties of sums and averages of random variables. These can be used to derive the formulas we just presented for the expected value and SD of the average from a population.</p>
</div>
<div class="section" id="general-properties-of-random-variables">
<h2><span class="section-number">16.6.2. </span>General properties of random variables<a class="headerlink" href="#general-properties-of-random-variables" title="Permalink to this headline">¶</a></h2>
<p>In general, a <em>random variable</em> represents a numeric outcome of a probabilistic event. In this book, we use capital letters like <span class="math notranslate nohighlight">\(X\)</span> or <span class="math notranslate nohighlight">\(Y\)</span> or <span class="math notranslate nohighlight">\(Z\)</span> to denote a random variable. The probability distribution for <span class="math notranslate nohighlight">\(X\)</span> is the specification, <span class="math notranslate nohighlight">\(\mathbb{P}(X = x) = p_x\)</span> for all values <span class="math notranslate nohighlight">\(x\)</span> that the random variable takes on.</p>
<p>Then, the expected value of <span class="math notranslate nohighlight">\(X\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[X] = \sum_{x} x p_x,\]</div>
<p>the variance <span class="math notranslate nohighlight">\(X\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbb{V}(X) ~&amp;=~ \mathbb{E}[(X - \mathbb{E}[X])^2] \\
 ~&amp;=~ \sum_{x} [x - \mathbb{E}(X)]^2  p_x,
\end{align}
\end{split}\]</div>
<p>and, the <span class="math notranslate nohighlight">\(SD(X)\)</span> is the square-root of <span class="math notranslate nohighlight">\(\mathbb{V}(X)\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although random variables can represent either discrete (such as, the number of children in a family drawn at random from a population) or continuous (such as, the air quality measured by an air monitor) quantities, we address only random variables with discrete outcomes in this book. Since most measurements are made to a certain degree of precision, this simplification doesn’t limit us too much.</p>
</div>
<p>Simple formulas provide the expected value, variance, and standard deviation when we make scale and shift changes to random variables, such as <span class="math notranslate nohighlight">\(a + bX\)</span> for constants <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{E}(a + bX) ~&amp;=~ a + b\mathbb{E}(X)  \\
\mathbb{V}(a + bX) ~&amp;=~ b^2\mathbb{V}(X) \\
SD(a + bX) ~&amp;=~ |b|SD(X) \\
\end{aligned}
\end{split}\]</div>
<p>To convince yourself that these formulas make sense, think about how a distribution changes if you added a constant <span class="math notranslate nohighlight">\(a\)</span> to each value: it would simply shift the distribution, which in turn would shift the expected value but not change the size of the deviations about the expected value. On the other hand, scaling the values by, say, 2 would spread the distribution out and essentially double the deviations from the expected value.</p>
<p>We are also interested in the properties of the sum of two or more random variables. Let’s consider two random variables, say <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>. Then,</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}(a + bX + cY) ~=~ a + b\mathbb{E}(X) + c\mathbb{E}(Y).
\]</div>
<p>But, to find the variance of <span class="math notranslate nohighlight">\(a + bX + cY\)</span>, we need to know how <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> vary together, which is called the <em>joint distribution</em> of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>. The joint distribution of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> assigns probabilities to combinations of their outcomes,</p>
<div class="math notranslate nohighlight">
\[ 
\mathbb{P}(X =x, Y=y) ~=~ p_{x,y} 
\]</div>
<p>A summary of how <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> vary together, called the covariance, is defined as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
Cov(X, Y) ~&amp;=~ \mathbb{E}[(X - \mathbb{E}[X])(Y - \mathbb{E}[Y])] \\
 ~&amp;=~ \mathbb{E}[(XY) - \mathbb{E}(X)\mathbb{E}(Y)] \\
 ~&amp;=~ \Sigma{x,y}[(xy) - \mathbb{E}(X)\mathbb{E}(Y)]p_{x,y} 
 \end{align}
\end{split}\]</div>
<p>The covariance enters into the calculation of <span class="math notranslate nohighlight">\(\mathbf(a + bX + cY)\)</span>, as shown below:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{V}(a + bX + cY) ~=~ b^2\mathbb{V}(X) + 2bcCov(X,Y) + c^2\mathbb{V}(Y)
\]</div>
<p>In the special case where <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are independent, their joint distribution is simplified to  <span class="math notranslate nohighlight">\(p_{x,y} = p_x p_y\)</span>. And, in this case, <span class="math notranslate nohighlight">\(Cov(X,Y) = 0\)</span> so</p>
<div class="math notranslate nohighlight">
\[
\mathbb{V}(a + bX + cY) ~=~ b^2\mathbb{V}(X) + c^2\mathbb{V}(Y)
\]</div>
<p>These properties can be used to show that for random variables, <span class="math notranslate nohighlight">\(X_1, X_2, \ldots X_n\)</span>, that are independent with expected value <span class="math notranslate nohighlight">\(\mu\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>, the average, <span class="math notranslate nohighlight">\(\bar{X}\)</span>, has the following expected value, variance, and standard deviation.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbb{E}(\bar{X}) ~&amp;=~ \mu\\
\mathbb{V}(\bar{X}) ~&amp;=~ \sigma^2 /n\\
SD(\bar{X}) ~&amp;=~ \sigma/\sqrt{n}
\end{align}
\end{split}\]</div>
<p>This situation arises with the urn model where <span class="math notranslate nohighlight">\(X_1, \ldots,X_n\)</span> are the result of random draws with replacement. In this case, <span class="math notranslate nohighlight">\(\mu\)</span> represents the average of the urn and <span class="math notranslate nohighlight">\(\sigma\)</span> the standard deviation.</p>
<p>However, when we made random draws from the urn, they were made without replacement. In this situation, <span class="math notranslate nohighlight">\(\bar{X}\)</span> has the following expected value and variance:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbb{E}(\bar{X}) ~&amp;=~ \mu\\
\mathbb{V}(\bar{X}) ~&amp;=~ \frac{N-n}{N-1} \times \frac{\sigma^2}{n}\\
\end{align}
\end{split}\]</div>
<p>Notice that while the expected value is the same as when the draws are without replacement, the variance and SD are smaller. These quantities are adjusted by <span class="math notranslate nohighlight">\((N-n/(N-1)\)</span>, which is called the <em>finite population correction factor</em>.  We used this formula earlier to compute the <span class="math notranslate nohighlight">\(SD(\hat{\theta})\)</span> in our Wikipedia example.</p>
<p>Returning to <a class="reference internal" href="#triptychrank"><span class="std std-numref">Figure 16.3</span></a>, we see that the sampling distribution for <span class="math notranslate nohighlight">\(\bar{X}\)</span> in the center of the diagram has an expectation that matches the population average; the SD decreases like <span class="math notranslate nohighlight">\(1/\sqrt{n}\)</span> but even faster because we are drawing without replacement; and the distribution is shaped like a normal curve.  We saw these properties earlier in our simulation study, any you can read more about the probability theory behind these observations in XX.</p>
<p>Now that we have outlined the general properties of random variables and their sums, we connect these ideas to testing, confidence, and prediction intervals.</p>
</div>
<div class="section" id="probability-behind-testing-and-intervals">
<h2><span class="section-number">16.6.3. </span>Probability behind testing and intervals<a class="headerlink" href="#probability-behind-testing-and-intervals" title="Permalink to this headline">¶</a></h2>
<p>As mentioned at the beginning of this chapter, probability is the underpinning behind conducting a hyptohesis test, providing a confidence interval for an estimator and a prediction interval for a future observation.</p>
<p>We now have the technical machinery to explain these concepts, which we have carefully defined in this chapter without the use of formal technicalities. This time we present the results in terms of random variables and their distributions.</p>
<p>Recall that a hypothesis test relies on a null model which provides the probability distribution for the statistic, <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>. The tests we carried out were essentially computing (sometimes approximately) the following probability: given the assumptions of the null distribution,</p>
<div class="math notranslate nohighlight">
\[ \mathbb{P}(\hat{\theta} \geq \textrm{observed statistic}) \]</div>
<p>Often times, the random variable is normalized to make these computations easier and standard:</p>
<div class="math notranslate nohighlight">
\[ 
\mathbb{P}\left( \frac{\hat{\theta} - {\theta}^*}{SD(\hat{\theta})} \geq \frac{\textrm{observed stat}- \theta^*}{SD(\hat{\theta})}\right)\]</div>
<p>When, <span class="math notranslate nohighlight">\(SD(\hat{\theta})\)</span> is not known, we have approximated it via simulation or, when we have a formula for <span class="math notranslate nohighlight">\(SD(\hat{\theta})\)</span> in terms of <span class="math notranslate nohighlight">\(SD(pop)\)</span>, we substitute <span class="math notranslate nohighlight">\(SD(samp)\)</span> in for <span class="math notranslate nohighlight">\(SD(pop)\)</span>. This normalization is popular because it simplifies the null distribution. For example, if <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> has an approximate normal distribution than the normalized version will have a standard normal distribution with center 0 and SD of 1. These approximations are useful if a lot of hypothesis tests are being carried out, such as with A/B testing, for there is no need to simulate every for every statistic because we can just use the normal curve probabilities.</p>
<p>The probability statement behind a confidence interval is quite similar to the probability calculations used in testing. In particular, to create a 95% confidence interval where the sampling distribution of the estimator is roughly normal, we standardize and use the probability,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}\left( \frac{|\hat{\theta} - \theta^*|}{SD(\hat{\theta})} \leq 1.96 \right) &amp;~=~ \mathbb{P}\left(\hat{\theta} - 1.96SD(\hat{\theta}) \leq \theta^* \leq \hat{\theta} + 1.96SD(\hat{\theta}) \right) \\
&amp;~\approx~ 0.95
\end{aligned}
\end{split}\]</div>
<p>Note that <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> is a random variable in the above probability statement and <span class="math notranslate nohighlight">\(\theta^*\)</span> is considered a fixed unknown parameter value. The confidence interval is created by substituting the observed statistic in for <span class="math notranslate nohighlight">\(\hat\theta\)</span> and calling it a 95% confidence interval:</p>
<div class="math notranslate nohighlight">
\[
\left[\textrm{observed stat} - 1.96SD(\hat{\theta}),~ \textrm{observed stat} + 1.96SD(\hat{\theta}) \right]
\]</div>
<p>Once the observed statistic is substituted in for the random variable, then we say that we are 95% confident that the interval we have created contains the true value <span class="math notranslate nohighlight">\(\theta^*\)</span>. In other words, in 100 cases where we compute an interval in this way, we expect 95 of them to cover the population parameter that we are estimating. We show how to simulate this scenario in the Exercises.</p>
<p>Lastly, we consider prediction intervals. The basic notion is to provide an interval that denotes the expected variation of a future observation about the estimator. In the simple case, where the statistic is <span class="math notranslate nohighlight">\(\bar{X}\)</span> and we have a hypothetical new observation <span class="math notranslate nohighlight">\(X_0\)</span> that has the same expected value, say <span class="math notranslate nohighlight">\(\mu\)</span>, and standard deviation, say <span class="math notranslate nohighlight">\(\sigma\)</span>, of each <span class="math notranslate nohighlight">\(X_i\)</span>, then we find the expected variation of the squared loss:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{E}[(X_0 - \bar{X})^2] ~&amp;=~ \mathbb{E}\{[(X_0 - \mu) - (\bar{X} - \mu)]^2\} \\
 ~&amp;=~  \mathbb{V}(X_0) + \mathbb{V}(\bar{X}) \\
 ~&amp;=~  \sigma^2 + \sigma^2/n \\
 ~&amp;=~ \sigma\sqrt{1 + 1/n}
\end{aligned}
\end{split}\]</div>
<p>Notice there are two parts to the variation: one due to the variation of <span class="math notranslate nohighlight">\(X_0\)</span> and the other due to the approximation of <span class="math notranslate nohighlight">\(\mathbb{E}(X_0)\)</span> by <span class="math notranslate nohighlight">\(\bar{X}\)</span>.</p>
<p>In the case of more complex models, the variation in prediction also breaks down into two components: the inherent variation in the data about the model plus the variation in the sampling distribution due to the estimation of the model. Assuming the model is roughly correct,
we can express it as follows:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{Y} ~=~ \textbf{X}\boldsymbol{\theta}^{*} + \boldsymbol{\epsilon},
\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^*\)</span> is a <span class="math notranslate nohighlight">\((p+1) \times 1\)</span> column vector, <span class="math notranslate nohighlight">\(\textbf{X}\)</span> is a <span class="math notranslate nohighlight">\(n \times (p+1)\)</span> design matrix, and <span class="math notranslate nohighlight">\(\boldsymbol{\epsilon}\)</span> consists of <span class="math notranslate nohighlight">\(n\)</span> independent random variables that each has expected value 0 and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>. In this equation, <span class="math notranslate nohighlight">\(\mathbf{Y}\)</span> is a
vector of random variables, where the expected value of each variable is determined by the design matrix and the variance is <span class="math notranslate nohighlight">\(\sigma^2\)</span>. That is, the variation about the line is constant in that it does not change with <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>.</p>
<p>When we create prediction intervals in regression, they are given an <span class="math notranslate nohighlight">\(1 \times (p+1)\)</span> row vector of covariates, called <span class="math notranslate nohighlight">\(\mathbf{x}_0\)</span>. the prediction is <span class="math notranslate nohighlight">\(\mathbf{x}_0\boldsymbol{\hat{\theta}}\)</span>, where <span class="math notranslate nohighlight">\(\boldsymbol{\hat{\theta}}\)</span> is the estimated parameter vector based on the original
<span class="math notranslate nohighlight">\(\mathbf{y}\)</span> and design matrix <span class="math notranslate nohighlight">\(\textbf{X}\)</span>. The expected squared error in this prediction is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{E}[(Y_0 - \mathbf{x_0} \boldsymbol{\hat{\theta}})^2] ~&amp;=~ 
\mathbb{E}\{[(Y_0 - \mathbf{x_0\boldsymbol{\theta}^{*} }) - (\mathbf{x_0}\boldsymbol{\hat{\theta}}  - \mathbf{x_0}\boldsymbol{\theta}^{*})]^2\} \\
 ~&amp;=~  \mathbb{V}(\epsilon) + \mathbb{V}(\mathbf{x_0}\boldsymbol{\hat{\theta}}) \\
 ~&amp;=~  \sigma^2 [1 + \mathbf{x}_0 (\textbf{X}^\top \textbf{X})^{-1} \mathbf{x}_0^\top] \\
\end{aligned}
\end{split}\]</div>
<p>We approximate the variance of <span class="math notranslate nohighlight">\(\epsilon\)</span> with the variance of the residuals from the least squares fit.</p>
<p>The prediction intervals we create using the normal curve rely on the additional assumption that the distribution of the errors is approximately normal. This is a stronger assumption than we  make for the confidence intervals. With confidence intervals, the probability distribution of <span class="math notranslate nohighlight">\(X_i\)</span> need not look normal for <span class="math notranslate nohighlight">\(\bar{X}\)</span> to have an approximate normal distribution. Similarly, the probability distribution of <span class="math notranslate nohighlight">\(\boldsymbol{\epsilon}\)</span> in the linear model need not look normal for the estimator <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> to have an approximate normal distribution.</p>
<p>We also assume that the linear model is approximately correct when making these prediction intervals. In <a class="reference internal" href="../17/ms_intro.html#ch-risk"><span class="std std-numref">Chapter 17</span></a> we consider the case where the fitted model doesn’t match the model that has produced the data.</p>
<p>While we have covered a lot of theory in this chapter, we have attempted to tie it to the basics of the urn model and the three distributions: population, sample, and sampling. We wrap up the chapter with a few cautions to keep in mind when performing hypothesis tests and when making confidence or prediction intervals.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch/16"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="inf_pred_gen_PI.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">16.5. </span>Basics of Prediction Intervals</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="inf_pred_gen_summary.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">16.7. </span>Summary</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Sam Lau, Joey Gonzalez, and Deb Nolan<br/>
    
        &copy; Copyright 2023.<br/>
      <div class="extra_footer">
        <p>
License: CC BY-NC-ND 4.0
</p>

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>