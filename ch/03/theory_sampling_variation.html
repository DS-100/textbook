
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3.1. Sampling Variation &#8212; Principles and Techniques of Data Science</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="3.2. Random Assignment" href="theory_random_assignment.html" />
    <link rel="prev" title="3. Theory for Data Design" href="theory_intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-113006011-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Principles and Techniques of Data Science</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Frontmatter
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../preface.html">
   To the Reader
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prereqs.html">
   Prerequisites
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../notation.html">
   Notation
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  The Data Science Lifecycle
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01/lifecycle_intro.html">
   1. The Data Science Lifecycle
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_students_1.html">
     1.1. The Students of Data 100
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_students_2.html">
     1.2. Exploratory Data Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_students_3.html">
     1.3. What’s in a Name?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02/data_scope_intro.html">
   2. Data Scope
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_big_data_hubris.html">
     2.1. Big Data Hubris
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_construct.html">
     2.2. A Construct for Data Scope
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_accuracy.html">
     2.3. Accuracy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data_scope_exercises.html">
     2.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="theory_intro.html">
   3. Theory for Data Design
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     3.1. Sampling Variation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="theory_random_assignment.html">
     3.2. Random Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="theory_measurement_error.html">
     3.3. Measurement Error
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="theory_prob_dist.html">
     3.4. Probability Distribution for a Statistic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="theory_exercises.html">
     3.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04/modeling_intro.html">
   4. Modeling and Estimation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/modeling_simple.html">
     4.1. Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/modeling_loss_functions.html">
     4.2. Loss Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/modeling_abs_huber.html">
     4.3. Absolute and Huber Loss
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../05/cycle_case_study_intro.html">
   5. [In progress] Case Study
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Rectangular Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../06/pandas_intro.html">
   6. Working With Dataframes Using pandas
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_subsetting.html">
     6.1. Subsetting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_aggregating.html">
     6.2. Aggregating
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_joining.html">
     6.3. Joining
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_transforming.html">
     6.4. Transforming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_other_reps.html">
     6.5. How are Dataframes Different from Other Data Representations?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_exercises.html">
     6.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../07/sql_intro.html">
   7. Working With Relations Using SQL
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_subsetting.html">
     7.1. Subsetting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_aggregating.html">
     7.2. Aggregating
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_joining.html">
     7.3. Joining
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_transforming.html">
     7.4. Transforming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_other_reps.html">
     7.5. How are Relations Different from Other Data Representations?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/sql_exercises.html">
     7.6. Exercises
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Understanding The Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08/repr_intro.html">
   8. Data Representation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/repr_structure.html">
     8.1. Structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/repr_data_types.html">
     8.2. Data Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08/repr_granularity.html">
     8.3. Granularity
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09/quality_intro.html">
   9. [In Progress] Data Quality
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../10/eda_intro.html">
   10. Exploratory Data Analysis
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_feature_types.html">
     10.1. Feature Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_distributions.html">
     10.2. What to Look For in a Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_relationships.html">
     10.3. What to Look For in a Relationship?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_guidelines.html">
     10.4. Guidelines for Exploration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_example.html">
     10.5. Example: Sale Prices for Houses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/eda_summary.html">
     10.6. Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../11/viz_intro.html">
   11. Data Visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_quantitative.html">
     11.1. Visualizing Quantitative Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_qualitative.html">
     11.2. Visualizing Qualitative Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_matplotlib.html">
     11.3. Customizing Plots using
     <code class="docutils literal notranslate">
      <span class="pre">
       matplotlib
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_principles.html">
     11.4. Visualization Principles
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_principles_2.html">
     11.5. Visualization Principles Continued
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/viz_philosophy.html">
     11.6. Philosophy for Data Visualization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../12/pa_intro.html">
   12. Case Study: Data Science for Accurate and Timely Air Quality Measurements
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_collocated.html">
     12.1. Finding Collocated Sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_cleaning_aqs.html">
     12.2. Exploring and Cleaning AQS Sensor Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_cleaning_purpleair.html">
     12.3. Exploring and Cleaning PurpleAir Sensor Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_modeling.html">
     12.4. Creating a Model to Correct PurpleAir Measurements
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_conclusion.html">
     12.5. In Conclusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/pa_exercises.html">
     12.6. Exercises
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Other Data Sources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../13/text_intro.html">
   13. Working with Text
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/text_strings.html">
     13.1. Python String Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/text_regex.html">
     13.2. Regular Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/text_re.html">
     13.3. Regex and Python
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../14/web_intro.html">
   14. Web Technologies
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/web_http.html">
     14.1. HTTP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/web_rest.html">
     14.2. [In Progress] REST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/web_html.html">
     14.3. [In Progress] XPath and HTML
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Linear Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../15/linear_models.html">
   15. Linear Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_tips.html">
     15.1. Predicting Tip Amounts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_fitting.html">
     15.2. [In progress] Fitting a linear model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_inference.html">
     15.3. [In progress] Inference for Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/linear_projection.html">
     15.4. Least Squares — A Geometric Perspective
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../16/prob_and_gen.html">
   16. Probability and Generalization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/prob_random_vars.html">
     16.1. Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/prob_exp_var.html">
     16.2. Expectation and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/prob_risk.html">
     16.3. Risk
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../17/gradient_descent.html">
   17. Gradient Descent and Numerical Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/gradient_basics.html">
     17.1. Loss Minimization Using a Program
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/gradient_descent_define.html">
     17.2. Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/gradient_convexity.html">
     17.3. Convexity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/gradient_stochastic.html">
     17.4. Stochastic Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17/gradient_lin_reg.html">
     17.5. Fitting a Linear Model Using Gradient Descent
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../18/donkey_intro.html">
   18. [In progress] Case Study: Donkey Dimensions
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../18/donkey_analysis.html">
     18.1. Linear Regression Case Study
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Multiple Linear Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../19/mult_intro.html">
   19. [In progress] Multiple Linear Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/mult_model.html">
     19.1. Multiple Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/mult_inference.html">
     19.2. Inference for Multiple Linear Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../20/feature_engineering.html">
   20. Feature Engineering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/feature_one_hot.html">
     20.1. The Walmart dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/feature_polynomial.html">
     20.2. Predicting Ice Cream Ratings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../21/bias_intro.html">
   21. The Bias-Variance Tradeoff
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../21/bias_risk.html">
     21.1. Risk and Loss Minimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../21/bias_modeling.html">
     21.2. Model Bias and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../21/bias_cv.html">
     21.3. Cross-Validation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../22/reg_intro.html">
   22. Regularization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../22/reg_intuition.html">
     22.1. Regularization Intuition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../22/reg_ridge.html">
     22.2. L2 Regularization: Ridge Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../22/reg_lasso.html">
     22.3. L1 Regularization: Lasso Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../23/mult_case_intro.html">
   23. [In progress] Case Study: Multiple Linear Models
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Classification
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../24/classification_intro.html">
   24. Classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
  <label for="toctree-checkbox-21">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/classification_prob.html">
     24.1. Regression on Probabilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/classification_log_model.html">
     24.2. The Logistic Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/classification_cost.html">
     24.3. A Loss Function for the Logistic Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/classification_log_reg.html">
     24.4. Using Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/classification_cost_justification.html">
     24.5. Approximating the Empirical Probability Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/classification_sgd.html">
     24.6. Fitting a Logistic Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/classification_sensitivity_specificity.html">
     24.7. Evaluating Logistic Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../24/classification_multiclass.html">
     24.8. Multiclass Classification
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Replicability
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../25/repl_intro.html">
   25. [In progress] Replicable Research
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../25/repl_phacking.html">
     25.1. P-hacking
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Extra Topics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../26/pca_intro.html">
   26. Dimensionality Reduction and PCA
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../26/pca_dims.html">
     26.1. Dimensions of a Data Table
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../26/pca_svd.html">
     26.2. PCA using the Singular Value Decomposition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../26/pca_in_practice.html">
     26.3. PCA in Practice
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../27/dtrees_intro.html">
   27. [In progress] Decision Trees and Random Forests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../28/clustering_intro.html">
   28. [In progress] Clustering
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Appendices
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../a01/prob_review.html">
   Probability Review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../a02/vector_space_review.html">
   Vector Space Review
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../a03/hyp_intro.html">
   Statistical Inference Review
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
  <label for="toctree-checkbox-24">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../a03/hyp_introduction.html">
     Hypothesis Testing and Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a03/hyp_introduction_part2.html">
     Permutation Test
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../a04/ref_intro.html">
   Reference Tables
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
  <label for="toctree-checkbox-25">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_pandas.html">
     pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_seaborn.html">
     Seaborn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_matplotlib.html">
     matplotlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_sklearn.html">
     scikit-learn
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../a05/contributors.html">
   Contributors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../references.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/ch/03/theory_sampling_variation.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simple-random-sample-srs">
   3.1.1. Simple Random Sample (SRS)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stratified-sampling">
   3.1.2. Stratified Sampling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sampling-distributions">
   3.1.3. Sampling Distributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulating-sampling-error">
   3.1.4. Simulating Sampling Error
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-urn-model">
     3.1.4.1. The Urn Model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#simulation-results">
     3.1.4.2. Simulation Results
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#common-probability-distributions">
     3.1.4.3. Common probability distributions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-election-polls-bias-variance-and-big-data">
   3.1.5. Example: Election Polls, Bias, Variance, and Big Data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#background">
     3.1.5.1. Background
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#simulation-study-of-the-sampling-error">
     3.1.5.2. Simulation Study of the Sampling Error
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     3.1.5.3. The Urn Model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#simulation-study-of-selection-bias">
     3.1.5.4. Simulation Study of Selection Bias
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#would-increasing-the-sample-size-have-helped">
     3.1.5.5. Would increasing the sample size have helped?
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="sampling-variation">
<span id="sec-samplingvariation"></span><h1><span class="section-number">3.1. </span>Sampling Variation<a class="headerlink" href="#sampling-variation" title="Permalink to this headline">¶</a></h1>
<p>Probability sampling, also known as scientific sampling, uses a chance mechanism, such as drawing indistinguishable marbles from an urn, to select a sample from the frame. The use of randomness in the selection process enables us to calculate the variation in our sample, e.g., we can compute the chance that we draw a particular sample. We demonstrate these calculations with the most basic sampling method, the Simple Random Sample (SRS), and then introduce an extension of the SRS, stratified sampling. To explain both sampling methods, we use a small population of <span class="math notranslate nohighlight">\(7\)</span> individuals.</p>
<div class="section" id="simple-random-sample-srs">
<h2><span class="section-number">3.1.1. </span>Simple Random Sample (SRS)<a class="headerlink" href="#simple-random-sample-srs" title="Permalink to this headline">¶</a></h2>
<p>To take a simple random sample of <span class="math notranslate nohighlight">\(3\)</span> from the population of <span class="math notranslate nohighlight">\(7\)</span>: we write a label on each marble  (<span class="math notranslate nohighlight">\(A - G\)</span>), place all the marbles in an urn, mix them well, and draw <span class="math notranslate nohighlight">\(3\)</span> without looking and without replacement between draws. All of the the possible samples we could get are listed here:</p>
<div class="math notranslate nohighlight">
\[\begin{split}ABC ~~ ABD ~~ ABE ~~ ABF ~~ ABG ~~ ACD ~~ ACE \\ ACF ~~ ACG ~~ ADE ~~ ADF ~~ ADG ~~ AEF ~~ AEG \\ AFG ~~ BCD ~~ BCE ~~ BCF ~~ BCG ~~ BDE ~~ BDF \\ BDG ~~ BEF ~~ BEG ~~BFG ~~CDE ~~ CDF ~~ CDG \\ CEF ~~ CEG ~~ CFG ~~ DEF ~~ DEG ~~ DFG ~~ EFG  \end{split}\]</div>
<p>There are <span class="math notranslate nohighlight">\(35\)</span>  unique samples of <span class="math notranslate nohighlight">\(3\)</span> from our population of <span class="math notranslate nohighlight">\(7\)</span>. By design, each of these <span class="math notranslate nohighlight">\(35\)</span> samples is equally likely to be chosen (the marbles are indistinguishable and well mixed) so the chance of any particular sample is <span class="math notranslate nohighlight">\(1/35\)</span>. In other words,</p>
<div class="math notranslate nohighlight">
\[{\mathbb{P}}(ABC) = {\mathbb{P}}(\textrm{ABD}) = \cdots = {\mathbb{P}}(\textrm{EFG}) = \frac{1}{35}. \]</div>
<p>Note that we use the special symbol <span class="math notranslate nohighlight">\({\mathbb{P}}\)</span> to stand for “probability” or “chance”.</p>
<p>We can use this chance mechanism to answer questions about the composition of a sample. For example, to find the chance that unit <span class="math notranslate nohighlight">\(A\)</span> is in the sample, we can count up all the samples that contain <span class="math notranslate nohighlight">\(A\)</span>. There are 15 of them so the chance is:</p>
<div class="math notranslate nohighlight">
\[{\mathbb{P}}(\textrm{A is in the sample}) = \frac{15}{35} = \frac{3}{7}.\]</div>
<p>And by symmetry, we have:</p>
<div class="math notranslate nohighlight">
\[{\mathbb{P}}(\textrm{A in sample}) = {\mathbb{P}}(\textrm{B in sample}) = \cdots = {\mathbb{P}}(\textrm{G in sample}) = \frac {3}{7}.\]</div>
<p>Or, you can count them to convince yourself that each unit has an equal chance of being in the sample. We now have a more formal definition of “representative data” that is very useful. Note: If you are familiar with counting arguments and factorials, you can compute the number of possible samples as follows:</p>
<div class="math notranslate nohighlight">
\[{7 \choose 3} = \frac {7!} {3!~4!} = 35.\]</div>
<p>Many people mistakingly think that the defining property of a SRS is that every unit has an equal chance of being in the sample. However, this is not the case. A SRS of <span class="math notranslate nohighlight">\(n\)</span> units from a population of <span class="math notranslate nohighlight">\(N\)</span> means that every possible subset of <span class="math notranslate nohighlight">\(n\)</span> units from <span class="math notranslate nohighlight">\(N\)</span> has the same chance of being selected.</p>
</div>
<div class="section" id="stratified-sampling">
<h2><span class="section-number">3.1.2. </span>Stratified Sampling<a class="headerlink" href="#stratified-sampling" title="Permalink to this headline">¶</a></h2>
<p>In stratified sampling, we divide the population into non-overlapping groups, called strata (one group is called a stratum and more than one are strata), and then take a simple random sample from each.  This is like having an urn for each stratum and drawing marbles from each urn, independently. The strata do not have to be the same size, and we need not take the same number of units from each stratum.</p>
<p>For example, we can divide our tiny population of <span class="math notranslate nohighlight">\(7\)</span> individuals into <span class="math notranslate nohighlight">\(2\)</span> strata as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\textrm{Stratum}~1: \{A, B, C, D \} \\ \textrm{Stratum}~2: \{ E, F, G \}\end{split}\]</div>
<p>Suppose we want to take a sample of size <span class="math notranslate nohighlight">\(2\)</span> from the first stratum and a sample of <span class="math notranslate nohighlight">\(1\)</span> from the smaller stratum.  All together, we have a sample of size <span class="math notranslate nohighlight">\(3\)</span> from the population. This sampling scheme gives us the following possible samples</p>
<div class="math notranslate nohighlight">
\[\begin{split}ABE~~ABF~~ABG~~ACE~~ACF~~ACG\\ADE~~ADF~~ADG~~BCE~~BCF~~BCG\\BDE~~BDF~~BDG~~CDE~~CDF~~CDG\end{split}\]</div>
<p>Each of these samples is equally likely, i.e.,</p>
<div class="math notranslate nohighlight">
\[{\mathbb{P}}\left(ABE\right) = {\mathbb{P}}\left(CDG\right) = \frac{1}{18}.\]</div>
<p>Notice that not all triples are possible in this sampling scheme, e.g.,</p>
<div class="math notranslate nohighlight">
\[{\mathbb{P}}\left(\textrm{AEF}\right) = 0,\]</div>
<p>since only one unit is chosen from the second stratum.</p>
<p>Again, we can compute the probability that unit <span class="math notranslate nohighlight">\(A\)</span> is in our sample by counting up all of the occurrences of <span class="math notranslate nohighlight">\(A\)</span> in the 18 samples:</p>
<div class="math notranslate nohighlight">
\[{\mathbb{P}}\left(A \textrm{ in sample}\right) = \frac{9}{18} = \frac{1}{2}.\]</div>
<p>This is just the chance that <span class="math notranslate nohighlight">\(A\)</span> is chosen from the first stratum, i.e., <span class="math notranslate nohighlight">\(2/4\)</span> or <span class="math notranslate nohighlight">\(1/2\)</span>. Not all units have the same chance of appearing in the sample, e.g.,</p>
<div class="math notranslate nohighlight">
\[{\mathbb{P}}\left(F \textrm{ in sample}\right) = \frac{6}{18} = {\mathbb{P}}\left(F \textrm{ chosen from stratum 2} \right)=\frac{1}{3}.\]</div>
<p>Stratified sampling is often used when some subgroups of the population are more heterogenous than others, in which case we take larger samples from the more variable strata.  Stratified sampling allows the researcher to ensure that subgroups of the population are well-represented in the sample without using human judgement to select the individuals. This approach to sampling can improve the accuracy of a sample. Despite not all samples of <span class="math notranslate nohighlight">\(3\)</span> are possible in these sampling scheme,  each stratum’s sample is representative of its stratum, and we can use our knowledge of the sampling scheme to combine the samples in a representative way through weighting. This topic is addressed in the exercises.</p>
<p>The simple random sample is at the core of many probability sampling schemes. For example, most government surveys use complex sampling schemes that involve multi-stages of sampling from clusters (see the exercises) and strata. It’s crucial to keep these sampling schemes in mind when we compute summary statistics, make plots, and fit models for otherwise, our analysis could be flawed.</p>
</div>
<div class="section" id="sampling-distributions">
<h2><span class="section-number">3.1.3. </span>Sampling Distributions<a class="headerlink" href="#sampling-distributions" title="Permalink to this headline">¶</a></h2>
<p>Probability sampling induces a sampling distribution on any statistic that we calculate from our sample. To explain the concept, we return to our small population of <span class="math notranslate nohighlight">\(7\)</span>, and this time give each unit a value that we want to measure. Suppose that these <span class="math notranslate nohighlight">\(7\)</span> units are pets, <span class="math notranslate nohighlight">\(4\)</span> dogs and <span class="math notranslate nohighlight">\(3\)</span> cats. From our sample, we might summarize our findings with, say, the proportion of dogs in our sample.  Each of our possible samples (remember, there are 35) gives us a summary statistic, a sample proportion. If units <span class="math notranslate nohighlight">\(A,B,C,D\)</span> are the dogs and <span class="math notranslate nohighlight">\(E,F,G\)</span> the cats, then for each sample, we get the following sample proportion of dogs:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>Sample</p></td>
<td class="text-align:left"><p>ABC</p></td>
<td class="text-align:left"><p>ABD</p></td>
<td class="text-align:left"><p>…</p></td>
<td class="text-align:left"><p>BCE</p></td>
<td class="text-align:left"><p>…</p></td>
<td class="text-align:left"><p>DFG</p></td>
<td class="text-align:left"><p>EFG</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Proportion</p></td>
<td class="text-align:left"><p>1</p></td>
<td class="text-align:left"><p>1</p></td>
<td class="text-align:left"><p>…</p></td>
<td class="text-align:left"><p>2/3</p></td>
<td class="text-align:left"><p>…</p></td>
<td class="text-align:left"><p>1/3</p></td>
<td class="text-align:left"><p>0</p></td>
</tr>
</tbody>
</table>
<p>This table can be collapsed into a probability distribution table for the sample proportions.  There are 4 samples that give us all dogs (sample proportion of 1). These are: <span class="math notranslate nohighlight">\(ABC\)</span> , <span class="math notranslate nohighlight">\(ABD\)</span>, <span class="math notranslate nohighlight">\(ACD\)</span>, <span class="math notranslate nohighlight">\(BCD\)</span>, so the chance of observing a sample proportion of <span class="math notranslate nohighlight">\(1\)</span> is <span class="math notranslate nohighlight">\(4/35\)</span>.  The probability distribution table below summaries these possible values and their chances.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p>Sample Proportion</p></th>
<th class="text-align:center head"><p>No. Occurrences</p></th>
<th class="text-align:center head"><p>Chance</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p>1</p></td>
<td class="text-align:center"><p>4</p></td>
<td class="text-align:center"><p>4/35</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>2/3</p></td>
<td class="text-align:center"><p>18</p></td>
<td class="text-align:center"><p>18/35</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>1/3</p></td>
<td class="text-align:center"><p>12</p></td>
<td class="text-align:center"><p>12/35</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>0</p></td>
<td class="text-align:center"><p>1</p></td>
<td class="text-align:center"><p>1/35</p></td>
</tr>
</tbody>
</table>
<p>We also can display this probability distribution with a probability histogram.  And we can find the expected outcome from the SRS, with the following reasoning:</p>
<div class="math notranslate nohighlight">
\[\begin{split}{\mathbb{E}}(\textrm{sample proportion}) = 1 \times \frac{4}{35} + \frac{2}{3}\times \frac{18}{35} + \frac{1}{3} \times \frac{12}{35} + 0 \times \frac{1}{35}\\ = \frac{20}{35} \\ =~ \frac{4}{7}\end{split}\]</div>
<p>The <em>expected sample proportion</em>, matches the proportion of dogs in the population. Further, we can find the standard error of the sample proportion, i.e., the typical deviation of the sample proportion from the expectation, <span class="math notranslate nohighlight">\(4/7\)</span>. That is, we compute the root mean square error of the sample proportion as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}{\mathbb{SE}} = \sqrt{(1-\frac{4}{7})^2\times \frac{4}{35} + (\frac{2}{3}-\frac{4}{7})^2\times \frac{18}{35} +(\frac{1}{3}-\frac{4}{7})^2\times \frac{12}{35} +(0-\frac{4}{7})^2\times \frac{1}{35} } \\ \approx 0.233\end{split}\]</div>
<p>The SE, also called the margin of error, indicates that even though our sample proportion has a expected value that matches <span class="math notranslate nohighlight">\(4/7\)</span>, it is likely to be around <span class="math notranslate nohighlight">\(0.23\)</span> away from <span class="math notranslate nohighlight">\(4/7\)</span>.</p>
<p>While the mathematics of these calculations are quite simple, we can approximate them through a simulation study. To do this, we take samples of size <span class="math notranslate nohighlight">\(3\)</span> from our population over and over, say 100,000 times.  For each sample, we calculate the proportion of dogs. So, we have 100,000 simulated sample proportions, and the probability distribution table tells us that roughly <span class="math notranslate nohighlight">\(4/35\)</span> of these <span class="math notranslate nohighlight">\(100,000\)</span> sample proportions should <span class="math notranslate nohighlight">\(1\)</span>, <span class="math notranslate nohighlight">\(18/35\)</span> of them will be <span class="math notranslate nohighlight">\(2/3\)</span>, …, and about 2,800 of the samples will be a sample with only cats (<span class="math notranslate nohighlight">\(100,000/35=2857\)</span>).</p>
<ul class="simple">
<li><p>A table of the simulated proportions should look like the probability distribution above</p></li>
<li><p>The average of the simulated proportions should be close to the expected proportion, <span class="math notranslate nohighlight">\(4/7 \approx 0.57\)</span> .</p></li>
<li><p>The standard deviation of the simulated proportions should be close to the standard error, about <span class="math notranslate nohighlight">\(0.23\)</span>.</p></li>
</ul>
<p>We show the results of such a simulation below.</p>
</div>
<div class="section" id="simulating-sampling-error">
<h2><span class="section-number">3.1.4. </span>Simulating Sampling Error<a class="headerlink" href="#simulating-sampling-error" title="Permalink to this headline">¶</a></h2>
<div class="section" id="the-urn-model">
<h3><span class="section-number">3.1.4.1. </span>The Urn Model<a class="headerlink" href="#the-urn-model" title="Permalink to this headline">¶</a></h3>
<p>Our urn has 7 marbles, one for each pet.
Since we care only about whether a pet is a dog or cat, we can label each marble as ‘dog’ or ‘cat’,
rather than A through G.
We create this urn as an array.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">urn</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Then we draw 3 marbles from our urn without replacement between draws using numpy’s ‘random.choice’ as follows.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">urn</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;cat&#39;, &#39;dog&#39;, &#39;cat&#39;], dtype=&#39;&lt;U3&#39;)
</pre></div>
</div>
</div>
</div>
<p>We can keep sampling from our urn, e.g., below we take 10 samples from the urn:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">urn</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">replace</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[array([&#39;dog&#39;, &#39;cat&#39;, &#39;dog&#39;], dtype=&#39;&lt;U3&#39;),
 array([&#39;dog&#39;, &#39;dog&#39;, &#39;cat&#39;], dtype=&#39;&lt;U3&#39;),
 array([&#39;cat&#39;, &#39;dog&#39;, &#39;dog&#39;], dtype=&#39;&lt;U3&#39;),
 array([&#39;dog&#39;, &#39;dog&#39;, &#39;cat&#39;], dtype=&#39;&lt;U3&#39;),
 array([&#39;cat&#39;, &#39;cat&#39;, &#39;dog&#39;], dtype=&#39;&lt;U3&#39;),
 array([&#39;dog&#39;, &#39;cat&#39;, &#39;cat&#39;], dtype=&#39;&lt;U3&#39;),
 array([&#39;dog&#39;, &#39;cat&#39;, &#39;cat&#39;], dtype=&#39;&lt;U3&#39;),
 array([&#39;dog&#39;, &#39;dog&#39;, &#39;cat&#39;], dtype=&#39;&lt;U3&#39;),
 array([&#39;dog&#39;, &#39;dog&#39;, &#39;dog&#39;], dtype=&#39;&lt;U3&#39;),
 array([&#39;dog&#39;, &#39;dog&#39;, &#39;dog&#39;], dtype=&#39;&lt;U3&#39;)]
</pre></div>
</div>
</div>
</div>
<p>Since we simply want to count the number of dogs in the sample, it’s easier if our urn contains 1s (for dogs) and 0s (for cats) so that we can sum the results of the 3 draws to get the number of dogs in the sample.
That is,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">urn</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">urn</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span><span class="o">/</span><span class="mi">3</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
<p>For our simulation, we generate 100,000 samples, and compute the proportion of dogs in each.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simulations</span> <span class="o">=</span> <span class="p">[</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">urn</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span> <span class="o">/</span> <span class="mi">3</span>
               <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">)]</span> 
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="simulation-results">
<h3><span class="section-number">3.1.4.2. </span>Simulation Results<a class="headerlink" href="#simulation-results" title="Permalink to this headline">¶</a></h3>
<p>Let’s study these 100,000 sample proportions.
First, we compute the average value and the standard deviation of the 100,000 sample proportions,
and compare them to what the theory told us: the expected proportion is 4/7 or about 0.571, and
the sampling error is about 0.233.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">simulations</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">simulations</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.5719233333333333, 0.23393334926854698)
</pre></div>
</div>
</div>
</div>
<p>These match quite closely.
We can also compare the fraction of the 100,000 values that are 0, 1/3, 2/3, and 1 and
make a histogram.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">unique_els</span><span class="p">,</span> <span class="n">counts_els</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">simulations</span><span class="p">),</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="n">unique_els</span><span class="p">,</span> <span class="n">counts_els</span><span class="o">/</span><span class="mi">100000</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.  , 0.33, 0.67, 1.  ],
       [0.03, 0.34, 0.51, 0.12]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">simulations</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mf">0.571</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Approximate Sampling Distribution&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;# of Simulations&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Sample Proportion&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0, &#39;Sample Proportion&#39;)
</pre></div>
</div>
<img alt="../../_images/theory_sampling_variation_31_1.png" src="../../_images/theory_sampling_variation_31_1.png" />
</div>
</div>
<p>The simulations closely match the theory we developed.
This simulation study does not <em>prove</em> the expected value of the chance outcome is 4/7 or that the chance a  sample has 2 dogs is 18/35.
However, the simulation does support our earlier calculations, and in more complex settings a simulation study can offer valuable insights.</p>
</div>
<div class="section" id="common-probability-distributions">
<h3><span class="section-number">3.1.4.3. </span>Common probability distributions<a class="headerlink" href="#common-probability-distributions" title="Permalink to this headline">¶</a></h3>
<p>This version of the urn model, where we count the number of marbles of a certain type (in our case ‘dog’ marbles), is so common that there is a random chance process named for it: the hypergeometric.
Instead of using <code class="docutils literal notranslate"><span class="pre">random.choice</span></code>, we can use <code class="docutils literal notranslate"><span class="pre">random.hypergeometric</span></code>, which is optimzed for the 0-1 urn and allows us to ask for 100,000 simulations in the call.
For completeness, we repeat our simulation study, calculate the average and standard error, and display the empirical proportions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simulations_fast</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">hypergeometric</span><span class="p">(</span><span class="n">ngood</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">nbad</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">nsample</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Note: we don’t think that cats are bad; it’s just a naming convention to call the type you want to count ‘good’ and the other ‘bad’.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">simulations_fast</span> <span class="o">/</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.57247
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">simulations_fast</span> <span class="o">/</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.23258281485670143
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">unique_els</span><span class="p">,</span> <span class="n">counts_els</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span> <span class="n">simulations_fast</span> <span class="p">),</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="n">unique_els</span><span class="p">,</span> <span class="n">counts_els</span><span class="o">/</span><span class="mi">100000</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.  , 1.  , 2.  , 3.  ],
       [0.03, 0.34, 0.52, 0.11]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">simulations_fast</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mf">0.57</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Approximate Sampling Distribution&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;# of Simulations&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Sample Proportion&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0, &#39;Sample Proportion&#39;)
</pre></div>
</div>
<img alt="../../_images/theory_sampling_variation_40_1.png" src="../../_images/theory_sampling_variation_40_1.png" />
</div>
</div>
<p>Perhaps the two most common probability distributions are those that arise from counting the number of 1s drawn from a 0-1 urn: drawing without replacement is the hypergeometric distribution and drawing with replacement is the binomial.
We do not delve further into the study of named probability distributions.
However, if possible, it’s a good idea to use the functionality provided in a third party package for simulating from a named distribution, rather than writing a simulation entirely from scratch.  Others have developed efficient and accurate code.</p>
<p>Our approach in this book is to develop intuition based on simulation studies to understand the results of a chance process. However, we do formalize the notion of a probability distribution, expected value, and standard deviation in Section <a class="reference internal" href="theory_prob_dist.html#sec-probintro"><span class="std std-numref">Section 3.4</span></a>.</p>
</div>
</div>
<div class="section" id="example-election-polls-bias-variance-and-big-data">
<h2><span class="section-number">3.1.5. </span>Example: Election Polls, Bias, Variance, and Big Data<a class="headerlink" href="#example-election-polls-bias-variance-and-big-data" title="Permalink to this headline">¶</a></h2>
<div class="section" id="background">
<h3><span class="section-number">3.1.5.1. </span>Background<a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h3>
<p>The US president is chosen by the Electoral College, not by popular vote.
Each state is alotted a certan number of electoral college votes, as a function of their population, and
typically, whomever wins the popular vote in the state receives all of the electoral college votes for that state.</p>
<p>In advance of the election, polls are conducted separately in all of the states.
The results help identify “battleground” states, and they are combined to predict the winner of the electoral college votes.
In 2016, pollsters correctly predicted the election outcome in 46 of the 50 states.
For those 46 states Trump received 231 and Clinton received 232 electoral college votes.
The remaining 4 states, Florida, Michigan, Pennsylvania, and Wisconsin, accounted for a total of 75 votes, and
whichever candidate received the majority of the electoral college votes in these states would win the election.</p>
<p>The electoral margins in these four states were narrow, e.g., in Pennsylvania Trump received 48.18% and Clinton received 47.46% of the 6,165,478 votes cast in the state.
Such narrow margins can make it hard to predict the outcome given the sample sizes that the polls used.</p>
<p>Many experts have studied the 2016 election results.
According to the American Association for Public Opinion Research (AAPOR),
one online, opt-in poll adjusted their polling results for education but used only three broad categories
(high school or less, some college, and college graduate).
They found that had they separated out those with advanced degrees from those with college
degrees, then they would have reduced Clinton’s margin by 0.5 percentage points.
In other words, after the fact they were able to identify an education bias where highly educated voters tended to be more willing to participate in polls. This bias matters because these voters also tended to prefer Clinton over Trump.</p>
<p>Now that we know how people actually voted, we can carry out a simulation study that imitates the election polling under different scenarios to help develop intuition for accuracy, bias, and variance (see <span id="id1">[<a class="reference internal" href="../../references.html#id16">te Grotenhuis <em>et al.</em>, 2018</a>]</span>.
We will simulate the polls for Pennsylvania under two scenarios:</p>
<ol class="simple">
<li><p>People surveyed didn’t change their minds, didn’t hide who they voted for, and were representative of those who voted on election day.</p></li>
<li><p>People with a higher education were more likely to respond, which led to a 0.5% bias for Clinton.</p></li>
</ol>
<p>Our ultimate goal is to understand the chance that a poll incorrectly calls the election for Hillary Clinton even if our sample was collected with absolutely no bias, and when there is a small amount of non-response bias.</p>
</div>
<div class="section" id="simulation-study-of-the-sampling-error">
<h3><span class="section-number">3.1.5.2. </span>Simulation Study of the Sampling Error<a class="headerlink" href="#simulation-study-of-the-sampling-error" title="Permalink to this headline">¶</a></h3>
<p>For the first scenario, we simulate a simple random sample (SRS) of the 6+m voters in Pennsylavania and
calculate Trump’s lead over Clinton.
We repeat this sample collection over and over, each time calculating Trump’s lead, to get
a sense of the different values a SRS might produce.</p>
<p>Our population consists of the votes cast for Trump, Clinton, and a third-party candidate.
We lump all of the third party candidates together because we are only interested in the difference between
votes cast for Trump and Clinton.</p>
</div>
<div class="section" id="id2">
<h3><span class="section-number">3.1.5.3. </span>The Urn Model<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>We can cast this problem in terms of an urn model as follows:</p>
<ul class="simple">
<li><p>There are 6,165,478 marbles in the urn, one for each vote</p></li>
<li><p>Since we care only about whether the vote is for Clinton, Trump, or some other third party candidate, we can lump all third party candidates together and label each marble in one of three ways: Trump, Clinton, and Other.</p></li>
<li><p>The poll is a SRS of, say, 1500 marbles from the urn</p></li>
<li><p>We tally up the counts of the three types of marbles</p></li>
</ul>
<p>We begin by creating an urn that represents the votes cast on election day.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">proportions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.4818</span><span class="p">,</span> <span class="mf">0.4746</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="mf">0.4818</span> <span class="o">+</span> <span class="mf">0.4746</span><span class="p">)])</span>               
<span class="n">n</span> <span class="o">=</span> <span class="mi">1_500</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">6_165_478</span>
<span class="n">votes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trunc</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">proportions</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">votes</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([2970527, 2926135,  268814])
</pre></div>
</div>
</div>
</div>
<p>This version of the urn model is so common that there is a random chance process named for it, the multivariate hypergeometric. In Python, this is implemented in the <code class="docutils literal notranslate"><span class="pre">scipy.stats.multivariate_hypergeom.rvs</span></code> function. We can take a SRS and get our counts with the function call:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multivariate_hypergeom</span>

<span class="n">multivariate_hypergeom</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">votes</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([744, 692,  64])
</pre></div>
</div>
</div>
</div>
<p>And, each time we call <code class="docutils literal notranslate"><span class="pre">multivariate_hypergeom.rvs</span></code> we get a different sample and counts, e.g.,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">multivariate_hypergeom</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">votes</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([714, 709,  77])
</pre></div>
</div>
</div>
</div>
<p>We compute Trumnp’s lead for each simulation, i.e., <span class="math notranslate nohighlight">\((n_T - n_C)/n\)</span>, where <span class="math notranslate nohighlight">\(n_T\)</span> are the number of Trump votes in the sample and <span class="math notranslate nohighlight">\(n_C\)</span> the number for Clinton. If the lead is positive, then the sample shows a win for Trump.</p>
<p>We know the actual lead was, 0.4818 - 0.4746 =  0.0072, and to get a sense of the variation in the sampling process
we can simulate the sampling process over and over and examine the values that we get in return.
Below we simulate 100,000 simple random samples of 1500 voters from the state of Pennsylvania.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">trump_advantage</span><span class="p">(</span><span class="n">votes</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="n">sample_votes</span> <span class="o">=</span> <span class="n">multivariate_hypergeom</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">votes</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">sample_votes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">sample_votes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">n</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simulations</span> <span class="o">=</span> <span class="p">[</span><span class="n">trump_advantage</span><span class="p">(</span><span class="n">votes</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">)]</span> 
</pre></div>
</div>
</div>
</div>
<p>On average, the polling results show Trump with close to a 0.7% lead:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">simulations</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.007201626666666666
</pre></div>
</div>
</div>
</div>
<p>However, many times the lead in the sample was negative, meaning Clinton was the winner for that sample of voters.
The histogram below shows the sampling distribution of Trump’s advantage in Pennsylvania for a sample of 1500 voters.
The vertical dashed line at 0 shows that more often than not, Trump is called, but there are many times when a sample
shows Clinton in the lead.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">simulations</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Approximate Sampling Distribution&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;# of Simulations&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Trump Lead in the Sample&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0, &#39;Trump Lead in the Sample&#39;)
</pre></div>
</div>
<img alt="../../_images/theory_sampling_variation_57_1.png" src="../../_images/theory_sampling_variation_57_1.png" />
</div>
</div>
<p>In the 100,0000 simulated polls, we find Trump a victor about 60% of the time:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">simulations</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="mi">100000</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.60816
</pre></div>
</div>
</div>
</div>
<p>This number represents the chance that a given sample will correctly predict Trump’s victory <em>even if the sample was collected with absoutely no bias</em>. In other words, even a non-biased sample will be wrong about 40% of the time.</p>
<p>We have just studied the sampling error, and found how our predictions might look if there was no bias in our
sampling process. Next we will see what happens when a little biasenters into the mix.</p>
</div>
<div class="section" id="simulation-study-of-selection-bias">
<h3><span class="section-number">3.1.5.4. </span>Simulation Study of Selection Bias<a class="headerlink" href="#simulation-study-of-selection-bias" title="Permalink to this headline">¶</a></h3>
<p>“In a perfect world, polls sample from the population of voters, who would state their political preference perfectly clearly and then vote accordingly.” <span id="id3">[<a class="reference internal" href="../../references.html#id16">te Grotenhuis <em>et al.</em>, 2018</a>]</span></p>
<p>That’s the simulation study that we just performed.</p>
<p>It’s difficult to control for every source of bias. We investigate here the effect of a small, education bias on the polling results.
Specifically, we examine the impacts of the 0.5 percent bias in favor of Clinton that we described earlier.</p>
<p>This bias essentially means that we see a distorted picture of voter preferences in our polls, where instead of 47.46 percent votes for Clinton, we have 47.96, and we have 48.18 - 0.5 = 47.68 percent for Trump.
We adjust the proportions to reflect this bias:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">proportions_bias</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.4818</span> <span class="o">-</span> <span class="mf">0.005</span><span class="p">,</span> <span class="mf">0.4747</span> <span class="o">+</span> <span class="mf">0.005</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="mf">0.4818</span> <span class="o">+</span> <span class="mf">0.4746</span><span class="p">)</span> <span class="p">]</span>
<span class="n">proportions_bias</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.4768, 0.4797, 0.04359999999999997]
</pre></div>
</div>
</div>
</div>
<p>Now, our simulations find Trump winning in about 45% of the samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simulations_bias</span> <span class="o">=</span> <span class="p">[</span><span class="n">trump_advantage</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">proportions_bias</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">)]</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">simulations_bias</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Approximate Sampling Distribution for a Biased Sample&#39;</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;# of Simulations&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Trump Lead in the Sample&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0, &#39;Trump Lead in the Sample&#39;)
</pre></div>
</div>
<img alt="../../_images/theory_sampling_variation_65_1.png" src="../../_images/theory_sampling_variation_65_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">simulations_bias</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="mi">100000</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.44817
</pre></div>
</div>
</div>
</div>
<p>Notice that the histograms from the two simulations are similar in shape.
They are symmetric with reasonable length tails, i.e., they appear to roughly follow the normal curve.
The second histogram is shifted slightly to the left, which reflects the non-response bias we introduced.</p>
</div>
<div class="section" id="would-increasing-the-sample-size-have-helped">
<h3><span class="section-number">3.1.5.5. </span>Would increasing the sample size have helped?<a class="headerlink" href="#would-increasing-the-sample-size-have-helped" title="Permalink to this headline">¶</a></h3>
<p>With our simulation study we can get insight into the answer to this question.
For example, we can try a sample size of 12,000 and run 100,000 simulations for both scenarios.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simulations_big</span> <span class="o">=</span> <span class="p">[</span><span class="n">trump_advantage</span><span class="p">(</span><span class="mi">12000</span><span class="p">,</span> <span class="n">proportions</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">)]</span> 
<span class="n">simulations_bias_big</span> <span class="o">=</span> <span class="p">[</span><span class="n">trump_advantage</span><span class="p">(</span><span class="mi">12000</span><span class="p">,</span> <span class="n">proportions_bias</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">)]</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scenario_no_bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">simulations_big</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="mi">100000</span>
<span class="n">scenario_bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">simulations_bias_big</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="mi">100000</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scenario_no_bias</span><span class="p">,</span> <span class="n">scenario_bias</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.78767 0.37232
</pre></div>
</div>
</div>
</div>
<p>By analyzing over 4,000 polls for 600 state-level, gubernatorial, senatorial, and presidential elections, <span id="id4">[<a class="reference internal" href="../../references.html#id18">Shirani-Mehr <em>et al.</em>, 2018</a>]</span> et al found that on average these polls exhibited a bias of about 1.5 percentage points.</p>
<p>When the margin of victory is relatively small as it was in 2016, a larger sample size reduces the sampling error, but unfortunately, if there is bias, then the predictions are close to the biased estimate. If the bias pushes the prediction from one candidate (Trump) to another (Clinton), then we have a “surprise” upset.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch/03"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="theory_intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">3. </span>Theory for Data Design</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="theory_random_assignment.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3.2. </span>Random Assignment</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Sam Lau, Joey Gonzalez, and Deb Nolan<br/>
        
            &copy; Copyright 2021.<br/>
          <div class="extra_footer">
            <p>
License: CC BY-NC-ND 4.0
</p>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>