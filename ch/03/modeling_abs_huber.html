
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3.3. Absolute and Huber Loss &#8212; Principles and Techniques of Data Science</title>
    
  <link rel="stylesheet" href="../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="4. [In progress] Case Study" href="../04/cycle_case_study_intro.html" />
    <link rel="prev" title="3.2. Loss Functions" href="modeling_loss_functions.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  
  <h1 class="site-logo" id="site-title">Principles and Techniques of Data Science</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Frontmatter
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../preface.html">
   To the Reader
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prereqs.html">
   Prerequisites
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../notation.html">
   Notation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  The Data Science Lifecycle
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../01/lifecycle_intro.html">
   1. The Data Science Lifecycle
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_students_1.html">
     1.1. The Students of Data 100
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_students_2.html">
     1.2. Exploratory Data Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/lifecycle_students_3.html">
     1.3. What’s in a Name?
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../02/design_intro.html">
   2. Generalizing from Data
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../02/design_dewey_truman.html">
     2.1. Dewey Defeats Truman
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/design_data.html">
     2.2. [In Progress] Data Design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/design_sampling.html">
     2.3. Probability Sampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/design_srs_vs_big_data.html">
     2.4. SRS vs. “Big Data”
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="modeling_intro.html">
   3. Modeling and Estimation
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="modeling_simple.html">
     3.1. Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="modeling_loss_functions.html">
     3.2. Loss Functions
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     3.3. Absolute and Huber Loss
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04/cycle_case_study_intro.html">
   4. [In progress] Case Study
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Rectangular Data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../05/sql_intro.html">
   5. Relational Databases and SQL
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../05/sql_rdbms.html">
     5.1. The Relational Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/sql_basics.html">
     5.2. SQL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/sql_joins.html">
     5.3. SQL Joins
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../06/pandas_intro.html">
   6. Data Tables in Python
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_indexes.html">
     6.1. Indexes, Slicing, and Sorting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_grouping_pivoting.html">
     6.2. Grouping and Pivoting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_apply_strings_plotting.html">
     6.3. Apply, Strings, and Plotting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/pandas_joins.html">
     6.4. [In progress] Joins
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Preparing and Exploring Data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../07/repr_intro.html">
   7. [In Progress] Data Representation
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../07/repr_structure.html">
     7.1. Structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/repr_semantics.html">
     7.2. [In Progress] Semantics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/repr_data_types.html">
     7.3. Data Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/repr_granularity.html">
     7.4. Granularity
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../08/quality_intro.html">
   8. [In Progress] Data Quality
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09/eda_intro.html">
   9. [In Progress] Exploratory Data Analysis
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../10/viz_intro.html">
   10. Data Visualization
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../10/viz_quantitative.html">
     10.1. Visualizing Quantitative Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/viz_qualitative.html">
     10.2. Visualizing Qualitative Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/viz_matplotlib.html">
     10.3. Customizing Plots using
     <code class="docutils literal notranslate">
      <span class="pre">
       matplotlib
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/viz_principles.html">
     10.4. Visualization Principles
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/viz_principles_2.html">
     10.5. Visualization Principles Continued
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/viz_philosophy.html">
     10.6. Philosophy for Data Visualization
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../11/police_intro.html">
   11. [In progress] Case Study: Berkeley Policing
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../11/police_calls.html">
     11.1. Cleaning the Calls Dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/police_stops.html">
     11.2. Cleaning The Stops Dataset
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Other Data Sources
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../12/text_intro.html">
   12. Working with Text
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../12/text_strings.html">
     12.1. Python String Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/text_regex.html">
     12.2. Regular Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/text_re.html">
     12.3. Regex and Python
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../13/web_intro.html">
   13. Web Technologies
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../13/web_http.html">
     13.1. HTTP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/web_rest.html">
     13.2. [In Progress] REST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13/web_html.html">
     13.3. [In Progress] XPath and HTML
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Linear Modeling
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../14/linear_models.html">
   14. Linear Models
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../14/linear_tips.html">
     14.1. Predicting Tip Amounts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/linear_fitting.html">
     14.2. [In progress] Fitting a linear model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/linear_inference.html">
     14.3. [In progress] Inference for Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14/linear_projection.html">
     14.4. Least Squares — A Geometric Perspective
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../15/prob_and_gen.html">
   15. Probability and Generalization
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../15/prob_random_vars.html">
     15.1. Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/prob_exp_var.html">
     15.2. Expectation and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15/prob_risk.html">
     15.3. Risk
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../16/gradient_descent.html">
   16. Gradient Descent and Numerical Optimization
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../16/gradient_basics.html">
     16.1. Loss Minimization Using a Program
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/gradient_descent_define.html">
     16.2. Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/gradient_convexity.html">
     16.3. Convexity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/gradient_stochastic.html">
     16.4. Stochastic Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../16/gradient_lin_reg.html">
     16.5. Fitting a Linear Model Using Gradient Descent
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../17/donkey_intro.html">
   17. [In progress] Case Study: Donkey Dimensions
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../17/donkey_analysis.html">
     17.1. Linear Regression Case Study
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Multiple Linear Modeling
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../18/mult_intro.html">
   18. [In progress] Multiple Linear Regression
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../18/mult_model.html">
     18.1. Multiple Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../18/mult_inference.html">
     18.2. Inference for Multiple Linear Regression
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../19/feature_engineering.html">
   19. Feature Engineering
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../19/feature_one_hot.html">
     19.1. The Walmart dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19/feature_polynomial.html">
     19.2. Predicting Ice Cream Ratings
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../20/bias_intro.html">
   20. The Bias-Variance Tradeoff
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../20/bias_risk.html">
     20.1. Risk and Loss Minimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/bias_modeling.html">
     20.2. Model Bias and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20/bias_cv.html">
     20.3. Cross-Validation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../21/reg_intro.html">
   21. Regularization
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../21/reg_intuition.html">
     21.1. Regularization Intuition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../21/reg_ridge.html">
     21.2. L2 Regularization: Ridge Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../21/reg_lasso.html">
     21.3. L1 Regularization: Lasso Regression
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../22/mult_case_intro.html">
   22. [In progress] Case Study: Multiple Linear Models
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Classification
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../23/classification_intro.html">
   23. Classification
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../23/classification_prob.html">
     23.1. Regression on Probabilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23/classification_log_model.html">
     23.2. The Logistic Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23/classification_cost.html">
     23.3. A Loss Function for the Logistic Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23/classification_log_reg.html">
     23.4. Using Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23/classification_cost_justification.html">
     23.5. Approximating the Empirical Probability Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23/classification_sgd.html">
     23.6. Fitting a Logistic Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23/classification_sensitivity_specificity.html">
     23.7. Evaluating Logistic Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23/classification_multiclass.html">
     23.8. Multiclass Classification
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Replicability
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../24/repl_intro.html">
   24. [In progress] Replicable Research
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../24/repl_phacking.html">
     24.1. P-hacking
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Extra Topics
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../25/pca_intro.html">
   25. Dimensionality Reduction and PCA
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../25/pca_dims.html">
     25.1. Dimensions of a Data Table
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25/pca_svd.html">
     25.2. PCA using the Singular Value Decomposition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25/pca_in_practice.html">
     25.3. PCA in Practice
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../26/dtrees_intro.html">
   26. [In progress] Decision Trees and Random Forests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../27/clustering_intro.html">
   27. [In progress] Clustering
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Appendices
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../a01/prob_review.html">
   Probability Review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../a02/vector_space_review.html">
   Vector Space Review
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../a03/hyp_intro.html">
   Statistical Inference Review
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../a03/hyp_introduction.html">
     Hypothesis Testing and Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a03/hyp_introduction_part2.html">
     Permutation Test
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../a04/ref_intro.html">
   Reference Tables
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_pandas.html">
     pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_seaborn.html">
     Seaborn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_matplotlib.html">
     matplotlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../a04/ref_sklearn.html">
     scikit-learn
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../a05/contributors.html">
   Contributors
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/ch/03/modeling_abs_huber.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/ch/03/modeling_abs_huber.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mean-absolute-error">
   3.3.1. Mean Absolute Error
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comparing-mse-and-mae">
     3.3.1.1. Comparing MSE and MAE
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#outliers">
   3.3.2. Outliers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#minimizing-the-mae">
   3.3.3. Minimizing the MAE
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mse-and-mae-comparison">
   3.3.4. MSE and MAE Comparison
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-huber-loss">
     3.3.4.1. The Huber Loss
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   3.3.5. Summary
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="c1"># Ignore numpy dtype warnings. These warnings are caused by an interaction</span>
<span class="c1"># between numpy and Cython and can be safely ignored.</span>
<span class="c1"># Reference: https://stackoverflow.com/a/40846742</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;numpy.dtype size changed&quot;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;numpy.ufunc size changed&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">interact_manual</span>
<span class="kn">import</span> <span class="nn">nbinteract</span> <span class="k">as</span> <span class="nn">nbi</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s1">&#39;talk&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_columns</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="c1"># This option stops scientific notation for pandas</span>
<span class="c1"># pd.set_option(&#39;display.float_format&#39;, &#39;{:.2f}&#39;.format)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tips</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;tips&#39;</span><span class="p">)</span>
<span class="n">tips</span><span class="p">[</span><span class="s1">&#39;pcttip&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tips</span><span class="p">[</span><span class="s1">&#39;tip&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">tips</span><span class="p">[</span><span class="s1">&#39;total_bill&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mse_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_vals</span> <span class="o">-</span> <span class="n">theta</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">abs_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_vals</span> <span class="o">-</span> <span class="n">theta</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compare_mse_abs</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">,</span> <span class="n">xlims</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">cols</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_vals</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_vals</span><span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">thetas</span><span class="p">)</span> <span class="o">/</span> <span class="n">cols</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">theta</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">thetas</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">rugplot</span><span class="p">(</span><span class="n">y_vals</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="sa">rf</span><span class="s1">&#39;$ \theta = </span><span class="si">{</span><span class="n">theta</span><span class="si">}</span><span class="s1"> $&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;MSE = </span><span class="si">{</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span>
                  <span class="sa">f</span><span class="s1">&#39;MAE = </span><span class="si">{</span><span class="n">abs_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">*</span><span class="n">xlims</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="absolute-and-huber-loss">
<h1><span class="section-number">3.3. </span>Absolute and Huber Loss<a class="headerlink" href="#absolute-and-huber-loss" title="Permalink to this headline">¶</a></h1>
<p>To fit a model, we select a loss function and select the model parameters that minimize the loss. In the previous section, we introduced the mean squared error (MSE) loss function:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
L(\theta, \textbf{y})
&amp;= \frac{1}{n} \sum_{i = 1}^{n}(y_i - \theta)^2\\
\end{aligned}
\end{split}\]</div>
<p>We used a constant model that predicts the same number <span class="math notranslate nohighlight">\( \theta \)</span> for all entries in the dataset. When we fit this model using the MSE loss, we found that <span class="math notranslate nohighlight">\( \hat{\theta} = \text{mean} (\textbf{y}) \)</span>. On the tips dataset, we found that a fitted constant model will predict <span class="math notranslate nohighlight">\( 16.08\% \)</span> since <span class="math notranslate nohighlight">\( 16.08\% \)</span> is the mean of the tip percents.</p>
<p>In this section, we introduce two new loss functions, the <strong>mean absolute error</strong> loss function and the <strong>Huber</strong> loss function.</p>
<div class="section" id="mean-absolute-error">
<h2><span class="section-number">3.3.1. </span>Mean Absolute Error<a class="headerlink" href="#mean-absolute-error" title="Permalink to this headline">¶</a></h2>
<p>Now, we will keep our model the same but switch to a different loss function: the mean absolute error (MAE). Instead taking the squared difference for each point and our prediction, this loss function takes the absolute difference:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
L(\theta, \textbf{y})
&amp;= \frac{1}{n} \sum_{i = 1}^{n} |y_i - \theta| \\
\end{aligned}
\end{split}\]</div>
<div class="section" id="comparing-mse-and-mae">
<h3><span class="section-number">3.3.1.1. </span>Comparing MSE and MAE<a class="headerlink" href="#comparing-mse-and-mae" title="Permalink to this headline">¶</a></h3>
<p>To get a better sense of how the MSE and MAE compare, let’s compare their losses on different datasets. First, we’ll use our dataset of one point: <span class="math notranslate nohighlight">\( \textbf{y} = [14] \)</span>.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">compare_mse_abs</span><span class="p">(</span><span class="n">thetas</span><span class="o">=</span><span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span>
                <span class="n">y_vals</span><span class="o">=</span><span class="p">[</span><span class="mi">14</span><span class="p">],</span> <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">17</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/modeling_abs_huber_7_0.png" src="../../_images/modeling_abs_huber_7_0.png" />
</div>
</div>
<p>We see that the MSE is usually higher than the MAE since the error is squared. Let’s see what happens when have five points: <span class="math notranslate nohighlight">\( \textbf{y} = [ 12.1, 12.8, 14.9, 16.3, 17.2 ] \)</span></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">compare_mse_abs</span><span class="p">(</span><span class="n">thetas</span><span class="o">=</span><span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">],</span>
                <span class="n">y_vals</span><span class="o">=</span><span class="p">[</span><span class="mf">12.1</span><span class="p">,</span> <span class="mf">12.8</span><span class="p">,</span> <span class="mf">14.9</span><span class="p">,</span> <span class="mf">16.3</span><span class="p">,</span> <span class="mf">17.2</span><span class="p">],</span>
                <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">18</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/modeling_abs_huber_9_0.png" src="../../_images/modeling_abs_huber_9_0.png" />
</div>
</div>
<p>Remember that the actual loss values themselves are not very interesting to us; they are only useful for comparing different values of <span class="math notranslate nohighlight">\( \theta \)</span>. Once we choose a loss function, we will look for <span class="math notranslate nohighlight">\( \hat{\theta} \)</span>, the <span class="math notranslate nohighlight">\( \theta \)</span> that produces the least loss. Thus, we are interested in whether the loss functions produce different <span class="math notranslate nohighlight">\( \hat{\theta} \)</span>.</p>
<p>So far, the two loss functions seem to agree on <span class="math notranslate nohighlight">\( \hat{\theta} \)</span>. If we look a bit closer, however, we will start to see some differences. We first take the losses and plot them against <span class="math notranslate nohighlight">\( \theta \)</span> for each of the six <span class="math notranslate nohighlight">\( \theta \)</span> values we tried.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">thetas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">])</span>
<span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">12.1</span><span class="p">,</span> <span class="mf">12.8</span><span class="p">,</span> <span class="mf">14.9</span><span class="p">,</span> <span class="mf">16.3</span><span class="p">,</span> <span class="mf">17.2</span><span class="p">])</span>
<span class="n">mse_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span> <span class="k">for</span> <span class="n">theta</span> <span class="ow">in</span> <span class="n">thetas</span><span class="p">]</span>
<span class="n">abs_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">abs_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span> <span class="k">for</span> <span class="n">theta</span> <span class="ow">in</span> <span class="n">thetas</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">mse_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MSE&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">abs_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MAE&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Loss vs. $ \theta $ when $ \bf</span><span class="si">{y}</span><span class="s1">$$= [ 12.1, 12.8, 14.9, 16.3, 17.2 ] $&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$ \theta $ Values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/modeling_abs_huber_11_0.png" src="../../_images/modeling_abs_huber_11_0.png" />
</div>
</div>
<p>Then, we compute more values of <span class="math notranslate nohighlight">\( \theta \)</span> so that the curve is smooth:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">thetas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mf">17.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
<span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">12.1</span><span class="p">,</span> <span class="mf">12.8</span><span class="p">,</span> <span class="mf">14.9</span><span class="p">,</span> <span class="mf">16.3</span><span class="p">,</span> <span class="mf">17.2</span><span class="p">])</span>
<span class="n">mse_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span> <span class="k">for</span> <span class="n">theta</span> <span class="ow">in</span> <span class="n">thetas</span><span class="p">]</span>
<span class="n">abs_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">abs_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span> <span class="k">for</span> <span class="n">theta</span> <span class="ow">in</span> <span class="n">thetas</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">mse_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MSE&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">abs_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MAE&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Loss vs. $ \theta $ when $ \bf</span><span class="si">{y}</span><span class="s1">$$ = [ 12.1, 12.8, 14.9, 16.3, 17.2 ] $&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$ \theta $ Values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/modeling_abs_huber_13_0.png" src="../../_images/modeling_abs_huber_13_0.png" />
</div>
</div>
<p>Then, we zoom into the region between 1.5 and 5 on the y-axis to see the difference in minima more clearly. We’ve marked the minima with dotted lines.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">thetas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mf">17.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
<span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">12.1</span><span class="p">,</span> <span class="mf">12.8</span><span class="p">,</span> <span class="mf">14.9</span><span class="p">,</span> <span class="mf">16.3</span><span class="p">,</span> <span class="mf">17.2</span><span class="p">])</span>
<span class="n">mse_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span> <span class="k">for</span> <span class="n">theta</span> <span class="ow">in</span> <span class="n">thetas</span><span class="p">]</span>
<span class="n">abs_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">abs_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span> <span class="k">for</span> <span class="n">theta</span> <span class="ow">in</span> <span class="n">thetas</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">mse_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MSE&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">abs_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MAE&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_vals</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Minimum MSE&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">y_vals</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Minimum MAE&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Loss vs. $ \theta $ when $ \bf</span><span class="si">{y}</span><span class="s1">$$ = [ 12.1, 12.8, 14.9, 16.3, 17.2 ] $&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$ \theta $ Values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/modeling_abs_huber_15_0.png" src="../../_images/modeling_abs_huber_15_0.png" />
</div>
</div>
<p>We’ve found empirically that the MSE and MAE can produce different <span class="math notranslate nohighlight">\( \hat{\theta} \)</span> for the same dataset. A closer analysis reveals when they will differ and more importantly, why they differ.</p>
</div>
</div>
<div class="section" id="outliers">
<h2><span class="section-number">3.3.2. </span>Outliers<a class="headerlink" href="#outliers" title="Permalink to this headline">¶</a></h2>
<p>One difference that we can see in the plots of loss vs. <span class="math notranslate nohighlight">\( \theta \)</span> above lies in the shape of the loss curves. Plotting the MSE results in a parabolic curve resulting from the squared term in the loss function.</p>
<p>Plotting the MAE, on the other hand, results in what looks like a connected series of lines. This makes sense when we consider that the absolute value function is linear, so taking the average of many absolute value functions should produce a semi-linear function.</p>
<p>Since the MSE has a squared error term, it will be more sensitive to outliers. If <span class="math notranslate nohighlight">\( \theta = 10 \)</span> and a point lies at 110, that point’s error term for MSE will be <span class="math notranslate nohighlight">\( (10 - 110)^2 = 10000 \)</span> whereas in the MAE, that point’s error term will be <span class="math notranslate nohighlight">\( |10 - 110| = 100 \)</span>. We can illustrate this by taking a set of three points <span class="math notranslate nohighlight">\( \textbf{y} = [ 12, 13, 14 ] \)</span> and plotting the loss vs. <span class="math notranslate nohighlight">\( \theta \)</span> curves for MSE and MAE.</p>
<p>Use the slider below to move the third point further away from the rest of the data and observe what happens to the loss curves. (We’ve scaled the curves to keep both in view since the MSE has larger values than the MAE.)</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compare_mse_abs_curves</span><span class="p">(</span><span class="n">y3</span><span class="o">=</span><span class="mi">14</span><span class="p">):</span>
    <span class="n">thetas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">11.5</span><span class="p">,</span> <span class="mf">26.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="n">y3</span><span class="p">])</span>
    
    <span class="n">mse_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span> <span class="k">for</span> <span class="n">theta</span> <span class="ow">in</span> <span class="n">thetas</span><span class="p">]</span>
    <span class="n">abs_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">abs_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span> <span class="k">for</span> <span class="n">theta</span> <span class="ow">in</span> <span class="n">thetas</span><span class="p">]</span>
    <span class="n">mse_abs_diff</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">mse_losses</span><span class="p">)</span> <span class="o">-</span> <span class="nb">min</span><span class="p">(</span><span class="n">abs_losses</span><span class="p">)</span>
    <span class="n">mse_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">loss</span> <span class="o">-</span> <span class="n">mse_abs_diff</span> <span class="k">for</span> <span class="n">loss</span> <span class="ow">in</span> <span class="n">mse_losses</span><span class="p">]</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">rugplot</span><span class="p">(</span><span class="n">y_vals</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mf">11.5</span><span class="p">,</span> <span class="mf">26.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Points&#39;</span><span class="p">)</span>
    
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">mse_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MSE&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">abs_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MAE&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mf">11.5</span><span class="p">,</span> <span class="mf">26.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">abs_losses</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">abs_losses</span><span class="p">)</span> <span class="o">+</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$ \theta $&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">interact</span><span class="p">(</span><span class="n">compare_mse_abs_curves</span><span class="p">,</span> <span class="n">y3</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">25</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "113cd2652b7e4b0b8379e7ac014102d4", "version_major": 2, "version_minor": 0}
</script></div>
</div>
<p>We’ve shown the curves for <span class="math notranslate nohighlight">\( y_3 = 14 \)</span> and <span class="math notranslate nohighlight">\( y_3 = 25 \)</span> below.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">compare_mse_abs_curves</span><span class="p">(</span><span class="n">y3</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/modeling_abs_huber_21_0.png" src="../../_images/modeling_abs_huber_21_0.png" />
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">compare_mse_abs_curves</span><span class="p">(</span><span class="n">y3</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/modeling_abs_huber_22_0.png" src="../../_images/modeling_abs_huber_22_0.png" />
</div>
</div>
<p>As we move the point further away from the rest of the data, the MSE curve moves with it. When <span class="math notranslate nohighlight">\( y_3 = 14 \)</span>, both MSE and MAE have <span class="math notranslate nohighlight">\( \hat{\theta} = 13 \)</span>. However, when <span class="math notranslate nohighlight">\( y_3 = 25 \)</span>, the MSE loss produces <span class="math notranslate nohighlight">\( \hat{\theta} = 16.7 \)</span> while the MAE produces <span class="math notranslate nohighlight">\( \hat{\theta} = 13 \)</span>, unchanged from before.</p>
</div>
<div class="section" id="minimizing-the-mae">
<h2><span class="section-number">3.3.3. </span>Minimizing the MAE<a class="headerlink" href="#minimizing-the-mae" title="Permalink to this headline">¶</a></h2>
<p>Now that we have a qualitative sense of how the MSE and MAE differ, we can minimize the MAE to make this difference more precise. As before, we will take the derivative of the loss function with respect to <span class="math notranslate nohighlight">\( \theta \)</span> and set it equal to zero.</p>
<p>This time, however, we have to deal with the fact that the absolute function is not always differentiable. When <span class="math notranslate nohighlight">\( x &gt; 0 \)</span>, <span class="math notranslate nohighlight">\( \frac{\partial}{\partial x} |x| = 1 \)</span>. When <span class="math notranslate nohighlight">\( x &lt; 0 \)</span>, <span class="math notranslate nohighlight">\( \frac{\partial}{\partial x} |x| = -1 \)</span>. Although <span class="math notranslate nohighlight">\( |x| \)</span> is not technicaly differentiable at <span class="math notranslate nohighlight">\( x = 0 \)</span>, we will set <span class="math notranslate nohighlight">\( \frac{\partial}{\partial x} |x| = 0 \)</span> so that the equations are easier to work with.</p>
<p>Recall that the equation for the MAE is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
L(\theta, \textbf{y})
&amp;= \frac{1}{n} \sum_{i = 1}^{n}|y_i - \theta|\\
&amp;= \frac{1}{n} \left( \sum_{y_i &lt; \theta}|y_i - \theta| + \sum_{y_i = \theta}|y_i - \theta| + \sum_{y_i &gt; \theta}|y_i - \theta| \right)\\
\end{aligned}
\end{split}\]</div>
<p>In the line above, we’ve split up the summation into three separate summations: one that has one term for each <span class="math notranslate nohighlight">\( y_i &lt; \theta \)</span>, one for <span class="math notranslate nohighlight">\( y_i = \theta \)</span>, and one for <span class="math notranslate nohighlight">\( y_i &gt; \theta \)</span>. Why make the summation seemingly more complicated? If we know that <span class="math notranslate nohighlight">\( y_i &lt; \theta \)</span> we also know that <span class="math notranslate nohighlight">\( |y_i - \theta| &lt; 0 \)</span> and thus <span class="math notranslate nohighlight">\( \frac{\partial}{\partial \theta} |y_i - \theta| = -1 \)</span> from before. A similar logic holds for each term above to make taking the derivative much easier.</p>
<p>Now, we take the derivative with respect to <span class="math notranslate nohighlight">\( \theta \)</span> and set it equal to zero:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\frac{1}{n} \left( \sum_{y_i &lt; \theta}(-1) + \sum_{y_i = \theta}(0) + \sum_{y_i &gt; \theta}(1) \right) &amp;= 0 \\
\sum_{y_i &lt; \theta}(-1) + \sum_{y_i &gt; \theta}(1) &amp;= 0 \\
-\sum_{y_i &lt; \theta}(1) + \sum_{y_i &gt; \theta}(1) &amp;= 0 \\
\sum_{y_i &lt; \theta}(1) &amp;= \sum_{y_i &gt; \theta}(1) \\
\end{aligned}
\end{split}\]</div>
<p>What does the result above mean? On the left hand side, we have one term for each data point less than <span class="math notranslate nohighlight">\( \theta \)</span>. On the right, we have one for each data point greater than <span class="math notranslate nohighlight">\( \theta \)</span>. Then, in order to satisfy the equation we need to pick a value for <span class="math notranslate nohighlight">\( \theta \)</span> that has the same number of smaller and larger points. This is the definition for the <em>median</em> of a set of numbers. Thus, the minimizing value of <span class="math notranslate nohighlight">\( \theta \)</span> for the MAE is <span class="math notranslate nohighlight">\( \hat \theta = \text{median} (\textbf{y}) \)</span>.</p>
<p>When we have an odd number of points, the median is simply the middle point when the points are arranged in sorted order. We can see that in the example below with five points, the loss is minimized when <span class="math notranslate nohighlight">\( \theta \)</span> lies at the median:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">points_and_loss</span><span class="p">(</span><span class="n">y_vals</span><span class="p">,</span> <span class="n">xlim</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">abs_loss</span><span class="p">):</span>
    <span class="n">thetas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">xlim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xlim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
    <span class="n">abs_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span> <span class="k">for</span> <span class="n">theta</span> <span class="ow">in</span> <span class="n">thetas</span><span class="p">]</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">rugplot</span><span class="p">(</span><span class="n">y_vals</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">*</span><span class="n">xlim</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Points&#39;</span><span class="p">)</span>
    
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">abs_losses</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">*</span><span class="n">xlim</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$ \theta $&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">points_and_loss</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">]),</span> <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/modeling_abs_huber_26_0.png" src="../../_images/modeling_abs_huber_26_0.png" />
</div>
</div>
<p>However, when we have an even number of points, the loss is minimized when <span class="math notranslate nohighlight">\( \theta \)</span> is any value in between the two central points.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">points_and_loss</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">]),</span> <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/modeling_abs_huber_28_0.png" src="../../_images/modeling_abs_huber_28_0.png" />
</div>
</div>
<p>This is not the case when we use the MSE:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">points_and_loss</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">]),</span> <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="n">mse_loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/modeling_abs_huber_30_0.png" src="../../_images/modeling_abs_huber_30_0.png" />
</div>
</div>
</div>
<div class="section" id="mse-and-mae-comparison">
<h2><span class="section-number">3.3.4. </span>MSE and MAE Comparison<a class="headerlink" href="#mse-and-mae-comparison" title="Permalink to this headline">¶</a></h2>
<p>Our investigation and the derivation above show that the MSE is easier to differentiate but is more sensitive to outliers than the MAE. For the MSE, <span class="math notranslate nohighlight">\( \hat{\theta} = \text{mean}(\textbf{y}) \)</span>, while for the MAE <span class="math notranslate nohighlight">\( \hat{\theta} = \text{median}(\textbf{y}) \)</span>. Notice that the median is less affected by outliers than the mean. This phenomenon arises from our construction of the two loss functions.</p>
<p>We have also seen that the MSE has a unique <span class="math notranslate nohighlight">\( \hat{\theta} \)</span>, whereas the mean absolute value can multiple possible <span class="math notranslate nohighlight">\( \hat{\theta} \)</span> values when there are an even number of data points.</p>
<div class="section" id="the-huber-loss">
<h3><span class="section-number">3.3.4.1. </span>The Huber Loss<a class="headerlink" href="#the-huber-loss" title="Permalink to this headline">¶</a></h3>
<p>A third loss function called the Huber loss combines both the MSE and MAE to create a loss function that is differentiable <em>and</em> robust to outliers. The Huber loss accomplishes this by behaving like the MSE function for <span class="math notranslate nohighlight">\(\theta\)</span> values close to the minimum and switching to the absolute loss for <span class="math notranslate nohighlight">\(\theta\)</span> values far from the minimum.</p>
<p>As usual, we create a loss function by taking the mean of the Huber losses for each point in our dataset.</p>
<p>Let’s see what the Huber loss function outputs for a dataset of <span class="math notranslate nohighlight">\( \textbf{y} = [14] \)</span> as we vary <span class="math notranslate nohighlight">\( \theta \)</span>:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">huber_loss</span><span class="p">(</span><span class="n">est</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">est</span> <span class="o">-</span> <span class="n">y_obs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">d</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">,</span> 
                    <span class="p">(</span><span class="n">est</span> <span class="o">-</span> <span class="n">y_obs</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">,</span>
                    <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">d</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">))</span>

<span class="n">thetas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">huber_loss</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">14</span><span class="p">]),</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Huber Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">14</span><span class="p">]),</span> <span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="n">colors</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Observation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Choice for $\theta$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;huber_loss.pdf&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/modeling_abs_huber_33_0.png" src="../../_images/modeling_abs_huber_33_0.png" />
</div>
</div>
<p>We can see that the Huber loss is smooth, unlike the MAE. The Huber loss also increases at a linear rate, unlike the quadratic rate of the mean squared loss.</p>
<p>The Huber loss does have a drawback, however. Notice that it transitions from the MSE to the MAE once <span class="math notranslate nohighlight">\( \theta \)</span> gets far enough from the point. We can tweak this “far enough” to get different loss curves. For example, we can make it transition once <span class="math notranslate nohighlight">\( \theta \)</span> is just one unit away from the observation:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">huber_loss</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">14</span><span class="p">]),</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Huber Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">14</span><span class="p">]),</span> <span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="n">colors</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Observation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Choice for $\theta$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;huber_loss.pdf&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/modeling_abs_huber_35_0.png" src="../../_images/modeling_abs_huber_35_0.png" />
</div>
</div>
<p>Or we can make it transition when <span class="math notranslate nohighlight">\( \theta \)</span> is ten units away from the observation:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">huber_loss</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">14</span><span class="p">]),</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Huber Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">14</span><span class="p">]),</span> <span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="n">colors</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Observation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Choice for $\theta$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;huber_loss.pdf&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/modeling_abs_huber_37_0.png" src="../../_images/modeling_abs_huber_37_0.png" />
</div>
</div>
<p>This choice results in a different loss curve and can thus result in different values of <span class="math notranslate nohighlight">\( \hat \theta \)</span>. If we want to use the Huber loss function, we have the additional task of setting this transition point to a suitable value.</p>
<p>The Huber loss function is defined mathematically as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
L_\alpha(\theta, \textbf{y}) = \frac{1}{n} \sum_{i=1}^n \begin{cases}
    \frac{1}{2}(y_i - \theta)^2 &amp;  | y_i - \theta | \le \alpha \\
    \alpha ( |y_i - \theta| - \frac{1}{2}\alpha ) &amp; \text{otherwise}
\end{cases}
\end{split}\]</div>
<p>It is more complex than the previous loss functions because it combines both MSE and MAE. The additional parameter <span class="math notranslate nohighlight">\( \alpha \)</span> sets the point where the Huber loss transitions from the MSE to the absolute loss.</p>
<p>Attempting to take the derivative of the Huber loss function is tedious and does not result in an elegant result like the MSE and MAE. Instead, we can use a computational method called gradient descent to find minimizing value of <span class="math notranslate nohighlight">\( \theta \)</span>.</p>
</div>
</div>
<div class="section" id="summary">
<h2><span class="section-number">3.3.5. </span>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>In this section, we introduce two loss functions: the mean absolute error and the Huber loss functions. We show for a constant model fitted using the MAE, <span class="math notranslate nohighlight">\( \hat{\theta} = \text{median}(\textbf{y}) \)</span>.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch/03"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="modeling_loss_functions.html" title="previous page"><span class="section-number">3.2. </span>Loss Functions</a>
    <a class='right-next' id="next-link" href="../04/cycle_case_study_intro.html" title="next page"><span class="section-number">4. </span>[In progress] Case Study</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Sam Lau, Joey Gonzalez, and Deb Nolan<br/>
        
            &copy; Copyright 2020.<br/>
          <div class="extra_footer">
            <p>
License: CC BY-NC-ND 4.0
</p>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.d3f166471bb80abb5163.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-113006011-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>