{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import nbinteract as nbi\n",
    "\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.options.display.max_rows = 7\n",
    "pd.options.display.max_columns = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation and Variance\n",
    "\n",
    "PMFs help describe a random variable's distribution entirely, but sometimes we want a brief summary of this distribution, which we can achieve through the notions of expectation and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectation\n",
    "\n",
    "We are often interested in the long-run average of a random variable because it gives us a sense of the center of the variable's distribution. We call this long-run average the **expected value**, or **expectation** of a random variable. The expected value of a random variable $ X $ is defined as:\n",
    "\n",
    "$$\\mathbb{E}[X] = \\sum_{x\\in \\mathbb{X}} x \\cdot \\mathbb{P}(X = x)$$\n",
    "\n",
    "For example, if $ X $ represents the roll of a single fair six-sided die, \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[X]\n",
    "&= 1 \\cdot \\mathbb{P}(X = 1) + 2 \\cdot \\mathbb{P}(X = 2) + \\ldots + 6 \\cdot \\mathbb{P}(X = 6) \\\\\n",
    "&= 1 \\cdot \\frac{1}{6} + 2 \\cdot \\frac{1}{6} + \\ldots + 6 \\cdot \\frac{1}{6} \\\\\n",
    "&= 3.5\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Notice that the expected value of $ X $ does not have to be a possible value of $ X $; although in this case  $ \\mathbb{E}[X] = 3.5 $, $ X $ never takes on the value $ 3.5 $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** We pick one person from the dataset in the previous section uniformly at random. Let $ Y $ be a random variable representing the age of this person. Then:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[Y]\n",
    "&= 50 \\cdot \\mathbb{P}(Y = 50) + 51 \\cdot \\mathbb{P}(Y = 51) + 52 \\cdot \\mathbb{P}(Y = 52) \\\\\n",
    "&= 50 \\cdot \\frac{2}{4} + 51 \\cdot \\frac{1}{4} + 52 \\cdot \\frac{1}{4} \\\\\n",
    "&= 50.75\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Suppose we sample two people from the dataset with replacement. If the random variable $ Z $ represents the difference between the ages of the first and second persons in the sample, what is  $ \\mathbb{E}[Z] $?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous section, we define $X$ as the age of the first person and $Y$ as the age of the second such that $Z = X - Y$. From the joint distribution of $X$ and $Y$ given in the previous section, we can find the PMF for $ Z $. For example, $ P(Z = 1) = P(X = 51, Y = 50) + P(X = 52, Y = 51) = \\frac{3}{16} $. Thus,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[Z]\n",
    "&= (-2) \\cdot P(Z = -2) + (-1) \\cdot P(Z = -1) + \\ldots + (2) \\cdot P(Z = 2) \\\\\n",
    "&= (-2) \\cdot \\frac{2}{16} + (-1) \\cdot \\frac{3}{16}+ \\ldots + (2) \\cdot \\frac{2}{16} \\\\\n",
    "&= 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Since $ \\mathbb{E}[Z] = 0 $, we expect that in the long run the difference between the ages of the people in a sample of size 2 will be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linearity of Expectation\n",
    "\n",
    "When working with linear combinations of random variables as we did above, we can often make good use of the **linearity of expectation** instead of tediously calculating each joint probability individually.\n",
    "\n",
    "The linearity of expectation states that:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[X + Y] &= \\mathbb{E}[X] + \\mathbb{E}[Y] \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "From this statement we may also derive:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[cX] &= c\\mathbb{E}[X] \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $X$ and $Y$ are random variables, and $c$ is a constant.\n",
    "\n",
    "In words, the expectation of a sum of any two random variables is equal to the sum of the expectations of the variables.\n",
    "\n",
    "In the previous example, we saw that $ Z = X - Y $. Thus,  $ \\mathbb{E}[Z] = \\mathbb{E}[X - Y] = \\mathbb{E}[X] - \\mathbb{E}[Y] $. \n",
    "\n",
    "Now we can calculate $ \\mathbb{E}[X] $ and  $ \\mathbb{E}[Y] $ separately from each other. Since $ \\mathbb{E}[X] = \\mathbb{E}[Y] = 50.75 $, $ \\mathbb{E}[Z] = 50.75 - 50.75 = 0 $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linearity of expectation holds even if $ X $ and $ Y $ are dependent on each other! As an example, let us again consider the case in which we sample two people from the dataset in the previous section but without replacement. As before, we define $X$ as the age of the first person and $Y$ as the age of the second, and $Z = X - Y$ where $X$ and $Y$ are not independent. \n",
    "\n",
    "From the joint distribution of $X$ and $Y$ given in the previous section, we can find $\\mathbb{E}[Z]$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[Z]\n",
    "&= (-2) \\cdot P(Z = -2) + (-1) \\cdot P(Z = -1) + \\ldots + (2) \\cdot P(Z = 2) \\\\\n",
    "&= (-2) \\cdot \\frac{2}{12} + (-1) \\cdot \\frac{3}{12}+ \\ldots + (2) \\cdot \\frac{2}{12} \\\\\n",
    "&= 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "A simpler way to compute this expectation is to use the linearity of expectation. Even though $X$ and $Y$ dependent, $\\mathbb{E}[Z] = \\mathbb{E}[X - Y] = \\mathbb{E}[X] - \\mathbb{E}[Y]$. Recall from the previous section that $X$ and $Y$ have the same PMF even though we are sampling without replacement, which means that $\\mathbb{E}[X] = \\mathbb{E}[Y] = 50.75$. Hence as in the first scenario, $\\mathbb{E}[Z] = 0$.\n",
    "\n",
    "Note that the linearity of expectation only holds for linear combinations of random variables. For example, $ \\mathbb{E}[XY] = \\mathbb{E}[X]\\mathbb{E}[Y] $ is not a linear combination of $ X $ and $ Y $. In this case, $ \\mathbb{E}[XY] = \\mathbb{E}[X]\\mathbb{E}[Y] $ is true in general only for independent random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance\n",
    "\n",
    "The variance of a random variable is a numerical description of the spread of a random variable. For a random variable $ X $:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Var(X) &= \\mathbb{E}[(X - \\mathbb{E}[X])^2] \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The above formula states that the variance of $ X $ is the average squared distance from $ X $'s expected value.\n",
    "\n",
    "With some algebraic manipulation that we omit for brevity, we may also equivalently write:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Var(X) &= \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following two random variables $ X $ and $ Y $ with the following probability distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2841375c320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# HIDDEN\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist([-1, 1], bins=np.arange(-2, 4), normed=True, rwidth=0.95)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$P(X = x)$')\n",
    "plt.xticks(np.arange(-2, 4))\n",
    "plt.yticks(np.arange(0, 1.1, 0.25),\n",
    "           (0, r'$\\frac{1}{4}$', r'$\\frac{1}{2}$', r'$\\frac{3}{4}$', r'$1$'))\n",
    "plt.ylim(0, 1)\n",
    "plt.title('PMF of $X$')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist([-2, -1, 1, 2], bins=np.arange(-2, 4), normed=True, rwidth=0.95)\n",
    "plt.xlabel('$y$')\n",
    "plt.xticks(np.arange(-2, 4))\n",
    "plt.ylabel('$P(Y = y)$')\n",
    "plt.ylim(0, 1)\n",
    "plt.yticks(np.arange(0, 1.1, 0.25),\n",
    "           (0, r'$\\frac{1}{4}$', r'$\\frac{1}{2}$', r'$\\frac{3}{4}$', r'$1$'))\n",
    "plt.title('PMF of $Y$')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ X $ takes on values -1 and 1 with probability $ \\frac{1}{2} $ each. $ Y $ takes on values -2, -1, 1, and 2 with probability $ \\frac{1}{4} $ each. We find that $ \\mathbb{E}[X] = \\mathbb{E}[Y] = 0 $. Since $ Y $'s distribution has a higher spread than $ X $'s, we expect that $ Var(Y) $ is larger than $ Var(X) $.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Var(X)\n",
    "&= \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 \\\\\n",
    "&= \\mathbb{E}[X^2] - 0^2 \\\\\n",
    "&= \\mathbb{E}[X^2] \\\\\n",
    "&= (-1)^2 P(X = -1) + (1)^2 P(X = 1) \\\\\n",
    "&= 1 \\cdot 0.5 + 1 \\cdot 0.5 \\\\\n",
    "&= 1 \\\\\\\\\n",
    "Var(Y)\n",
    "&= \\mathbb{E}[Y^2] - \\mathbb{E}[Y]^2 \\\\\n",
    "&= \\mathbb{E}[Y^2] - 0^2 \\\\\n",
    "&= \\mathbb{E}[Y^2] \\\\\n",
    "&= (-2)^2 P(Y = -2) + (-1)^2 P(Y = -1) + (1)^2 P(Y = 1) + (2)^2 P(Y = 2) \\\\\n",
    "&= 4 \\cdot 0.25 + 1 \\cdot 0.25 + 1 \\cdot 0.25 + 4 \\cdot 0.25\\\\\n",
    "&= 2.5\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the variance of $ Y $ is greater than the variance of $ X $.\n",
    "\n",
    "The variance has a useful property to simplify some calculations. If $ X $ is a random variable:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Var(aX + b) &= a^2 Var(X)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "If two random variables $ X $ and $ Y $ are independent:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Var(X + Y) = Var(X) + Var(Y)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Note that the linearity of expectation holds for any $ X $ and $ Y $ even if they are dependent; $ Var(X + Y) = Var(X) + Var(Y) $ holds only when $ X $ and $ Y $ are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance\n",
    "\n",
    "The covariance of two random variables $X$ and $Y$ is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Cov(X, Y) &= \\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Again, we can perform some algebraic manipulation to obtain:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Cov(X, Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Note that although the variance of a single random variable must be non-negative, the covariance of two random variables can be negative. In fact, the covariance helps measure the correlation between two random variables; the sign of the covariance helps us determine whether two random variables are positively or negatively correlated. If two random variables $X$ and $Y$ are independent, then $Cov(X, Y) = 0$, and $\\mathbb{E}[XY] = \\mathbb{E}[X]\\mathbb{E}[Y]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Bernoulli Random Variables\n",
    "\n",
    "Suppose we want to use a random variable $X$ to a simulate a biased coin with $P(Heads) = p$. We can say that $X = 1$ if the coin flip is heads, and $X = 0$ if the coin flip is tails. Therefore, $P(X = 1) = p$, and $P(X = 0) = 1 - p$. This type of binary random variable is called a Bernoulli random variable; we can calculate its expected value and variance as follows:\n",
    "\n",
    "$$\\mathbb{E}[X] = 1 \\times p + 0 \\times (1 - p) = p$$\n",
    "\n",
    "$$Var(X) = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 = 1^2 \\times p + 0^2 \\times (1 - p) - p^2 = p - p^2 = p(1 - p)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Means\n",
    "\n",
    "Suppose we flip a coin with $P(Heads) = p$ a total of $n$ times and find the proportion of heads. Let us call this proportion $\\hat{p}$. If we wanted to estimate $P(Heads)$, we might intuitively believe that $\\hat{p}$ is a good guess. Now, we can use our newly gained knowledge of random variables, expectation, and variance to confirm this intuition.\n",
    "\n",
    "Note that $\\hat{p}$ itself is a random variable; thus, it must have some underlying distribution. If we let $X_i$ be a Bernoulli random variable for the $i^{th}$ coin flip (note that the $X_i$'s are independent since they represent independent coin flips), then we can mathematically determine that $\\hat{p} = \\frac{1}{n} \\sum_{i=1}^{n} X_i$. We can then calculate the expected value, variance, and standard deviation of $\\hat{p}$ as follows:\n",
    "\n",
    "$$\\mathbb{E}[\\frac{1}{n} \\sum_{i=1}^{n} X_i] = \\frac{1}{n} \\sum_{i=1}^{n}\\mathbb{E}[X_i] = \\frac{1}{n} \\times np = p$$\n",
    "\n",
    "$$Var(\\frac{1}{n} \\sum_{i=1}^{n} X_i) = \\frac{1}{n^2} \\sum_{i=1}^{n}Var(X_i) = \\frac{1}{n^2} \\times np(1-p) = \\frac{p(1-p)}{n}$$\n",
    "\n",
    "The expected value of $\\hat{p}$, the sample proportion, is the same as $p$, the true proportion! Furthermore, the variance of the sample proportion gives us a measure of how much error we should expect if we use $\\hat{p}$ to estimate $p$. As we increase the sample size $n$, the variance of our estimator decreases by a factor of $\\frac{1}{n}$, and $\\hat{p}$ converges to $p$. This fact is known as the law of large numbers.\n",
    "\n",
    "Since this sample proportion converges to the true proportion as the sample size becomes large, the sample proportion is considered an *unbiased estimator* for the true proportion. Some estimators are biasedâ€”the sample maximum, for example, meaning that the expected value for these estimators is not the true value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Expectation and variance are simple descriptions of a random variable's center and spread. We use the versatility of random variables to describe data generation and modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
