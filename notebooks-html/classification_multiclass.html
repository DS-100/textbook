
<div id="ipython-notebook">
    <div class="buttons">
        <button class="interact-button js-nbinteract-widget">
            Show Widgets
        </button>
        <a class="interact-button" href="http://data100.datahub.berkeley.edu/user-redirect/git-pull?repo=https://github.com/DS-100/textbook&subPath=notebooks/ch17/classification_multiclass.ipynb">Open on DataHub</a></div>
    




<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  style="display:none;"
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="c1"># Clear previously defined variables</span>
<span class="o">%</span><span class="k">reset</span> -f

<span class="c1"># Set directory for data loading to work properly</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/notebooks/ch17&#39;</span><span class="p">))</span>
</pre></div></div></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  style="display:none;"
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">confusion_matrix</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
</pre></div></div></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  style="display:none;"
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">markers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;triangle&#39;</span><span class="p">:[</span><span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">]],</span> 
           <span class="s1">&#39;square&#39;</span><span class="p">:[</span><span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">1</span><span class="p">]],</span>
           <span class="s1">&#39;circle&#39;</span><span class="p">:[</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">2</span><span class="p">]]}</span>

<span class="k">def</span> <span class="nf">plot_binary</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="n">data_copy</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">data_copy</span><span class="p">[</span><span class="s1">&#39;$y$ == &#39;</span> <span class="o">+</span> <span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_copy</span><span class="p">[</span><span class="s1">&#39;$y$&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">label</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>
    
    <span class="n">sns</span><span class="o">.</span><span class="n">lmplot</span><span class="p">(</span><span class="s1">&#39;$x_1$&#39;</span><span class="p">,</span> <span class="s1">&#39;$x_2$&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data_copy</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;$y$ == &#39;</span> <span class="o">+</span> <span class="n">label</span><span class="p">,</span> <span class="n">hue_order</span><span class="o">=</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span> 
               <span class="n">markers</span><span class="o">=</span><span class="p">[</span><span class="n">markers</span><span class="p">[</span><span class="n">label</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;x&#39;</span><span class="p">],</span> <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="n">markers</span><span class="p">[</span><span class="n">label</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;gray&#39;</span><span class="p">],</span>
               <span class="n">fit_reg</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">);</span>
</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="(outline)">(outline)<a class="anchor-link" href="#(outline)">&#182;</a></h3><ul>
<li>What is multiclass classification<ul>
<li>More than 2 labels that can be classified; versus a binary classification which is restricted to 2 labels</li>
</ul>
</li>
<li>A situation where multiclass classification might be used<ul>
<li>Preferably come up with an example in lebron.csv, but might have to use a different data set</li>
</ul>
</li>
<li>OvO vs OvR<ul>
<li>In logistic regression, multiclass classification comes down to a bunch of binary problems</li>
<li>OvO: Fit a binary classification problem to each pair of classes, then vote for class that wins the most "head-to-head" classifications</li>
<li>OvR/OvA: Fit a binary classification problem for each class versus the rest of the classes; result is class that has the highest probability</li>
</ul>
</li>
<li>Example walking through multiclass? sklearn's logistic regression supports OvR out of the box.</li>
<li>Multilabel: More than one classification problem (e.g. a document can be positive/negative, religion/not religion, political/apolitical, etc.)</li>
</ul></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Multiclass-Classification">Multiclass Classification<a class="anchor-link" href="#Multiclass-Classification">&#182;</a></h2><p>So far we have discussed binary classification, in which our classifier determines whether an observation is part of the positive class (e.g. an email is classified as spam) or the negative class (e.g. an email is not spam). However, many data science problems involve <strong>multiclass classification</strong>, in which we would like to classify observations as one of several different classes. For example, we may be interested in classifying emails into folders such as Family, Friends, Work, and Promotions. To solve these types of problems, we use a new method called <strong>one-vs-rest (OvR) classification</strong>.</p>
<h3 id="One-Vs-Rest-Classification">One-Vs-Rest Classification<a class="anchor-link" href="#One-Vs-Rest-Classification">&#182;</a></h3><p>In OvR classification (also known as one-vs-all, or OvA), we decompose a multiclass classification problem into several different binary classification problems. For example, we might observe training data as shown below:</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  style="display:none;"
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">shapes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">[[</span><span class="mf">1.3</span><span class="p">,</span> <span class="mf">3.6</span><span class="p">,</span> <span class="s1">&#39;triangle&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.6</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">,</span> <span class="s1">&#39;triangle&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.8</span><span class="p">,</span> <span class="mf">3.8</span><span class="p">,</span> <span class="s1">&#39;triangle&#39;</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="s1">&#39;square&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.2</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">,</span> <span class="s1">&#39;square&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.6</span><span class="p">,</span> <span class="mf">1.4</span><span class="p">,</span> <span class="s1">&#39;square&#39;</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">3.2</span><span class="p">,</span> <span class="mf">2.9</span><span class="p">,</span> <span class="s1">&#39;circle&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="s1">&#39;circle&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.9</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="s1">&#39;circle&#39;</span><span class="p">]],</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;$x_1$&#39;</span><span class="p">,</span> <span class="s1">&#39;$x_2$&#39;</span><span class="p">,</span> <span class="s1">&#39;$y$&#39;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div></div></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">lmplot</span><span class="p">(</span><span class="s1">&#39;$x_1$&#39;</span><span class="p">,</span> <span class="s1">&#39;$x_2$&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">shapes</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;$y$&#39;</span><span class="p">,</span> <span class="n">markers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">],</span> <span class="n">fit_reg</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">);</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">





<div class="output_png output_subarea ">
<img src="/notebooks-images/classification_multiclass_6_0.png"
></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our goal is to build a multiclass classifier that labels observations as <code>triangle</code>, <code>square</code>, or <code>circle</code> given values for $x_1$ and $x_2$. First, we want to build a binary classifier that predicts observations as <code>triangle</code>/not <code>triangle</code>:</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_binary</span><span class="p">(</span><span class="n">shapes</span><span class="p">,</span> <span class="s1">&#39;triangle&#39;</span><span class="p">)</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">





<div class="output_png output_subarea ">
<img src="/notebooks-images/classification_multiclass_8_0.png"
></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Similarly, we build binary classifiers for the remaining classes:</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_binary</span><span class="p">(</span><span class="n">shapes</span><span class="p">,</span> <span class="s1">&#39;square&#39;</span><span class="p">)</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">





<div class="output_png output_subarea ">
<img src="/notebooks-images/classification_multiclass_10_0.png"
></div></div></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_binary</span><span class="p">(</span><span class="n">shapes</span><span class="p">,</span> <span class="s1">&#39;circle&#39;</span><span class="p">)</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">





<div class="output_png output_subarea ">
<img src="/notebooks-images/classification_multiclass_11_0.png"
></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We know that the output of the sigmoid function in logistic regression is a probability value from 0 to 1. Then to solve our multiclass classification task, we find the probability of the positive class in each binary classifier and select the class that outputs the highest positive class probability. For example, if we have a new observation with the following values:</p>
<table>
<thead><tr>
<th>$x_1$</th>
<th>$x_2$</th>
</tr>
</thead>
<tbody>
<tr>
<td>3.2</td>
<td>2.5</td>
</tr>
</tbody>
</table>
<p>Then our multiclass classifier would fit three binary classifiers to each of the labels of <code>triangle</code>, <code>square</code>, and <code>circle</code>. We extract the positive class probability of each of the three classifiers:</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  style="display:none;"
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">lr_triangle</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">lr_triangle</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">shapes</span><span class="p">[[</span><span class="s1">&#39;$x_1$&#39;</span><span class="p">,</span> <span class="s1">&#39;$x_2$&#39;</span><span class="p">]],</span> <span class="n">shapes</span><span class="p">[</span><span class="s1">&#39;$y$&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;triangle&#39;</span><span class="p">)</span>
<span class="n">proba_triangle</span> <span class="o">=</span> <span class="n">lr_triangle</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">([[</span><span class="mf">3.2</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">]])[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

<span class="n">lr_square</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">lr_square</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">shapes</span><span class="p">[[</span><span class="s1">&#39;$x_1$&#39;</span><span class="p">,</span> <span class="s1">&#39;$x_2$&#39;</span><span class="p">]],</span> <span class="n">shapes</span><span class="p">[</span><span class="s1">&#39;$y$&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;square&#39;</span><span class="p">)</span>
<span class="n">proba_square</span> <span class="o">=</span> <span class="n">lr_square</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">([[</span><span class="mf">3.2</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">]])[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

<span class="n">lr_circle</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">lr_circle</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">shapes</span><span class="p">[[</span><span class="s1">&#39;$x_1$&#39;</span><span class="p">,</span> <span class="s1">&#39;$x_2$&#39;</span><span class="p">]],</span> <span class="n">shapes</span><span class="p">[</span><span class="s1">&#39;$y$&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;circle&#39;</span><span class="p">)</span>
<span class="n">proba_circle</span> <span class="o">=</span> <span class="n">lr_circle</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">([[</span><span class="mf">3.2</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">]])[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Triangle:&#39;</span><span class="p">,</span> <span class="n">proba_triangle</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Square:&#39;</span><span class="p">,</span> <span class="n">proba_square</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Circle:&#39;</span><span class="p">,</span> <span class="n">proba_circle</span><span class="p">)</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">



<div class="output_subarea output_stream output_stdout output_text">
<pre>Triangle: 0.1457476378273223
Square: 0.28507914730638007
Circle: 0.49761172107185986
</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<table>
<thead><tr>
<th>triangle</th>
<th>square</th>
<th>circle</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.145748</td>
<td>0.285079</td>
<td>0.497612</td>
</tr>
</tbody>
</table>
<p>Since the positive class probability of <code>circle</code> is the greatest of the three, our multiclass classifier predicts that the observation is a <code>circle</code>.</p></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Case-Study:-Iris-dataset">Case Study: Iris dataset<a class="anchor-link" href="#Case-Study:-Iris-dataset">&#182;</a></h2><p>The <a href="https://archive.ics.uci.edu/ml/datasets/iris">Iris dataset</a> is a famous dataset that is often used in data science to explore machine learning concepts. There are three classes, each representing a type of Iris plant:</p>
<ul>
<li>Iris-setosa (represented in the dataset by <code>0</code>)</li>
<li>Iris-versicolour (<code>1</code>)</li>
<li>Iris-virginica (<code>2</code>)</li>
</ul>
<p>There are four features available in the dataset:</p>
<ul>
<li>Sepal length (cm)</li>
<li>Sepal width (cm)</li>
<li>Petal length (cm)</li>
<li>Petal width (cm)</li>
</ul>
<p><img src="petal_sepal.png" alt=""></p>
<p>We will create a multiclass classifier that predicts the type of Iris plant based on the four features above. First, we read in the data:</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">iris</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#39;</span><span class="p">,</span>
                  <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal_width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal_width&#39;</span><span class="p">,</span> <span class="s1">&#39;species&#39;</span><span class="p">])</span>

<span class="n">iris</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">




<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal_length</th>
      <th>sepal_width</th>
      <th>petal_length</th>
      <th>petal_width</th>
      <th>species</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
  </tbody>
</table></div></div></div></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;species&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">]</span>
</pre></div></div></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Alternatively, read in from sklearn.datasets</span>
<span class="c1"># from sklearn.datasets import load_iris</span>

<span class="c1"># X, y = load_iris(return_X_y=True)</span>
</pre></div></div></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.35</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After dividing the dataset into train and test splits, we fit a multiclass classifier to our training data. By default, scikit-learn's <code>LogisticRegression</code> sets <code>multi_class='ovr'</code>:</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">





<div class="output_text output_subarea output_execute_result">
<pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;ovr&#39;, n_jobs=1,
          penalty=&#39;l2&#39;, random_state=42, solver=&#39;liblinear&#39;, tol=0.0001,
          verbose=0, warm_start=False)</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We predict on the test data, and use a confusion matrix to evaluate the results:</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># to-do: add x-axis, y-axis labels to confusion matrix</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">





<div class="output_text output_subarea output_execute_result">
<pre>array([[19,  0,  0],
       [ 0, 15,  2],
       [ 0,  0, 17]])</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The confusion matrix shows that our classifier misclassified two <code>Iris-versicolour</code> observations as <code>Iris-virginica</code>. In the real world, certain misclassifications can be more common than others. Confusion matrices are valuable because they help us identify where our classifier struggles, and thus provides insight on what kind of features we may need to extract in order to improve the classifier.</p></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Multilabel-Classification">Multilabel Classification<a class="anchor-link" href="#Multilabel-Classification">&#182;</a></h2><p>Another type of classification problem is <strong>multilabel classification</strong>, in which each observation can have multiple labels. An example would be a document classification system: a document can be classified as having positive or negative sentiments, but it can also be distinguished between religious/nonreligious or political/apolitical. Multilabel problems can also be multiclass; we may want our document classification system to distinguish between a list of genres, as well as identify the language that the document is written in.</p>
<p>Because each set of labels in a multiclass classification is mutually exclusive, each problem can be solved independently of the others. We can then combine the outputs so that every observation is assigned a set of classification labels.</p></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary">Summary<a class="anchor-link" href="#Summary">&#182;</a></h2><p>(to-do)</p></div></div></div></div>
