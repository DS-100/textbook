
<div id="ipython-notebook">
    <div class="buttons">
        <button class="interact-button js-nbinteract-widget">
            Show Widgets
        </button>
        <a class="interact-button" href="http://data100.datahub.berkeley.edu/user-redirect/git-pull?repo=https://github.com/DS-100/textbook&subPath=notebooks/ch17/classification_precision_recall.ipynb">Open on DataHub</a></div>
    




<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  style="display:none;"
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="c1"># Clear previously defined variables</span>
<span class="o">%</span><span class="k">reset</span> -f

<span class="c1"># Set directory for data loading to work properly</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/notebooks/ch17&#39;</span><span class="p">))</span>
</pre></div></div></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  style="display:none;"
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="k">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">interact_manual</span>
<span class="kn">import</span> <span class="nn">nbinteract</span> <span class="k">as</span> <span class="nn">nbi</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s1">&#39;talk&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_columns</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="c1"># This option stops scientific notation for pandas</span>
<span class="c1"># pd.set_option(&#39;display.float_format&#39;, &#39;{:.2f}&#39;.format)</span>
</pre></div></div></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction</span> <span class="k">import</span> <span class="n">DictVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">confusion_matrix</span>

<span class="n">emails</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;emails.csv&#39;</span><span class="p">)</span>
<span class="n">ham</span> <span class="o">=</span> <span class="n">emails</span><span class="p">[</span><span class="n">emails</span><span class="p">[</span><span class="s1">&#39;spam&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="mi">1000</span><span class="p">:</span><span class="mi">1950</span><span class="p">][[</span><span class="s1">&#39;email&#39;</span><span class="p">,</span> <span class="s1">&#39;spam&#39;</span><span class="p">]]</span>
<span class="n">spam</span> <span class="o">=</span> <span class="n">emails</span><span class="p">[</span><span class="n">emails</span><span class="p">[</span><span class="s1">&#39;spam&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="mi">400</span><span class="p">:</span><span class="mi">450</span><span class="p">][[</span><span class="s1">&#39;email&#39;</span><span class="p">,</span> <span class="s1">&#39;spam&#39;</span><span class="p">]]</span>
<span class="n">emails</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">ham</span><span class="p">,</span> <span class="n">spam</span><span class="p">])</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">emails</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;selected_emails.csv&#39;</span><span class="p">)</span>
</pre></div></div></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#HIDDEN (from proj 2, simply for the purpose of generating the feature matrix X for the model training)</span>

<span class="k">def</span> <span class="nf">words_in_texts</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">texts</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Args:</span>
<span class="sd">        words (list-like): words to find</span>
<span class="sd">        texts (Series): strings to search in</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        NumPy array of 0s and 1s with shape (n, p) where n is the</span>
<span class="sd">        number of texts and p is the number of words.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">indicator_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">texts</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>

    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">return</span> <span class="n">indicator_array</span>
</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluating-Classification-Models">Evaluating Classification Models<a class="anchor-link" href="#Evaluating-Classification-Models">&#182;</a></h2><p>In this section, we examine more metrics to evaluate the performance of trained classification models.</p></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Suppose we have a dataset of 1000 emails that are labeled as spam or ham and our goal is to build a classifier that distinguishes future spam emails from ham emails. The data is contained in the <code>emails</code> DataFrame displayed below:</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">emails</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">




<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>email</th>
      <th>spam</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>\n Hi Folks,\n \n I've been trying to set a bu...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Hah.  I guess she doesn't want everyone to kno...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>This article from NYTimes.com \n has been sent...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>997</th>
      <td>&lt;html&gt;\n &lt;head&gt;\n     &lt;meta http-equiv="Conten...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>998</th>
      <td>&lt;html&gt;\n &lt;head&gt;\n &lt;/head&gt;\n &lt;body&gt;\n \n &lt;cente...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>999</th>
      <td>\n &lt;html&gt;\n \n &lt;head&gt;\n &lt;meta http-equiv=3D"Co...</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>1000 rows Ã— 2 columns</p></div></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Each row contains the body of an email and a <code>spam</code> column, which is <code>0</code> if the email is ham or <code>1</code> if it is spam.</p></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Suppose we have a list of words <code>words_list</code> that we believe are common in spam emails: "please", "click", "money", and "business". We transform each email into a feature vector by setting the vector's $i$th entry to 1 if the $i$th word in <code>words_list</code> is contained in the email body and 0 if it isn't. For example, using our four chosen words and the email body "please respond by tomorrow", the feature vector would be $[1, 0, 0, 0]$. This procedure generates the <code>1000 X 4</code> feature matrix $X$.</p></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The following code trains the classifier <code>words_list_model</code>. The conversion of the raw email text to the feature matrix $X$ and the train-test split are omitted for brevity.</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  style="display:none;"
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;please&#39;</span><span class="p">,</span> <span class="s1">&#39;click&#39;</span><span class="p">,</span> <span class="s1">&#39;money&#39;</span><span class="p">,</span> <span class="s1">&#39;business&#39;</span><span class="p">]</span>

<span class="c1"># HIDDEN</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">words_in_texts</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">emails</span><span class="p">[</span><span class="s1">&#39;email&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()))</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">emails</span><span class="p">[</span><span class="s1">&#39;spam&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span>

<span class="c1"># Train-test split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">41</span>
<span class="p">)</span>

<span class="c1"># SHOW</span>

<span class="c1">#Fit the model</span>
<span class="n">words_list_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">words_list_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test set accuracy: {words_list_model.score(X_test, y_test)}&#39;</span><span class="p">)</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">



<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set accuracy: 0.944
</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using just the occurrence of four words, we have built a model that accurately classifies about 94% of the emails in the test set, which at first glance is a good result. However, if we take a closer look at our data we realize that our classifier isn't performing as well as we thought.</p>
<p>The accuracy we computed is the proportion of predictions that the model correctly classified. The fact that the accuracy is high implies that most of the model's classifications are true positives and true negatives, which occur when the model correctly labels the positive class (spam) and negative class (ham) respectively. On the other hand, there are two types of errors a model can make:</p>
<ul>
<li>False positive: a ham email gets flagged as spam and filtered out of the inbox. Generally, a false positive occurs when the model assigns a data point to the positive class (spam) whereas it actually belonged in the negative class (ham).</li>
<li>False negative:  a spam email gets mislabelled as ham and ends up in the inbox. Generally, a false negative occurs when the model assigns a data point to the negative class (ham) whereas it actually belonged in the positive class (spam).</li>
</ul>
<p>We can assess the number of errors relative to correct classifications by building a <strong>confusion matrix</strong>, which contains the model predictions on one axis and the actual labels on the other.</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">confusion_matrix</span>

<span class="n">cnf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">words_list_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">plot_confusion_matrix</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span>
                          <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                          <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Confusion matrix&#39;</span><span class="p">,</span>
                          <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function prints and plots the confusion matrix.</span>
<span class="sd">    Normalization can be applied by setting `normalize=True`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">itertools</span>
    <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="n">cm</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Normalized confusion matrix&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Confusion matrix, without normalization&#39;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
    <span class="n">tick_marks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>

    <span class="n">fmt</span> <span class="o">=</span> <span class="s1">&#39;.2f&#39;</span> <span class="k">if</span> <span class="n">normalize</span> <span class="k">else</span> <span class="s1">&#39;d&#39;</span>
    <span class="n">thresh</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">/</span> <span class="mf">2.</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="nb">format</span><span class="p">(</span><span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">fmt</span><span class="p">),</span>
                 <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
                 <span class="n">color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span> <span class="k">if</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">thresh</span> <span class="k">else</span> <span class="s2">&quot;black&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True label&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted label&#39;</span><span class="p">)</span>
    
<span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Ham&#39;</span><span class="p">,</span> <span class="s1">&#39;Spam&#39;</span><span class="p">]</span>
<span class="c1"># Plot non-normalized confusion matrix</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">cnf_matrix</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">class_names</span><span class="p">,</span>
                      <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Confusion matrix, without normalization&#39;</span><span class="p">)</span>

<span class="c1"># # Plot normalized confusion matrix</span>
<span class="c1"># plt.figure()</span>
<span class="c1"># plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,</span>
<span class="c1">#                       title=&#39;Normalized confusion matrix&#39;)</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">



<div class="output_subarea output_stream output_stdout output_text">
<pre>Confusion matrix, without normalization
[[710   4]
 [ 33   3]]
</pre></div></div>

<div class="output_area">





<div class="output_png output_subarea ">
<img src="/notebooks-images/classification_precision_recall_12_1.png"
></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>See <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix">here</a> for more on scikit-learn's confusion matrix generator.</p>
<p>Adding together the number of true positives and false negatives, we know the training dataset contains 36 spam emails, but the model only detected 3 of them. Despite its high accuracy, the model identified $\frac{1}{12}$ of spam emails, which is quite a poor performance.</p>
<p>What if we used a classifier <code>ham_only</code> that simply labeled every email as ham? We can calculate its accuracy by knowing the number of ham emails in the dataset: $$ \text{Accuracy} = \frac{TP + TN}{TP + FP + TN + FN} = \frac{0 + 714}{0 + 0 + 714 + 36} = .95$$</p></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This model, which is essentially useless as a classifier, surprisingly achieves a better accuracy than our EDA-driven model. Clearly accuracy alone can be a misleading indicator of model performance. This is especially characteristic of <strong>class-imbalanced datasets</strong>, in which a vast majority of labels belong in one class over the other. In this case, most of our emails are ham. The confusion matrix shows that <code>words_list_model</code> had many more false negatives than true positives, which implies that it didn't have enough features to reliably identify spam, but because the dataset is predominantly ham, it had a deceptively high accuracy. Another common example of class imbalance is disease detection when the frequency of the disease in a population is low.</p>
<p>We now turn to precision and recall, two metrics that are better suited for evaluating class-imbalanced datasets.</p></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Precision">Precision<a class="anchor-link" href="#Precision">&#182;</a></h3><p><strong>Precision</strong> (also called <strong>positive predictive value</strong>) measures the proportion of positively classified data that are actually positive.</p>
<p>$$ \text{Precision} = \frac{TP}{TP + FP} $$</p>
<p>A model with high precision accurately classifies data that truly has positive labels, whereas a model with low precision incorrectly labels truly negative data as positive with high frequency (many false positives).</p>
<p>The precision of <code>words_list_model</code> is $ \frac{3}{3 + 4} \approx .43 $, whereas the precision of <code>ham_only</code> is 0 (do you see why?). This validates our expectation that <code>words_list_model</code> is a better classifier than <code>ham_only</code>, but there is still significant room to improve it.</p>
<p>See <a href="">here</a> for scikit-learn's precision function.</p></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Recall">Recall<a class="anchor-link" href="#Recall">&#182;</a></h3><p><strong>Recall</strong> (also called <strong>sensitivity</strong>) measures the proportion of actual positive data that is classified as positive.</p>
<p>$$ \text{Recall} = \frac{TP}{TP + FN} $$</p>
<p>A model with high recall accurately recognizes aspects of positive data, whereas a model with low recall isn't sensitive enough to what distinguishes positive from negative data, and as a result leads to ample false negatives.</p>
<p>The recall of <code>words_list_model</code> is $ \frac{3}{3 + 33} \approx .083$, whereas the recall of <code>ham_only</code> is 0 (do you see why?). This is further confirmation that <code>ham_only</code> is useless; however the abysmally low recall of <code>words_list_model</code> is a strong indication that we need to do much more EDA and feature engineering to improve the model.</p>
<p>See <a href="">here</a> for scikit-learn's recall function.</p></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Precision-Recall-Curve">Precision-Recall Curve<a class="anchor-link" href="#Precision-Recall-Curve">&#182;</a></h3><p>Both precision and recall are needed to thoroughly evaluate a model. Although the goal is to maximize both metrics, there is a tradeoff between increasing precision and increasing recall. Generally, increasing precision leads to a decrease in recall and vice versa (though there may be some cases where they move in the same direction). For instance, reducing the number of false negatives can increase false positives on data for which the model is less certain of its classification.</p>
<p>The <strong>classification threshold</strong> is a value that determines what class a data point is assigned to; points that fall on opposite sides of the threshold are labeled with different classes. Recall that logistic regression outputs a probability that the data point belongs to the positive class. If the probability output on $x_1$ is .90 and the output on $x_2$ is .1, then we can be fairly confident that $x_1$ is spam and $x_2$ is ham. However, if the probability associated with $x_3$ is around .55, there is greater uncertainty about the correct class. If the classification threshold is .50, $x_3$ is labeled as spam, but if the threshold is .60, $x_3$ is labeled as ham. Depending on the classification problem, false positives and false negatives may have different importance. Set the classification threshold based on which error type you want to minimize: minimizing false positives maximizes precision and minimizing false negatives maximizes recall. For email classification, false positives result in important emails being filtered out, so they are worse than false negatives, in which a spam email winds up in the inbox. In medical settings, however, false negatives in a diagnostic test can be much more consequential than false positives.</p>
<p>A <strong>precision-recall curve</strong> plots the precision and recall at all classification thresholds. A point $(r, p)$ on the curve represents the recall and precision associated with a specific threshold value. The precision-recall curve for <code>words_list_model</code> is shown below:</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">precision_recall_curve</span>


<span class="n">probabilities</span> <span class="o">=</span> <span class="n">words_list_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">probabilities</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
         <span class="n">where</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                 <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Recall&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Precision&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Spam vs. Ham Classifier Precision-Recall Curve&#39;</span><span class="p">)</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">





<div class="output_text output_subarea output_execute_result">
<pre>array([ 0.02,  0.03,  0.05,  0.05,  0.06,  0.07,  0.11,  0.13,  0.14,
        0.17,  0.24,  0.26,  0.3 ,  0.33,  0.48,  0.56])</pre></div></div>

<div class="output_area">





<div class="output_png output_subarea ">
<img src="/notebooks-images/classification_precision_recall_18_1.png"
></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>See <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve">here</a> for scikit-learn's precision-recall function.</p>
<p>The <strong>Area Under the Curve (AUC)</strong> is a single number performance summary of the classifier. A large AUC means that the model has both high precision and recall, which implies that it has few false postivives and false negatives. The AUC for <code>words_list_model</code> is:</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># from sklearn import metrics</span>
<span class="c1"># metrics.auc(precision, recall)</span>
</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Depending on whether we value high precision or recall, we can pick a point on the precision-recall curve and use its associated threshold value for our final model. Most importantly, we use the curve to evaluate the performance of the model and whether or not to continue EDA and feature selection to improve it, as would be beneficial in the case of <code>words_list_model</code>.</p></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Summary">Summary<a class="anchor-link" href="#Summary">&#182;</a></h3><p><em>In progress: depends on approval of the material covered so far.</em></p></div></div></div></div>
