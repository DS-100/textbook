
<div id="ipython-notebook">
    <div class="buttons">
        <button class="interact-button js-nbinteract-widget">
            Show Widgets
        </button>
        <a class="interact-button" href="http://data100.datahub.berkeley.edu/user-redirect/git-pull?repo=https://github.com/DS-100/textbook&subPath=notebooks/ch13/feature_one_hot.ipynb">Open on DataHub</a></div>
    




<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  style="display:none;"
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="c1"># Clear previously defined variables</span>
<span class="o">%</span><span class="k">reset</span> -f

<span class="c1"># Set directory for data loading to work properly</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~/notebooks/ch13&#39;</span><span class="p">))</span>
</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><h1>Table of Contents<span class="tocSkip"></span></h1></p>
<div class="toc"><ul class="toc-item"><li><span><a href="#One-Hot-Encoding-for-Categorial-Data" data-toc-modified-id="One-Hot-Encoding-for-Categorial-Data-1">One-Hot Encoding for Categorial Data</a></span><ul class="toc-item"><li><span><a href="#The-Walmart-dataset" data-toc-modified-id="The-Walmart-dataset-1.1">The Walmart dataset</a></span></li><li><span><a href="#Fitting-a-Model-Using-Scikit-Learn" data-toc-modified-id="Fitting-a-Model-Using-Scikit-Learn-1.2">Fitting a Model Using Scikit-Learn</a></span></li><li><span><a href="#The-One-Hot-Encoding" data-toc-modified-id="The-One-Hot-Encoding-1.3">The One-Hot Encoding</a></span></li><li><span><a href="#One-Hot-Encoding-in-Scikit-Learn" data-toc-modified-id="One-Hot-Encoding-in-Scikit-Learn-1.4">One-Hot Encoding in Scikit-Learn</a></span></li><li><span><a href="#Fitting-a-Model-Using-the-Transformed-Data" data-toc-modified-id="Fitting-a-Model-Using-the-Transformed-Data-1.5">Fitting a Model Using the Transformed Data</a></span></li><li><span><a href="#Model-Diagnosis" data-toc-modified-id="Model-Diagnosis-1.6">Model Diagnosis</a></span></li></ul></li><li><span><a href="#Summary" data-toc-modified-id="Summary-2">Summary</a></span></li></ul></div></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  style="display:none;"
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="k">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">interact_manual</span>
<span class="kn">import</span> <span class="nn">nbinteract</span> <span class="k">as</span> <span class="nn">nbi</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="k">import</span> <span class="n">display</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s1">&#39;talk&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_columns</span> <span class="o">=</span> <span class="mi">8</span>
</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="One-Hot-Encoding-for-Categorial-Data">One-Hot Encoding for Categorial Data<a class="anchor-link" href="#One-Hot-Encoding-for-Categorial-Data">&#182;</a></h2><h3 id="The-Walmart-dataset">The Walmart dataset<a class="anchor-link" href="#The-Walmart-dataset">&#182;</a></h3><p>In 2014, Walmart released some of its sales data as part of a competition to predict the weekly sales of its stores. We've taken a subset of their data and loaded it below.</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">walmart</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;walmart.csv&#39;</span><span class="p">)</span>
<span class="n">walmart</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Weekly_Sales</th>
      <th>IsHoliday</th>
      <th>Temperature</th>
      <th>Fuel_Price</th>
      <th>Unemployment</th>
      <th>MarkDown</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2010-02-05</td>
      <td>24924.50</td>
      <td>No</td>
      <td>42.31</td>
      <td>2.572</td>
      <td>8.106</td>
      <td>No Markdown</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2010-02-12</td>
      <td>46039.49</td>
      <td>Yes</td>
      <td>38.51</td>
      <td>2.548</td>
      <td>8.106</td>
      <td>No Markdown</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2010-02-19</td>
      <td>41595.55</td>
      <td>No</td>
      <td>39.93</td>
      <td>2.514</td>
      <td>8.106</td>
      <td>No Markdown</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>140</th>
      <td>2012-10-12</td>
      <td>22764.01</td>
      <td>No</td>
      <td>62.99</td>
      <td>3.601</td>
      <td>6.573</td>
      <td>MarkDown2</td>
    </tr>
    <tr>
      <th>141</th>
      <td>2012-10-19</td>
      <td>24185.27</td>
      <td>No</td>
      <td>67.97</td>
      <td>3.594</td>
      <td>6.573</td>
      <td>MarkDown2</td>
    </tr>
    <tr>
      <th>142</th>
      <td>2012-10-26</td>
      <td>27390.81</td>
      <td>No</td>
      <td>69.16</td>
      <td>3.506</td>
      <td>6.573</td>
      <td>MarkDown1</td>
    </tr>
  </tbody>
</table>
<p>143 rows × 7 columns</p></div></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The data contains several interesting features, including whether a week contained a holiday (<code>IsHoliday</code>), the unemployment rate that week (<code>Unemployment</code>), and which special deals the store offered that week (<code>MarkDown</code>).</p>
<p>Our goal is to create a model that predicts the <code>Weekly_Sales</code> variable using the other variables in our data. Using a linear regression model we directly can use the <code>Temperature</code>, <code>Fuel_Price</code>, and <code>Unemployment</code> columns because they contain numerical data.</p></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Fitting-a-Model-Using-Scikit-Learn">Fitting a Model Using Scikit-Learn<a class="anchor-link" href="#Fitting-a-Model-Using-Scikit-Learn">&#182;</a></h3><p>In previous sections we have seen how to take the gradient of the cost function and use gradient descent to fit a model. To do this, we had to define Python functions for our model, the cost function, the gradient of the cost function, and the gradient descent algorithm. While this was important to demonstrate how the concepts work, in this section we will instead use a machine learning library called <a href="http://scikit-learn.org/"><code>scikit-learn</code></a> which allows us to fit a model with less code.</p>
<p>For example, to fit a multiple linear regression model using the numerical columns in the Walmart dataset, we first create a two-dimensional NumPy array containing the variables used for prediction and a one-dimensional array containing the values we want to predict:</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">numerical_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Temperature&#39;</span><span class="p">,</span> <span class="s1">&#39;Fuel_Price&#39;</span><span class="p">,</span> <span class="s1">&#39;Unemployment&#39;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">walmart</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">]</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span>
<span class="n">X</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_text output_subarea output_execute_result">
<pre>array([[ 42.31,   2.57,   8.11],
       [ 38.51,   2.55,   8.11],
       [ 39.93,   2.51,   8.11],
       ..., 
       [ 62.99,   3.6 ,   6.57],
       [ 67.97,   3.59,   6.57],
       [ 69.16,   3.51,   6.57]])</pre></div></div></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">walmart</span><span class="p">[</span><span class="s1">&#39;Weekly_Sales&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span>
<span class="n">y</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_text output_subarea output_execute_result">
<pre>array([ 24924.5 ,  46039.49,  41595.55, ...,  22764.01,  24185.27,
        27390.81])</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then, we import the <code>LinearRegression</code> class from <code>scikit-learn</code> (<a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression">docs</a>), instantiate it, and call the <code>fit</code> method using <code>X</code> to predict <code>y</code>.</p>
<p>Note that previously we had to manually add a column of all $1$'s to the <code>X</code> matrix in order to conduct linear regression with an intercept. This time, <code>scikit-learn</code> will take care of the intercept column behind the scenes, saving us some work.</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LinearRegression</span>

<span class="n">simple_classifier</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">simple_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_text output_subarea output_execute_result">
<pre>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We are done! When we called <code>.fit</code>, <code>scikit-learn</code> found the linear regression parameters that minimized the least squares cost function. We can see the parameters below:</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">simple_classifier</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">simple_classifier</span><span class="o">.</span><span class="n">intercept_</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_text output_subarea output_execute_result">
<pre>(array([ -332.22,  1626.63,  1356.87]), 29642.700510138635)</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To calculate the mean squared cost, we can ask the classifier to make predictions for the input data <code>X</code> and compare the predictions with the actual values <code>y</code>.</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">simple_classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">predictions</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_text output_subarea output_execute_result">
<pre>74401210.603607252</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The mean squared error looks quite high. This is likely because our variables (temperature, price of fuel, and unemployment rate) are only weakly correlated with the weekly sales.</p>
<p>There are two more variables in our data that might be more useful for prediction: the <code>IsHoliday</code> column and <code>MarkDown</code> column. The boxplot below shows that holidays may have some relation with the weekly sales.</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">pointplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;IsHoliday&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Weekly_Sales&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">walmart</span><span class="p">);</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/feature_one_hot_16_0.png"
></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The different markdown categories seem to correlate with different weekly sale amounts well.</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">markdowns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;No Markdown&#39;</span><span class="p">,</span> <span class="s1">&#39;MarkDown1&#39;</span><span class="p">,</span> <span class="s1">&#39;MarkDown2&#39;</span><span class="p">,</span> <span class="s1">&#39;MarkDown3&#39;</span><span class="p">,</span> <span class="s1">&#39;MarkDown4&#39;</span><span class="p">,</span> <span class="s1">&#39;MarkDown5&#39;</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pointplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;Weekly_Sales&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;MarkDown&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">walmart</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">markdowns</span><span class="p">);</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/feature_one_hot_18_0.png"
></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>However, both <code>IsHoliday</code> and <code>MarkDown</code> columns contain categorical data, not numerical, so we cannot use them as-is for regression.</p></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-One-Hot-Encoding">The One-Hot Encoding<a class="anchor-link" href="#The-One-Hot-Encoding">&#182;</a></h3><p>Fortunately, we can perform a <strong>one-hot encoding</strong> transformation on these categorical variables to convert them into numerical variables. The transformation works as follows: create a new column for every unique value in a categorical variable. The column contains a $1$ if the variable originally had the corresponding value, otherwise the column contains a $0$. For example, the <code>MarkDown</code> column below contains the following values:</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  style="display:none;"
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">walmart</span><span class="p">[[</span><span class="s1">&#39;MarkDown&#39;</span><span class="p">]]</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MarkDown</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>No Markdown</td>
    </tr>
    <tr>
      <th>1</th>
      <td>No Markdown</td>
    </tr>
    <tr>
      <th>2</th>
      <td>No Markdown</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>140</th>
      <td>MarkDown2</td>
    </tr>
    <tr>
      <th>141</th>
      <td>MarkDown2</td>
    </tr>
    <tr>
      <th>142</th>
      <td>MarkDown1</td>
    </tr>
  </tbody>
</table>
<p>143 rows × 1 columns</p></div></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This variable contains six different unique values: 'No Markdown', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', and 'MarkDown5'. We create one column for each value to get six columns in total. Then, we fill in the columns with zeros and ones according the scheme described above.</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  style="display:none;"
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction</span> <span class="k">import</span> <span class="n">DictVectorizer</span>

<span class="n">items</span> <span class="o">=</span> <span class="n">walmart</span><span class="p">[[</span><span class="s1">&#39;MarkDown&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="n">orient</span><span class="o">=</span><span class="s1">&#39;records&#39;</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">DictVectorizer</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">items</span><span class="p">),</span>
    <span class="n">columns</span><span class="o">=</span><span class="n">encoder</span><span class="o">.</span><span class="n">feature_names_</span>
<span class="p">)</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MarkDown=MarkDown1</th>
      <th>MarkDown=MarkDown2</th>
      <th>MarkDown=MarkDown3</th>
      <th>MarkDown=MarkDown4</th>
      <th>MarkDown=MarkDown5</th>
      <th>MarkDown=No Markdown</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>140</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>141</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>142</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>143 rows × 6 columns</p></div></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Notice that the first value in the data is "No Markdown", and thus only the last column of the first row in the transformed table is marked with $1$. In addition, the last value in the data is "MarkDown1" which results in the first column of row 142 marked as $1$.</p>
<p>Each row of the resulting table will contain a single column containing $1$; the rest will contain $0$. The name "one-hot" reflects the fact that only one column is "hot" (marked with a $1$).</p></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="One-Hot-Encoding-in-Scikit-Learn">One-Hot Encoding in Scikit-Learn<a class="anchor-link" href="#One-Hot-Encoding-in-Scikit-Learn">&#182;</a></h3><p>To perform one-hot encoding we can use <code>scikit-learn</code>'s <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html"><code>DictVectorizer</code></a> class. To use the class, we have to convert our dataframe into a list of dictionaries. The DictVectorizer class automatically one-hot encodes the categorical data (which needs to be strings) and leaves numerical data untouched.</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction</span> <span class="k">import</span> <span class="n">DictVectorizer</span>

<span class="n">all_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Temperature&#39;</span><span class="p">,</span> <span class="s1">&#39;Fuel_Price&#39;</span><span class="p">,</span> <span class="s1">&#39;Unemployment&#39;</span><span class="p">,</span> <span class="s1">&#39;IsHoliday&#39;</span><span class="p">,</span>
               <span class="s1">&#39;MarkDown&#39;</span><span class="p">]</span>

<span class="n">records</span> <span class="o">=</span> <span class="n">walmart</span><span class="p">[</span><span class="n">all_columns</span><span class="p">]</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="n">orient</span><span class="o">=</span><span class="s1">&#39;records&#39;</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">DictVectorizer</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">encoded_X</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">records</span><span class="p">)</span>
<span class="n">encoded_X</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_text output_subarea output_execute_result">
<pre>array([[  2.57,   1.  ,   0.  , ...,   1.  ,  42.31,   8.11],
       [  2.55,   0.  ,   1.  , ...,   1.  ,  38.51,   8.11],
       [  2.51,   1.  ,   0.  , ...,   1.  ,  39.93,   8.11],
       ..., 
       [  3.6 ,   1.  ,   0.  , ...,   0.  ,  62.99,   6.57],
       [  3.59,   1.  ,   0.  , ...,   0.  ,  67.97,   6.57],
       [  3.51,   1.  ,   0.  , ...,   0.  ,  69.16,   6.57]])</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To get a better sense of the transformed data, we can display it with the column names:</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">encoded_X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">encoder</span><span class="o">.</span><span class="n">feature_names_</span><span class="p">)</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fuel_Price</th>
      <th>IsHoliday=No</th>
      <th>IsHoliday=Yes</th>
      <th>MarkDown=MarkDown1</th>
      <th>...</th>
      <th>MarkDown=MarkDown5</th>
      <th>MarkDown=No Markdown</th>
      <th>Temperature</th>
      <th>Unemployment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2.572</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>42.31</td>
      <td>8.106</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.548</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>38.51</td>
      <td>8.106</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2.514</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>39.93</td>
      <td>8.106</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>140</th>
      <td>3.601</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>62.99</td>
      <td>6.573</td>
    </tr>
    <tr>
      <th>141</th>
      <td>3.594</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>67.97</td>
      <td>6.573</td>
    </tr>
    <tr>
      <th>142</th>
      <td>3.506</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>69.16</td>
      <td>6.573</td>
    </tr>
  </tbody>
</table>
<p>143 rows × 11 columns</p></div></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The numerical variables (fuel price, temperature, and unemployment) are left as numbers. The categorical variables (holidays and markdown) are one-hot encoded. When we use the new matrix of data to fit a linear regression model, we will generate one parameter for each column of the data. Since this data matrix contains eleven columns, the model will have twelve parameters since we fit extra parameter for the intercept term.</p></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Fitting-a-Model-Using-the-Transformed-Data">Fitting a Model Using the Transformed Data<a class="anchor-link" href="#Fitting-a-Model-Using-the-Transformed-Data">&#182;</a></h3><p>We can now use the <code>encoded_X</code> variable for linear regression.</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">encoded_X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_text output_subarea output_execute_result">
<pre>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As promised, we have eleven parameters for the columns and one intercept parameter.</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">intercept_</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_text output_subarea output_execute_result">
<pre>(array([ 1622.11,    -2.04,     2.04,   962.91,  1805.06, -1748.48,
        -2336.8 ,   215.06,  1102.25,  -330.91,  1205.56]), 29723.135729284979)</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can compare a few of the predictions from both classifiers to see whether there's a large difference between the two.</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">walmart</span><span class="p">[[</span><span class="s1">&#39;Weekly_Sales&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">pred_numeric</span><span class="o">=</span><span class="n">simple_classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span>
    <span class="n">pred_both</span><span class="o">=</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">encoded_X</span><span class="p">)</span>
<span class="p">)</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Weekly_Sales</th>
      <th>pred_numeric</th>
      <th>pred_both</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>24924.50</td>
      <td>30768.878035</td>
      <td>30766.790214</td>
    </tr>
    <tr>
      <th>1</th>
      <td>46039.49</td>
      <td>31992.279504</td>
      <td>31989.410395</td>
    </tr>
    <tr>
      <th>2</th>
      <td>41595.55</td>
      <td>31465.220158</td>
      <td>31460.280008</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>140</th>
      <td>22764.01</td>
      <td>23492.262649</td>
      <td>24447.348979</td>
    </tr>
    <tr>
      <th>141</th>
      <td>24185.27</td>
      <td>21826.414794</td>
      <td>22788.049554</td>
    </tr>
    <tr>
      <th>142</th>
      <td>27390.81</td>
      <td>21287.928537</td>
      <td>21409.367463</td>
    </tr>
  </tbody>
</table>
<p>143 rows × 3 columns</p></div></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It appears that both models make very similar predictions. A scatter plot of both sets of predictions confirms this.</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">simple_classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">encoded_X</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Predictions using all data vs. numerical features only&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predictions using numerical features&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Predictions using all features&#39;</span><span class="p">);</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_png output_subarea ">
<img src="/notebooks-images/feature_one_hot_37_0.png"
></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model-Diagnosis">Model Diagnosis<a class="anchor-link" href="#Model-Diagnosis">&#182;</a></h3></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Why might this be the case? We can examine the parameters that both models learn. The table below shows the weights learned by the classifier that only used numerical variables without one-hot encoding:</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  style="display:none;"
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="k">def</span> <span class="nf">clf_params</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">clf</span><span class="p">):</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">names</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;Intercept&#39;</span><span class="p">])</span>

<span class="n">clf_params</span><span class="p">(</span><span class="n">numerical_columns</span><span class="p">,</span> <span class="n">simple_classifier</span><span class="p">)</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Temperature</th>
      <td>-332.221180</td>
    </tr>
    <tr>
      <th>Fuel_Price</th>
      <td>1626.625604</td>
    </tr>
    <tr>
      <th>Unemployment</th>
      <td>1356.868319</td>
    </tr>
    <tr>
      <th>Intercept</th>
      <td>29642.700510</td>
    </tr>
  </tbody>
</table></div></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The table below shows the weights learned by the classifier with one-hot encoding.</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  style="display:none;"
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">13</span>
<span class="n">display</span><span class="p">(</span><span class="n">clf_params</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">feature_names_</span><span class="p">,</span> <span class="n">clf</span><span class="p">))</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">7</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Fuel_Price</th>
      <td>1622.106239</td>
    </tr>
    <tr>
      <th>IsHoliday=No</th>
      <td>-2.041451</td>
    </tr>
    <tr>
      <th>IsHoliday=Yes</th>
      <td>2.041451</td>
    </tr>
    <tr>
      <th>MarkDown=MarkDown1</th>
      <td>962.908849</td>
    </tr>
    <tr>
      <th>MarkDown=MarkDown2</th>
      <td>1805.059613</td>
    </tr>
    <tr>
      <th>MarkDown=MarkDown3</th>
      <td>-1748.475046</td>
    </tr>
    <tr>
      <th>MarkDown=MarkDown4</th>
      <td>-2336.799791</td>
    </tr>
    <tr>
      <th>MarkDown=MarkDown5</th>
      <td>215.060616</td>
    </tr>
    <tr>
      <th>MarkDown=No Markdown</th>
      <td>1102.245760</td>
    </tr>
    <tr>
      <th>Temperature</th>
      <td>-330.912587</td>
    </tr>
    <tr>
      <th>Unemployment</th>
      <td>1205.564331</td>
    </tr>
    <tr>
      <th>Intercept</th>
      <td>29723.135729</td>
    </tr>
  </tbody>
</table></div></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see that even when we fit a linear regression model using one-hot encoded columns the weights for fuel price, temperature, and unemployment are very similar to the previous values. All the weights are small in comparison to the intercept term, suggesting that most of the variables are still only slightly correlated with the actual sale amounts. In fact, the model weights for the <code>IsHoliday</code> variable are so low that it makes nearly no difference in prediction whether the date was a holiday or not. Although some of the <code>MarkDown</code> weights are rather large, many markdown events only appear a few times in the dataset.</p></div></div></div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell"
  
>
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">walmart</span><span class="p">[</span><span class="s1">&#39;MarkDown&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div></div></div></div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



<div class="output_text output_subarea output_execute_result">
<pre>No Markdown    92
MarkDown1      25
MarkDown2      13
MarkDown5       9
MarkDown4       2
MarkDown3       2
Name: MarkDown, dtype: int64</pre></div></div></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This suggests that we probably need to collect more data in order for the model to better utilize the effects of markdown events on the sale amounts. (In reality, the dataset shown here is a small subset of a <a href="https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting">much larger dataset</a> released by Walmart. It will be a useful exercise to train a model using the entire dataset instead of a small subset.)</p></div></div></div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary">Summary<a class="anchor-link" href="#Summary">&#182;</a></h2><p>We have learned to use one-hot encoding, a useful technique for conducting linear regression on categorical data. Although in this particular example the transformation didn't affect our model very much, in practice the technique is used widely when working with categorical data. One-hot encoding also illustrates the general principle of feature engineering—it takes an original data matrix and transforms it into a potentially more useful one.</p></div></div></div></div>
